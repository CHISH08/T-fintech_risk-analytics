{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from typing import Union, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные\n",
    "\n",
    "- Данные упорядочены по времени\n",
    "- Задача - предсказать `target`\n",
    "- Фичи - `feature_i`\n",
    "- Трейн, валидация и тест уже определены (см. колонку `sample_part`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет по [ссылке](https://data.tinkoff.ru/s/WreJPgb9pJS687D). Пароль в канале курса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500000 entries, 22620 to 310653\n",
      "Columns: 235 entries, date to sample_part\n",
      "dtypes: category(2), datetime64[ms](1), datetime64[us](2), float64(220), int64(9), object(1)\n",
      "memory usage: 893.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('df.parquet.gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>feature_217</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_193</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_199</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_188</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_106</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_92</th>\n",
       "      <th>feature_179</th>\n",
       "      <th>feature_102</th>\n",
       "      <th>target</th>\n",
       "      <th>sample_part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22620</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1.180855</td>\n",
       "      <td>0.483118</td>\n",
       "      <td>13.976791</td>\n",
       "      <td>1.135021</td>\n",
       "      <td>43.271792</td>\n",
       "      <td>-46.888875</td>\n",
       "      <td>97.558366</td>\n",
       "      <td>...</td>\n",
       "      <td>23.745198</td>\n",
       "      <td>-32.001093</td>\n",
       "      <td>85.489903</td>\n",
       "      <td>1.454045</td>\n",
       "      <td>-195.725786</td>\n",
       "      <td>3.719083</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.813537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478621</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>3.427814</td>\n",
       "      <td>0.886778</td>\n",
       "      <td>27.158209</td>\n",
       "      <td>-0.378728</td>\n",
       "      <td>80.087863</td>\n",
       "      <td>-67.242703</td>\n",
       "      <td>105.803406</td>\n",
       "      <td>...</td>\n",
       "      <td>22.902111</td>\n",
       "      <td>-37.436243</td>\n",
       "      <td>71.735619</td>\n",
       "      <td>1.657242</td>\n",
       "      <td>-176.250404</td>\n",
       "      <td>3.277817</td>\n",
       "      <td>1</td>\n",
       "      <td>-45.987721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372254</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>-38.555018</td>\n",
       "      <td>1.227175</td>\n",
       "      <td>19.893873</td>\n",
       "      <td>0.498787</td>\n",
       "      <td>98.464365</td>\n",
       "      <td>-67.402522</td>\n",
       "      <td>81.858076</td>\n",
       "      <td>...</td>\n",
       "      <td>21.848414</td>\n",
       "      <td>-51.872841</td>\n",
       "      <td>65.363236</td>\n",
       "      <td>1.626874</td>\n",
       "      <td>-178.116798</td>\n",
       "      <td>2.028950</td>\n",
       "      <td>0</td>\n",
       "      <td>-31.074122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>-14.666558</td>\n",
       "      <td>0.753129</td>\n",
       "      <td>18.203010</td>\n",
       "      <td>-1.200014</td>\n",
       "      <td>117.331340</td>\n",
       "      <td>-25.557745</td>\n",
       "      <td>90.277266</td>\n",
       "      <td>...</td>\n",
       "      <td>26.134586</td>\n",
       "      <td>-49.703003</td>\n",
       "      <td>65.013659</td>\n",
       "      <td>1.170023</td>\n",
       "      <td>-192.232264</td>\n",
       "      <td>2.218177</td>\n",
       "      <td>1</td>\n",
       "      <td>-36.703897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216892</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>6.734990</td>\n",
       "      <td>1.129100</td>\n",
       "      <td>11.245920</td>\n",
       "      <td>-0.108955</td>\n",
       "      <td>61.205722</td>\n",
       "      <td>-78.397406</td>\n",
       "      <td>82.637472</td>\n",
       "      <td>...</td>\n",
       "      <td>24.201039</td>\n",
       "      <td>-41.070219</td>\n",
       "      <td>69.986127</td>\n",
       "      <td>1.630795</td>\n",
       "      <td>-200.155528</td>\n",
       "      <td>3.055104</td>\n",
       "      <td>1</td>\n",
       "      <td>-44.672299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date      month    quarter  feature_217  feature_66  feature_9  \\\n",
       "22620  2021-01-01 2021-01-01 2021-01-01     1.180855    0.483118  13.976791   \n",
       "478621 2021-01-01 2021-01-01 2021-01-01     3.427814    0.886778  27.158209   \n",
       "372254 2021-01-01 2021-01-01 2021-01-01   -38.555018    1.227175  19.893873   \n",
       "2596   2021-01-01 2021-01-01 2021-01-01   -14.666558    0.753129  18.203010   \n",
       "216892 2021-01-01 2021-01-01 2021-01-01     6.734990    1.129100  11.245920   \n",
       "\n",
       "        feature_193  feature_15  feature_199  feature_25  ...  feature_20  \\\n",
       "22620      1.135021   43.271792   -46.888875   97.558366  ...   23.745198   \n",
       "478621    -0.378728   80.087863   -67.242703  105.803406  ...   22.902111   \n",
       "372254     0.498787   98.464365   -67.402522   81.858076  ...   21.848414   \n",
       "2596      -1.200014  117.331340   -25.557745   90.277266  ...   26.134586   \n",
       "216892    -0.108955   61.205722   -78.397406   82.637472  ...   24.201039   \n",
       "\n",
       "        feature_188  feature_71  feature_106  feature_14  feature_92  \\\n",
       "22620    -32.001093   85.489903     1.454045 -195.725786    3.719083   \n",
       "478621   -37.436243   71.735619     1.657242 -176.250404    3.277817   \n",
       "372254   -51.872841   65.363236     1.626874 -178.116798    2.028950   \n",
       "2596     -49.703003   65.013659     1.170023 -192.232264    2.218177   \n",
       "216892   -41.070219   69.986127     1.630795 -200.155528    3.055104   \n",
       "\n",
       "        feature_179  feature_102  target  sample_part  \n",
       "22620             1   -28.813537     0.0        train  \n",
       "478621            1   -45.987721     1.0        train  \n",
       "372254            0   -31.074122     1.0        train  \n",
       "2596              1   -36.703897     0.0        train  \n",
       "216892            1   -44.672299     1.0        train  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'target'\n",
    "N_FEATURES = 230\n",
    "features = [f'feature_{i}' for i in range(N_FEATURES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первичный отбор признаков... (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Сначала отсеем совсем уж мусорные признаки.\n",
    "\n",
    "Воспользовавшись вашим кодом для вычисления `IV` из прошлой домашки, для всех **числовых** фичей вычислите `IV` на 20 бакетах. Отсейте признаки с `IV < 0.005`.\n",
    "\n",
    "**Hint:** паркет не всегда сохраняет `dtype` колонки. Чтобы проверить признаки на \"реальный\" тип данных, лучше на всякий случай посмотреть на `nunique` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_0', 'feature_10', 'feature_31', 'feature_37', 'feature_62',\n",
       "       'feature_140', 'feature_144', 'feature_147', 'feature_157',\n",
       "       'feature_161', 'feature_165', 'feature_168', 'feature_179',\n",
       "       'feature_209', 'feature_222'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].columns[df[features].nunique() < 30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_0       4\n",
       "feature_10      2\n",
       "feature_31      3\n",
       "feature_37     12\n",
       "feature_62      2\n",
       "feature_140    52\n",
       "feature_144     2\n",
       "feature_147     2\n",
       "feature_157    13\n",
       "feature_161     2\n",
       "feature_165     2\n",
       "feature_168     2\n",
       "feature_179     2\n",
       "feature_209     3\n",
       "feature_222     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['feature_0', 'feature_10', 'feature_31', 'feature_37', 'feature_62',\n",
    "       'feature_140', 'feature_144', 'feature_147', 'feature_157',\n",
    "       'feature_161', 'feature_165', 'feature_168', 'feature_179',\n",
    "       'feature_209', 'feature_222']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit\n",
    "\n",
    "def woe_transform(badrate : float, offset : float) -> float:\n",
    "    \"\"\"Считаем WoE для бакета с данным badrate и выборки\n",
    "    с данным offset.\"\"\"\n",
    "    epsilon = 0.001\n",
    "    badrate = np.clip(badrate, epsilon, 1 - epsilon)\n",
    "    woe = logit(badrate) - offset\n",
    "    return woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_buckets(x : Union[np.ndarray, pd.Series], n_buckets : int) -> np.ndarray:\n",
    "    \"\"\"Разбивает массив значений признака x на \n",
    "    n_buckets бакетов\"\"\"\n",
    "\n",
    "    x = pd.Series(x).reset_index(drop=True)\n",
    "    buckets = x.rank(method=\"dense\", pct=True) * n_buckets\n",
    "    buckets = np.ceil(buckets) - 1   # np.floor дает другой результат для 5.0, 6.0 и т.д.\n",
    "    buckets = np.array(buckets, dtype=np.int16)\n",
    "\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IV_score(target: np.ndarray,\n",
    "                buckets: np.ndarray):\n",
    "    _, indices = np.unique(buckets, return_inverse=True)\n",
    "    bucket_n = np.bincount(indices)\n",
    "    bucket_sum = np.bincount(indices, weights=target)\n",
    "    B_i = bucket_sum\n",
    "    B = target.sum()\n",
    "    G_i = bucket_n - B_i\n",
    "    G = len(target) - B\n",
    "    badrate_i = bucket_sum / bucket_n\n",
    "    offset = logit(target.sum() / len(target))\n",
    "    woe = pd.Series(woe_transform(badrate_i, offset))\n",
    "    IV = np.sum((B_i / B - G_i / G) * woe)\n",
    "    return IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[TARGET]\n",
    "good_numeric_feature = []\n",
    "category_feature = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/.local/lib/python3.10/site-packages/pandas/core/series.py:1022: RuntimeWarning: invalid value encountered in cast\n",
      "  arr = np.asarray(values, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    if (df[feature].nunique() < 20):\n",
    "        continue\n",
    "    buckets = calc_buckets(df[feature], 20)\n",
    "    iv = IV_score(target, buckets)\n",
    "\n",
    "    if (iv >= 0.005):\n",
    "        good_numeric_feature.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_numeric_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Почему некорректно сравнивать `IV` у категориальных и числовых фичей?\n",
    "\n",
    "Вычислите IV для категориальных фичей на `n` бакетах, где `n = min(число категорий фичи, 20)`. Возможно, придётся перекодировать некоторые фичи (*только не OneHot-ом!*)\n",
    "\n",
    "*Опционально*: примените также и к категориальным фичам предварительный отбор по `IV` с менее строгим порогом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ**:\n",
    "- Разное кол-во бакетов\n",
    "- Так как категориальные признаки имеют определенные значения, его IV более устойчив (в тестовую выборку могут попасть числовые значения, которые не находятся в диапазоне значений train выборки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_0 0.0008358691357387304\n",
      "feature_10 0.011839696555363967\n",
      "feature_31 0.012373891296708375\n",
      "feature_37 0.00012575456432455502\n",
      "feature_62 0.00706412337610622\n",
      "feature_144 0.013360993295612683\n",
      "feature_147 0.007958353560070207\n",
      "feature_157 0.00014195011557541028\n",
      "feature_161 0.0026729692259997626\n",
      "feature_165 0.00913622428642341\n",
      "feature_168 0.006440163058606558\n",
      "feature_179 6.183068576974373e-07\n",
      "feature_209 0.02519535296049066\n",
      "feature_222 7.464729004320941e-07\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    if (df[feature].nunique() >= 20):\n",
    "        continue\n",
    "    le = LabelEncoder()\n",
    "    df_column_up = le.fit_transform(df[feature])\n",
    "    buckets = calc_buckets(df_column_up, min(len(np.unique(df_column_up)), 20))\n",
    "    iv = IV_score(target, buckets)\n",
    "\n",
    "    if (iv >= 0.002):\n",
    "        category_feature.append(feature)\n",
    "    print(feature, iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = [LabelEncoder() for _ in range(len(category_feature))]\n",
    "for le_i in range(len(le)):\n",
    "    df[category_feature[le_i]] = le[le_i].fit_transform(df[category_feature[le_i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров бустинга (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подберем оптимальные гиперпараметры бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В переменную features_optuna положите список признаков с предыдущего шага\n",
    "features_optuna = good_numeric_feature + category_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Заполните пропуски в коде ниже и подберите оптимальные гиперпараметры.\n",
    "\n",
    "Для успешного решения необходимо преодолеть порог ROC-AUC `0.725` на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        # 'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss', 'rf']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 0.4, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.0, 1.0),\n",
    "        'n_estimators': trial.suggest_int('num_leaves', 1, 800),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.0, 1.0),\n",
    "        'importance_type': trial.suggest_categorical('importance_type', ['split', 'gain']),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 3),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 3),\n",
    "        'objective': 'binary',\n",
    "        'n_jobs': 12,\n",
    "        #####\n",
    "        # your code here\n",
    "        # Тут вы можете добавить любые гиперпараметры LGBMClassifier (например, что-то из того, что разбирали в лекции)\n",
    "        #####\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(\n",
    "        X=df.loc[df['sample_part'] == 'train', features_optuna],\n",
    "        y=df.loc[df['sample_part'] == 'train', TARGET]\n",
    "    )\n",
    "    preds = clf.predict_proba(df.loc[df['sample_part'] == 'val', features_optuna])[:, 1]\n",
    "    auc_valid = roc_auc_score(\n",
    "        y_true=df.loc[df['sample_part'] == 'val', TARGET],\n",
    "        y_score=preds\n",
    "    )\n",
    "\n",
    "    return auc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:48:30,488] A new study created in memory with name: no-name-64a6cc22-4f96-43a9-8314-8625bab58f2b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:48:42,648] Trial 0 finished with value: 0.7445005235551239 and parameters: {'learning_rate': 0.18312444310486622, 'max_depth': 125, 'subsample': 0.948085524087867, 'num_leaves': 591, 'colsample_bytree': 0.7171365055018374, 'importance_type': 'gain', 'reg_alpha': 1.4559035057458853, 'reg_lambda': 2.595776426854668}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:48:48,760] Trial 1 finished with value: 0.7344275444390481 and parameters: {'learning_rate': 0.14351858160048198, 'max_depth': 95, 'subsample': 0.8816436062239197, 'num_leaves': 207, 'colsample_bytree': 0.9335445633937115, 'importance_type': 'gain', 'reg_alpha': 1.353185996589419, 'reg_lambda': 2.479657049618295}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:48:50,741] Trial 2 finished with value: 0.7083721384167071 and parameters: {'learning_rate': 0.08442755768582291, 'max_depth': 282, 'subsample': 0.4840867456236212, 'num_leaves': 65, 'colsample_bytree': 0.5522990235322709, 'importance_type': 'gain', 'reg_alpha': 2.4887722638695116, 'reg_lambda': 1.0902745333496076}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:48:59,040] Trial 3 finished with value: 0.7355925716367169 and parameters: {'learning_rate': 0.28654115022764237, 'max_depth': 265, 'subsample': 0.21125977294019438, 'num_leaves': 435, 'colsample_bytree': 0.9352485981368034, 'importance_type': 'split', 'reg_alpha': 0.39792439691096626, 'reg_lambda': 1.0343748360344427}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:49:21,756] Trial 4 finished with value: 0.722921084992715 and parameters: {'learning_rate': 0.014324818532816962, 'max_depth': 248, 'subsample': 0.024062993398165533, 'num_leaves': 618, 'colsample_bytree': 0.949567121050867, 'importance_type': 'split', 'reg_alpha': 0.2478532435818398, 'reg_lambda': 1.7272970603139202}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:49:35,008] Trial 5 finished with value: 0.7441808081593007 and parameters: {'learning_rate': 0.08090328220906594, 'max_depth': 365, 'subsample': 0.08298357378728516, 'num_leaves': 701, 'colsample_bytree': 0.9587875577893682, 'importance_type': 'gain', 'reg_alpha': 1.112086991592407, 'reg_lambda': 1.0872071268314045}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:49:52,696] Trial 6 finished with value: 0.726870410393395 and parameters: {'learning_rate': 0.014527792880417296, 'max_depth': 71, 'subsample': 0.6497441073532841, 'num_leaves': 771, 'colsample_bytree': 0.811779573751762, 'importance_type': 'split', 'reg_alpha': 2.5239367989235078, 'reg_lambda': 1.472749134155234}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:49:56,137] Trial 7 finished with value: 0.6955743642544925 and parameters: {'learning_rate': 0.019889626868304592, 'max_depth': 361, 'subsample': 0.4089324302800006, 'num_leaves': 128, 'colsample_bytree': 0.6690250120159187, 'importance_type': 'split', 'reg_alpha': 2.056319576965077, 'reg_lambda': 1.4486447839354075}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:06,641] Trial 8 finished with value: 0.7357110650801361 and parameters: {'learning_rate': 0.27643287814470746, 'max_depth': 427, 'subsample': 0.94314979762852, 'num_leaves': 771, 'colsample_bytree': 0.7572125329448869, 'importance_type': 'gain', 'reg_alpha': 0.6388584589285589, 'reg_lambda': 0.8067917665778337}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:11,630] Trial 9 finished with value: 0.7107160568237009 and parameters: {'learning_rate': 0.02333023723403631, 'max_depth': 374, 'subsample': 0.8527305633673785, 'num_leaves': 445, 'colsample_bytree': 0.15749818134108573, 'importance_type': 'gain', 'reg_alpha': 1.9126442603379115, 'reg_lambda': 2.530341587121796}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:14,467] Trial 10 finished with value: 0.6906492710053425 and parameters: {'learning_rate': 0.03579909578282767, 'max_depth': 3, 'subsample': 0.6792950738301919, 'num_leaves': 290, 'colsample_bytree': 0.3053807877369275, 'importance_type': 'gain', 'reg_alpha': 0.9186491479049685, 'reg_lambda': 0.02576236766078499}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:22,944] Trial 11 finished with value: 0.7431040529383196 and parameters: {'learning_rate': 0.09888293697267181, 'max_depth': 497, 'subsample': 0.010514197929749614, 'num_leaves': 583, 'colsample_bytree': 0.4744826222614977, 'importance_type': 'gain', 'reg_alpha': 1.200561285875346, 'reg_lambda': 2.9932165145355527}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:31,130] Trial 12 finished with value: 0.7443096522583779 and parameters: {'learning_rate': 0.16328197073392411, 'max_depth': 169, 'subsample': 0.2804742822428199, 'num_leaves': 616, 'colsample_bytree': 0.624681072964375, 'importance_type': 'gain', 'reg_alpha': 1.6870403309285078, 'reg_lambda': 0.42013234643723507}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:38,615] Trial 13 finished with value: 0.7422598285575522 and parameters: {'learning_rate': 0.15016462911170542, 'max_depth': 168, 'subsample': 0.30317620848621907, 'num_leaves': 514, 'colsample_bytree': 0.5046331211475712, 'importance_type': 'gain', 'reg_alpha': 1.7313431032096047, 'reg_lambda': 0.11128382766146222}. Best is trial 0 with value: 0.7445005235551239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:47,231] Trial 14 finished with value: 0.7450317576493444 and parameters: {'learning_rate': 0.15459647217502157, 'max_depth': 171, 'subsample': 0.6281427669695776, 'num_leaves': 619, 'colsample_bytree': 0.6207560346826999, 'importance_type': 'gain', 'reg_alpha': 2.859909442544021, 'reg_lambda': 2.086084711887949}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:50:52,851] Trial 15 finished with value: 0.7278688931520155 and parameters: {'learning_rate': 0.043833678020413484, 'max_depth': 169, 'subsample': 0.7001822375552493, 'num_leaves': 327, 'colsample_bytree': 0.400456916633546, 'importance_type': 'gain', 'reg_alpha': 2.9622978098428074, 'reg_lambda': 2.10493645667609}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:00,904] Trial 16 finished with value: 0.7349232127246237 and parameters: {'learning_rate': 0.3645545625343483, 'max_depth': 81, 'subsample': 0.7902534440885841, 'num_leaves': 536, 'colsample_bytree': 0.7392648929877188, 'importance_type': 'gain', 'reg_alpha': 2.273098290671275, 'reg_lambda': 2.1420212346185865}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:05,509] Trial 17 finished with value: 0.6589393244293347 and parameters: {'learning_rate': 0.2132723199083838, 'max_depth': 217, 'subsample': 0.5237307445733574, 'num_leaves': 675, 'colsample_bytree': 0.002855878442499016, 'importance_type': 'gain', 'reg_alpha': 0.01043760209855793, 'reg_lambda': 2.96398518681915}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:12,028] Trial 18 finished with value: 0.7336005823215153 and parameters: {'learning_rate': 0.04751577763542795, 'max_depth': 11, 'subsample': 0.9868912048124665, 'num_leaves': 478, 'colsample_bytree': 0.3064155641941854, 'importance_type': 'split', 'reg_alpha': 2.9078915227328084, 'reg_lambda': 1.963264369254617}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:18,510] Trial 19 finished with value: 0.7399621952404081 and parameters: {'learning_rate': 0.1265050512459846, 'max_depth': 125, 'subsample': 0.5650385767238235, 'num_leaves': 358, 'colsample_bytree': 0.8245682349422574, 'importance_type': 'gain', 'reg_alpha': 1.4757019152494129, 'reg_lambda': 2.548731906200985}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:27,227] Trial 20 finished with value: 0.7429199339485186 and parameters: {'learning_rate': 0.21526397202368097, 'max_depth': 203, 'subsample': 0.7538664884117114, 'num_leaves': 686, 'colsample_bytree': 0.6444652684193486, 'importance_type': 'gain', 'reg_alpha': 0.8369622704670292, 'reg_lambda': 2.339083041302789}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:35,203] Trial 21 finished with value: 0.742176468188441 and parameters: {'learning_rate': 0.18546216612322797, 'max_depth': 139, 'subsample': 0.34934734209915275, 'num_leaves': 612, 'colsample_bytree': 0.6071705975243877, 'importance_type': 'gain', 'reg_alpha': 1.6685979994723243, 'reg_lambda': 0.5606956955092549}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:45,811] Trial 22 finished with value: 0.7395368348712967 and parameters: {'learning_rate': 0.06312831396944733, 'max_depth': 308, 'subsample': 0.23466616005016663, 'num_leaves': 556, 'colsample_bytree': 0.712736638084068, 'importance_type': 'gain', 'reg_alpha': 2.158891981631297, 'reg_lambda': 2.74369250446768}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:51:54,494] Trial 23 finished with value: 0.7443954827586208 and parameters: {'learning_rate': 0.11450276412183671, 'max_depth': 191, 'subsample': 0.15998943984649663, 'num_leaves': 651, 'colsample_bytree': 0.5651474553347363, 'importance_type': 'gain', 'reg_alpha': 2.686735807403534, 'reg_lambda': 0.3685456058745382}. Best is trial 14 with value: 0.7450317576493444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:02,932] Trial 24 finished with value: 0.7459851733851384 and parameters: {'learning_rate': 0.10209757513913861, 'max_depth': 219, 'subsample': 0.14457987160083507, 'num_leaves': 716, 'colsample_bytree': 0.4121969555436103, 'importance_type': 'gain', 'reg_alpha': 2.460075757061116, 'reg_lambda': 1.8248180154426359}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:12,644] Trial 25 finished with value: 0.742231790675085 and parameters: {'learning_rate': 0.06383369816333963, 'max_depth': 115, 'subsample': 0.6290116590631643, 'num_leaves': 795, 'colsample_bytree': 0.4057887688511931, 'importance_type': 'gain', 'reg_alpha': 2.705046074691748, 'reg_lambda': 1.7631178390891018}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:19,513] Trial 26 finished with value: 0.7399893584264206 and parameters: {'learning_rate': 0.2726503053423, 'max_depth': 39, 'subsample': 0.4576750672743423, 'num_leaves': 729, 'colsample_bytree': 0.2651827294309943, 'importance_type': 'split', 'reg_alpha': 2.305611954301404, 'reg_lambda': 1.7370917840189648}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:25,422] Trial 27 finished with value: 0.7416018601262748 and parameters: {'learning_rate': 0.11456743496533306, 'max_depth': 240, 'subsample': 0.8157597760264419, 'num_leaves': 512, 'colsample_bytree': 0.4344461919858814, 'importance_type': 'gain', 'reg_alpha': 1.8992833746615174, 'reg_lambda': 2.2164651649829237}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:37,829] Trial 28 finished with value: 0.7442474856726566 and parameters: {'learning_rate': 0.07939126639140237, 'max_depth': 310, 'subsample': 0.5911723292189763, 'num_leaves': 740, 'colsample_bytree': 0.8089157241125188, 'importance_type': 'gain', 'reg_alpha': 2.747601044937203, 'reg_lambda': 1.933601296108982}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:47,751] Trial 29 finished with value: 0.7412007863040311 and parameters: {'learning_rate': 0.14579512900040945, 'max_depth': 99, 'subsample': 0.3920592007875555, 'num_leaves': 393, 'colsample_bytree': 0.8660338012981722, 'importance_type': 'gain', 'reg_alpha': 1.3721495670362973, 'reg_lambda': 2.7021439603250976}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:52:50,280] Trial 30 finished with value: 0.7339226376881982 and parameters: {'learning_rate': 0.20164035249342968, 'max_depth': 145, 'subsample': 0.7280381447117655, 'num_leaves': 239, 'colsample_bytree': 0.19357564123734006, 'importance_type': 'gain', 'reg_alpha': 2.4437163953809398, 'reg_lambda': 2.4280286485774547}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:02,538] Trial 31 finished with value: 0.7448276668285575 and parameters: {'learning_rate': 0.11207744449211068, 'max_depth': 195, 'subsample': 0.17740268620353983, 'num_leaves': 654, 'colsample_bytree': 0.5745455429193477, 'importance_type': 'gain', 'reg_alpha': 2.706341117940341, 'reg_lambda': 1.45194442412916}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:12,245] Trial 32 finished with value: 0.7442555934919863 and parameters: {'learning_rate': 0.0914225130957975, 'max_depth': 230, 'subsample': 0.14905872551975904, 'num_leaves': 654, 'colsample_bytree': 0.5521662674222704, 'importance_type': 'gain', 'reg_alpha': 2.8152903364128345, 'reg_lambda': 1.39756190534511}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:20,358] Trial 33 finished with value: 0.7317311243322001 and parameters: {'learning_rate': 0.39778405174079434, 'max_depth': 296, 'subsample': 0.10298639968411512, 'num_leaves': 583, 'colsample_bytree': 0.5262930326680849, 'importance_type': 'gain', 'reg_alpha': 2.5374271169274847, 'reg_lambda': 1.3329820250240971}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:33,996] Trial 34 finished with value: 0.7431994303059738 and parameters: {'learning_rate': 0.06565345403828902, 'max_depth': 269, 'subsample': 0.9013173249929997, 'num_leaves': 727, 'colsample_bytree': 0.7040774188278655, 'importance_type': 'gain', 'reg_alpha': 2.3380829407665855, 'reg_lambda': 1.6467031772435796}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:35,020] Trial 35 finished with value: 0.6725508237008258 and parameters: {'learning_rate': 0.12044343268285118, 'max_depth': 188, 'subsample': 0.23485157262020823, 'num_leaves': 13, 'colsample_bytree': 0.4648444920858772, 'importance_type': 'split', 'reg_alpha': 2.6273903082711403, 'reg_lambda': 1.9255727158869713}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:47,195] Trial 36 finished with value: 0.7445347037396794 and parameters: {'learning_rate': 0.1697129493876644, 'max_depth': 57, 'subsample': 0.16507167306658965, 'num_leaves': 640, 'colsample_bytree': 0.5836765709903673, 'importance_type': 'gain', 'reg_alpha': 2.051546119574553, 'reg_lambda': 1.3054141966568618}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:53:56,809] Trial 37 finished with value: 0.741501770762506 and parameters: {'learning_rate': 0.2393764226744722, 'max_depth': 40, 'subsample': 0.06635470600981987, 'num_leaves': 647, 'colsample_bytree': 0.3673883721748402, 'importance_type': 'gain', 'reg_alpha': 2.1001606720216284, 'reg_lambda': 1.2759387677164171}. Best is trial 24 with value: 0.7459851733851384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:54:10,073] Trial 38 finished with value: 0.7466070150558524 and parameters: {'learning_rate': 0.1694362716971237, 'max_depth': 62, 'subsample': 0.17772872852757055, 'num_leaves': 709, 'colsample_bytree': 0.5875893984025683, 'importance_type': 'split', 'reg_alpha': 2.965578927468924, 'reg_lambda': 0.8699301606120771}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:54:20,814] Trial 39 finished with value: 0.7461233477416221 and parameters: {'learning_rate': 0.10257751065549632, 'max_depth': 103, 'subsample': 0.3014194135949037, 'num_leaves': 711, 'colsample_bytree': 0.6692209600640445, 'importance_type': 'split', 'reg_alpha': 2.9774998962850177, 'reg_lambda': 0.7654227074174246}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:54:37,631] Trial 40 finished with value: 0.7443881505585236 and parameters: {'learning_rate': 0.07294838653008306, 'max_depth': 101, 'subsample': 0.3131084832628168, 'num_leaves': 791, 'colsample_bytree': 0.8661972237712356, 'importance_type': 'split', 'reg_alpha': 2.9897116367278347, 'reg_lambda': 0.8708018813680631}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:54:48,021] Trial 41 finished with value: 0.7459944662457503 and parameters: {'learning_rate': 0.100082078601528, 'max_depth': 143, 'subsample': 0.2017919983706656, 'num_leaves': 706, 'colsample_bytree': 0.6651883347204574, 'importance_type': 'split', 'reg_alpha': 2.827251063569198, 'reg_lambda': 1.13043625878231}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:55:04,154] Trial 42 finished with value: 0.7454896177756192 and parameters: {'learning_rate': 0.09422693023462406, 'max_depth': 150, 'subsample': 0.09861939015929033, 'num_leaves': 723, 'colsample_bytree': 0.6483946430597601, 'importance_type': 'split', 'reg_alpha': 2.837705650392069, 'reg_lambda': 0.9019981907884617}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:55:15,282] Trial 43 finished with value: 0.745310727051967 and parameters: {'learning_rate': 0.09764260494879565, 'max_depth': 145, 'subsample': 0.09817629894194088, 'num_leaves': 711, 'colsample_bytree': 0.6773315108543717, 'importance_type': 'split', 'reg_alpha': 2.998751394801294, 'reg_lambda': 0.9194975719842207}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:55:29,952] Trial 44 finished with value: 0.7407820529383196 and parameters: {'learning_rate': 0.05342885319935635, 'max_depth': 69, 'subsample': 0.04611381454135288, 'num_leaves': 751, 'colsample_bytree': 0.792636647510409, 'importance_type': 'split', 'reg_alpha': 2.511368329742392, 'reg_lambda': 0.6019655616597126}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:55:45,744] Trial 45 finished with value: 0.7449893637688199 and parameters: {'learning_rate': 0.09359056322950984, 'max_depth': 108, 'subsample': 0.2506925222237726, 'num_leaves': 705, 'colsample_bytree': 0.6534688834375253, 'importance_type': 'split', 'reg_alpha': 2.616261015625269, 'reg_lambda': 1.1224710067316854}. Best is trial 38 with value: 0.7466070150558524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:55:59,377] Trial 46 finished with value: 0.7477234429334628 and parameters: {'learning_rate': 0.1336967177565762, 'max_depth': 35, 'subsample': 0.12236059687192063, 'num_leaves': 766, 'colsample_bytree': 0.7619377128290068, 'importance_type': 'split', 'reg_alpha': 2.8124701852668563, 'reg_lambda': 0.7599592763984113}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:56:22,149] Trial 47 finished with value: 0.7214568300145702 and parameters: {'learning_rate': 0.010939674529832799, 'max_depth': 35, 'subsample': 0.19639501955559013, 'num_leaves': 754, 'colsample_bytree': 0.7434185712478898, 'importance_type': 'split', 'reg_alpha': 2.407348494070003, 'reg_lambda': 0.7232040829749331}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:56:36,598] Trial 48 finished with value: 0.7472656498300145 and parameters: {'learning_rate': 0.13608511671190376, 'max_depth': 76, 'subsample': 0.013120832211913847, 'num_leaves': 771, 'colsample_bytree': 0.9125085349513476, 'importance_type': 'split', 'reg_alpha': 2.8299049031279693, 'reg_lambda': 1.183878199618391}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:56:53,941] Trial 49 finished with value: 0.736642159786304 and parameters: {'learning_rate': 0.327362413535194, 'max_depth': 19, 'subsample': 0.03144190923054668, 'num_leaves': 794, 'colsample_bytree': 0.9902147098272249, 'importance_type': 'split', 'reg_alpha': 2.791021607828778, 'reg_lambda': 1.1656153717793507}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:57:07,539] Trial 50 finished with value: 0.7459462486644003 and parameters: {'learning_rate': 0.1780439416267637, 'max_depth': 77, 'subsample': 0.001579238220083365, 'num_leaves': 678, 'colsample_bytree': 0.9067865554719677, 'importance_type': 'split', 'reg_alpha': 2.8711162328141144, 'reg_lambda': 1.0205145834461342}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:57:19,458] Trial 51 finished with value: 0.747192435648373 and parameters: {'learning_rate': 0.13113698125333184, 'max_depth': 61, 'subsample': 0.12912419967343516, 'num_leaves': 765, 'colsample_bytree': 0.7671530362676896, 'importance_type': 'split', 'reg_alpha': 2.5991229221353827, 'reg_lambda': 1.582403093562154}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:57:35,891] Trial 52 finished with value: 0.7467194225352113 and parameters: {'learning_rate': 0.1353099353902294, 'max_depth': 88, 'subsample': 0.28112115157073714, 'num_leaves': 752, 'colsample_bytree': 0.9073880243509916, 'importance_type': 'split', 'reg_alpha': 2.5745109786981093, 'reg_lambda': 1.569615980073411}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:57:48,731] Trial 53 finished with value: 0.7462228479844584 and parameters: {'learning_rate': 0.128233091730904, 'max_depth': 58, 'subsample': 0.27661362540904355, 'num_leaves': 760, 'colsample_bytree': 0.9018247940224015, 'importance_type': 'split', 'reg_alpha': 2.5886904320898103, 'reg_lambda': 0.7123666114180023}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:58:05,616] Trial 54 finished with value: 0.7473726906265177 and parameters: {'learning_rate': 0.13497127228590672, 'max_depth': 67, 'subsample': 0.1242511721249481, 'num_leaves': 756, 'colsample_bytree': 0.9103085497395417, 'importance_type': 'split', 'reg_alpha': 2.593890397871896, 'reg_lambda': 1.6387144369466826}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:58:20,768] Trial 55 finished with value: 0.7467525439533754 and parameters: {'learning_rate': 0.14341351035961547, 'max_depth': 27, 'subsample': 0.054066567797296544, 'num_leaves': 779, 'colsample_bytree': 0.9742899732624718, 'importance_type': 'split', 'reg_alpha': 2.2140777820061768, 'reg_lambda': 1.563725286530025}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:58:38,176] Trial 56 finished with value: 0.746357610976202 and parameters: {'learning_rate': 0.13198449112216668, 'max_depth': 29, 'subsample': 0.06064218223469238, 'num_leaves': 769, 'colsample_bytree': 0.9962054353764795, 'importance_type': 'split', 'reg_alpha': 2.2511660316939697, 'reg_lambda': 1.662845096443852}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:58:43,333] Trial 57 finished with value: 0.7346086187469646 and parameters: {'learning_rate': 0.23728247852324388, 'max_depth': 86, 'subsample': 0.13534249255939482, 'num_leaves': 150, 'colsample_bytree': 0.9398522834176393, 'importance_type': 'split', 'reg_alpha': 1.8803590926980625, 'reg_lambda': 1.5885932629099073}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:58:51,105] Trial 58 finished with value: 0.7091295735794074 and parameters: {'learning_rate': 0.14841606907024582, 'max_depth': 2, 'subsample': 0.11339350813186798, 'num_leaves': 798, 'colsample_bytree': 0.8531817478330624, 'importance_type': 'split', 'reg_alpha': 2.3988889332906385, 'reg_lambda': 1.5639324092412712}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:59:09,826] Trial 59 finished with value: 0.7349485366682855 and parameters: {'learning_rate': 0.02920953361063616, 'max_depth': 45, 'subsample': 0.033596310067449425, 'num_leaves': 770, 'colsample_bytree': 0.9070326759502021, 'importance_type': 'split', 'reg_alpha': 2.1997349714853227, 'reg_lambda': 1.5285962928567685}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:59:23,109] Trial 60 finished with value: 0.7451025905779505 and parameters: {'learning_rate': 0.19604869141360504, 'max_depth': 23, 'subsample': 0.07253634306092349, 'num_leaves': 685, 'colsample_bytree': 0.7776071718787858, 'importance_type': 'split', 'reg_alpha': 2.603548199702168, 'reg_lambda': 1.2139833132117834}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:59:39,715] Trial 61 finished with value: 0.7462540417678485 and parameters: {'learning_rate': 0.16450796196524065, 'max_depth': 57, 'subsample': 0.12650208838727475, 'num_leaves': 799, 'colsample_bytree': 0.9720703150385822, 'importance_type': 'split', 'reg_alpha': 2.682689992581599, 'reg_lambda': 1.02550876697508}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:59:55,612] Trial 62 finished with value: 0.7468788465274405 and parameters: {'learning_rate': 0.13243217645013616, 'max_depth': 65, 'subsample': 0.1973450231306878, 'num_leaves': 783, 'colsample_bytree': 0.940836655288072, 'importance_type': 'split', 'reg_alpha': 2.513312588168045, 'reg_lambda': 1.8215307096980045}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:00:10,197] Trial 63 finished with value: 0.7472941393880524 and parameters: {'learning_rate': 0.13721673847032653, 'max_depth': 85, 'subsample': 0.21706323260807323, 'num_leaves': 748, 'colsample_bytree': 0.9451139170473181, 'importance_type': 'split', 'reg_alpha': 2.345954111838645, 'reg_lambda': 1.8555273609159972}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:00:26,832] Trial 64 finished with value: 0.7456163715395823 and parameters: {'learning_rate': 0.14496966661029895, 'max_depth': 123, 'subsample': 0.00912394443324939, 'num_leaves': 768, 'colsample_bytree': 0.9528858515019645, 'importance_type': 'split', 'reg_alpha': 2.021896261766165, 'reg_lambda': 1.8195338887524013}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:00:38,986] Trial 65 finished with value: 0.7446002166100049 and parameters: {'learning_rate': 0.08114516811197525, 'max_depth': 13, 'subsample': 0.07885769744576021, 'num_leaves': 736, 'colsample_bytree': 0.8309610951761908, 'importance_type': 'split', 'reg_alpha': 2.3000389093871565, 'reg_lambda': 2.0248121262604877}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:00:53,172] Trial 66 finished with value: 0.7429186537153958 and parameters: {'learning_rate': 0.24754483181160256, 'max_depth': 47, 'subsample': 0.21894180786652967, 'num_leaves': 776, 'colsample_bytree': 0.8761538106396098, 'importance_type': 'split', 'reg_alpha': 2.4598718684430216, 'reg_lambda': 1.883092791233003}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:01:07,188] Trial 67 finished with value: 0.7444980558523555 and parameters: {'learning_rate': 0.10908054747460824, 'max_depth': 447, 'subsample': 0.35442743752074674, 'num_leaves': 677, 'colsample_bytree': 0.9406260916360917, 'importance_type': 'split', 'reg_alpha': 2.373824151349869, 'reg_lambda': 1.3756007452022343}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:01:19,540] Trial 68 finished with value: 0.7414691976687713 and parameters: {'learning_rate': 0.2148507422557662, 'max_depth': 74, 'subsample': 0.12309132749110008, 'num_leaves': 619, 'colsample_bytree': 0.8388281232429013, 'importance_type': 'split', 'reg_alpha': 0.5665687454005917, 'reg_lambda': 2.2407575415158547}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:01:33,399] Trial 69 finished with value: 0.7440728606119476 and parameters: {'learning_rate': 0.12391878837971979, 'max_depth': 90, 'subsample': 0.050566722678158996, 'num_leaves': 740, 'colsample_bytree': 0.9697397206392658, 'importance_type': 'split', 'reg_alpha': 1.2061861800959526, 'reg_lambda': 0.2917440159282085}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:01:49,417] Trial 70 finished with value: 0.7457374273919377 and parameters: {'learning_rate': 0.15520469857051486, 'max_depth': 52, 'subsample': 0.19395372772071184, 'num_leaves': 772, 'colsample_bytree': 0.8883387970899688, 'importance_type': 'split', 'reg_alpha': 1.7733273171972577, 'reg_lambda': 1.739650830000712}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:02:04,757] Trial 71 finished with value: 0.746599824672171 and parameters: {'learning_rate': 0.13516717651410454, 'max_depth': 79, 'subsample': 0.2594424844761533, 'num_leaves': 744, 'colsample_bytree': 0.9212732180992753, 'importance_type': 'split', 'reg_alpha': 2.529318555488696, 'reg_lambda': 1.4726953111498744}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:02:19,057] Trial 72 finished with value: 0.7452935235551239 and parameters: {'learning_rate': 0.18430515834583722, 'max_depth': 124, 'subsample': 0.15037407780177736, 'num_leaves': 747, 'colsample_bytree': 0.9314205918616278, 'importance_type': 'split', 'reg_alpha': 2.7046081311950587, 'reg_lambda': 1.6342911421645343}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:02:32,378] Trial 73 finished with value: 0.7456702209810588 and parameters: {'learning_rate': 0.1414581959587952, 'max_depth': 32, 'subsample': 0.23223499480137572, 'num_leaves': 696, 'colsample_bytree': 0.765112279359228, 'importance_type': 'split', 'reg_alpha': 2.7667345026619383, 'reg_lambda': 2.0206198018695347}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:02:46,411] Trial 74 finished with value: 0.7458156779990286 and parameters: {'learning_rate': 0.11176770329857923, 'max_depth': 95, 'subsample': 0.4426788263305071, 'num_leaves': 800, 'colsample_bytree': 0.8022881100238047, 'importance_type': 'split', 'reg_alpha': 2.182508016172479, 'reg_lambda': 1.8596241142570629}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:02:59,790] Trial 75 finished with value: 0.7463327319086935 and parameters: {'learning_rate': 0.12407124115656945, 'max_depth': 68, 'subsample': 0.08294455748926183, 'num_leaves': 673, 'colsample_bytree': 0.9708608592623327, 'importance_type': 'split', 'reg_alpha': 2.5527393965763117, 'reg_lambda': 1.67097239286018}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:03:14,546] Trial 76 finished with value: 0.7450850830500243 and parameters: {'learning_rate': 0.08582300044236163, 'max_depth': 13, 'subsample': 0.16969836445747527, 'num_leaves': 776, 'colsample_bytree': 0.8790675664282617, 'importance_type': 'split', 'reg_alpha': 1.5864995850696542, 'reg_lambda': 1.4967906281949301}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:03:23,048] Trial 77 finished with value: 0.7436343108305002 and parameters: {'learning_rate': 0.15697642583572644, 'max_depth': 84, 'subsample': 0.3342439637385448, 'num_leaves': 448, 'colsample_bytree': 0.8381262677705397, 'importance_type': 'split', 'reg_alpha': 2.650975371435972, 'reg_lambda': 1.8029122698373263}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:03:39,280] Trial 78 finished with value: 0.7452963351141331 and parameters: {'learning_rate': 0.1920837467894107, 'max_depth': 114, 'subsample': 0.11540058297122804, 'num_leaves': 734, 'colsample_bytree': 0.9213957438558863, 'importance_type': 'split', 'reg_alpha': 2.903439663334405, 'reg_lambda': 1.6989100167174735}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:03:46,198] Trial 79 finished with value: 0.7373919305488101 and parameters: {'learning_rate': 0.13715199199544553, 'max_depth': 27, 'subsample': 0.034403926230006876, 'num_leaves': 274, 'colsample_bytree': 0.9920148828042694, 'importance_type': 'split', 'reg_alpha': 2.475453294662745, 'reg_lambda': 1.2629157183964488}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:04:00,389] Trial 80 finished with value: 0.7435891850412821 and parameters: {'learning_rate': 0.07641621487535759, 'max_depth': 44, 'subsample': 0.2128793122580559, 'num_leaves': 665, 'colsample_bytree': 0.9539829692152333, 'importance_type': 'split', 'reg_alpha': 1.991155506199176, 'reg_lambda': 1.3752719374777627}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:04:14,646] Trial 81 finished with value: 0.7443628858669257 and parameters: {'learning_rate': 0.1739487356554578, 'max_depth': 339, 'subsample': 0.18165143937324235, 'num_leaves': 722, 'colsample_bytree': 0.7228432478099132, 'importance_type': 'split', 'reg_alpha': 2.762230194948497, 'reg_lambda': 0.5902429837733034}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:04:28,291] Trial 82 finished with value: 0.7460545036425449 and parameters: {'learning_rate': 0.15650240706590626, 'max_depth': 68, 'subsample': 0.14412003316396055, 'num_leaves': 695, 'colsample_bytree': 0.8946087332920762, 'importance_type': 'split', 'reg_alpha': 2.893593546274576, 'reg_lambda': 0.9793863556179063}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.352998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:04:43,102] Trial 83 finished with value: 0.7474123496843128 and parameters: {'learning_rate': 0.1083607669934416, 'max_depth': 68, 'subsample': 0.2870493396195578, 'num_leaves': 778, 'colsample_bytree': 0.8652127918309914, 'importance_type': 'split', 'reg_alpha': 2.651996096999839, 'reg_lambda': 0.5005856682319367}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:04:58,934] Trial 84 finished with value: 0.7467950004856726 and parameters: {'learning_rate': 0.11432452587137613, 'max_depth': 132, 'subsample': 0.38135268463080696, 'num_leaves': 759, 'colsample_bytree': 0.7886207161414646, 'importance_type': 'split', 'reg_alpha': 2.5709076274128364, 'reg_lambda': 0.3569722905948348}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:05:12,752] Trial 85 finished with value: 0.7471602549781446 and parameters: {'learning_rate': 0.10710951389598354, 'max_depth': 158, 'subsample': 0.3900632339619506, 'num_leaves': 782, 'colsample_bytree': 0.7870196604892893, 'importance_type': 'split', 'reg_alpha': 2.32506745486508, 'reg_lambda': 0.15599443556879145}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:05:25,074] Trial 86 finished with value: 0.7427704108790675 and parameters: {'learning_rate': 0.07135061417615647, 'max_depth': 159, 'subsample': 0.5136228732827953, 'num_leaves': 761, 'colsample_bytree': 0.7864544341546179, 'importance_type': 'split', 'reg_alpha': 2.3793542059566737, 'reg_lambda': 0.11937511636948078}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:05:38,575] Trial 87 finished with value: 0.7455172059252064 and parameters: {'learning_rate': 0.10932327309090273, 'max_depth': 134, 'subsample': 0.3770200361304445, 'num_leaves': 723, 'colsample_bytree': 0.8166146737727803, 'importance_type': 'split', 'reg_alpha': 2.7232902389251303, 'reg_lambda': 0.4729907264056228}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:05:53,507] Trial 88 finished with value: 0.7414477911607578 and parameters: {'learning_rate': 0.05682677382143648, 'max_depth': 179, 'subsample': 0.43307814851029547, 'num_leaves': 756, 'colsample_bytree': 0.8541204684717929, 'importance_type': 'split', 'reg_alpha': 2.1092774805452197, 'reg_lambda': 0.23948772163268445}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.254308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:06:10,397] Trial 89 finished with value: 0.7447884249635746 and parameters: {'learning_rate': 0.08485060899854634, 'max_depth': 104, 'subsample': 0.47507132982779704, 'num_leaves': 782, 'colsample_bytree': 0.7552949010598177, 'importance_type': 'split', 'reg_alpha': 2.4907570769463714, 'reg_lambda': 0.14013656284577547}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:06:20,233] Trial 90 finished with value: 0.7441636075764935 and parameters: {'learning_rate': 0.1066758694097312, 'max_depth': 117, 'subsample': 0.3258066237810339, 'num_leaves': 588, 'colsample_bytree': 0.7216120248675506, 'importance_type': 'split', 'reg_alpha': 2.321539486776683, 'reg_lambda': 0.396235013503922}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:06:26,398] Trial 91 finished with value: 0.6602615794074793 and parameters: {'learning_rate': 0.11862905985561291, 'max_depth': 57, 'subsample': 0.5548762132969696, 'num_leaves': 784, 'colsample_bytree': 0.005705982255682085, 'importance_type': 'split', 'reg_alpha': 2.2329601050345573, 'reg_lambda': 0.050243825525945196}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:06:40,309] Trial 92 finished with value: 0.7473100670228268 and parameters: {'learning_rate': 0.12545354458642077, 'max_depth': 42, 'subsample': 0.29325671025467404, 'num_leaves': 726, 'colsample_bytree': 0.8561186488365925, 'importance_type': 'split', 'reg_alpha': 2.642816301831759, 'reg_lambda': 0.515630108699811}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:06:51,779] Trial 93 finished with value: 0.745725915007285 and parameters: {'learning_rate': 0.08911131039967446, 'max_depth': 78, 'subsample': 0.3951746406619856, 'num_leaves': 735, 'colsample_bytree': 0.6992045230626828, 'importance_type': 'split', 'reg_alpha': 2.650722528768538, 'reg_lambda': 0.4614955424846471}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:07:07,417] Trial 94 finished with value: 0.7456428508984945 and parameters: {'learning_rate': 0.12001257566971009, 'max_depth': 94, 'subsample': 0.2954850052025299, 'num_leaves': 711, 'colsample_bytree': 0.8551880049960537, 'importance_type': 'split', 'reg_alpha': 2.8112248789265886, 'reg_lambda': 0.30396929141099494}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:07:23,437] Trial 95 finished with value: 0.7472622316658573 and parameters: {'learning_rate': 0.10110584346340679, 'max_depth': 135, 'subsample': 0.255969654531537, 'num_leaves': 759, 'colsample_bytree': 0.822306483116916, 'importance_type': 'split', 'reg_alpha': 2.5727795588862636, 'reg_lambda': 0.2687518313108217}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:07:36,259] Trial 96 finished with value: 0.7437701748421565 and parameters: {'learning_rate': 0.09733479687093682, 'max_depth': 62, 'subsample': 0.2545133259659607, 'num_leaves': 634, 'colsample_bytree': 0.8166412135215573, 'importance_type': 'split', 'reg_alpha': 2.4356839008265303, 'reg_lambda': 0.2070127984772429}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:07:50,850] Trial 97 finished with value: 0.7461989922292374 and parameters: {'learning_rate': 0.10315429853674139, 'max_depth': 42, 'subsample': 0.279141295068069, 'num_leaves': 785, 'colsample_bytree': 0.8805192070223377, 'importance_type': 'split', 'reg_alpha': 2.646391976468001, 'reg_lambda': 0.523334020127781}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:08:04,062] Trial 98 finished with value: 0.7460467571636716 and parameters: {'learning_rate': 0.1306945618410161, 'max_depth': 160, 'subsample': 0.22356322827510997, 'num_leaves': 694, 'colsample_bytree': 0.8388529702345977, 'importance_type': 'split', 'reg_alpha': 2.8559308527482368, 'reg_lambda': 0.640782645646853}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:08:19,178] Trial 99 finished with value: 0.7456788834385624 and parameters: {'learning_rate': 0.16700042036872112, 'max_depth': 107, 'subsample': 0.3528607911653341, 'num_leaves': 730, 'colsample_bytree': 0.9289284505740667, 'importance_type': 'split', 'reg_alpha': 2.722226779532193, 'reg_lambda': 0.17077948438643542}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:08:32,073] Trial 100 finished with value: 0.7449948023312287 and parameters: {'learning_rate': 0.09248156125686284, 'max_depth': 68, 'subsample': 0.2534486517323637, 'num_leaves': 752, 'colsample_bytree': 0.7672867719332389, 'importance_type': 'split', 'reg_alpha': 2.9195388177108095, 'reg_lambda': 0.059947357865241746}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:08:46,137] Trial 101 finished with value: 0.7460857081107334 and parameters: {'learning_rate': 0.11347536952270004, 'max_depth': 47, 'subsample': 0.307826510201424, 'num_leaves': 758, 'colsample_bytree': 0.8023161821442645, 'importance_type': 'split', 'reg_alpha': 2.5701260002332194, 'reg_lambda': 0.33563523769227566}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:09:00,183] Trial 102 finished with value: 0.7469279864011655 and parameters: {'learning_rate': 0.1237204268432363, 'max_depth': 135, 'subsample': 0.4134057062807901, 'num_leaves': 800, 'colsample_bytree': 0.7426095221311992, 'importance_type': 'split', 'reg_alpha': 2.519916753579224, 'reg_lambda': 0.6712233704517365}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:09:14,085] Trial 103 finished with value: 0.7463069815444391 and parameters: {'learning_rate': 0.14504838304754267, 'max_depth': 208, 'subsample': 0.42092957396926595, 'num_leaves': 799, 'colsample_bytree': 0.7448982296232165, 'importance_type': 'split', 'reg_alpha': 2.504539896231626, 'reg_lambda': 0.8148853907027167}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:09:30,038] Trial 104 finished with value: 0.7471922486644001 and parameters: {'learning_rate': 0.1273373137222128, 'max_depth': 17, 'subsample': 0.19107267473423814, 'num_leaves': 782, 'colsample_bytree': 0.8683714246300258, 'importance_type': 'split', 'reg_alpha': 2.3390051005858057, 'reg_lambda': 0.6475750243920142}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:09:39,116] Trial 105 finished with value: 0.7301608654686742 and parameters: {'learning_rate': 0.12271192079150371, 'max_depth': 3, 'subsample': 0.3302492581047101, 'num_leaves': 772, 'colsample_bytree': 0.8630579738360851, 'importance_type': 'split', 'reg_alpha': 2.3802755430674956, 'reg_lambda': 0.6732311844300924}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:09:51,979] Trial 106 finished with value: 0.7451630874210782 and parameters: {'learning_rate': 0.10527951262666187, 'max_depth': 34, 'subsample': 0.16078931832366528, 'num_leaves': 740, 'colsample_bytree': 0.6968645420379905, 'importance_type': 'split', 'reg_alpha': 2.2956952698138706, 'reg_lambda': 0.523170739590552}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:10:09,130] Trial 107 finished with value: 0.7284770616804274 and parameters: {'learning_rate': 0.01833651491850282, 'max_depth': 20, 'subsample': 0.10201585262719085, 'num_leaves': 715, 'colsample_bytree': 0.8303834519256813, 'importance_type': 'split', 'reg_alpha': 2.756421143798164, 'reg_lambda': 0.41561713806306455}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:10:22,276] Trial 108 finished with value: 0.7429041408450704 and parameters: {'learning_rate': 0.15871146243970274, 'max_depth': 177, 'subsample': 0.2626413377457888, 'num_leaves': 784, 'colsample_bytree': 0.7762976999188629, 'importance_type': 'split', 'reg_alpha': 0.05263382016027007, 'reg_lambda': 0.723565813486476}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:10:37,029] Trial 109 finished with value: 0.7473119980573093 and parameters: {'learning_rate': 0.12753070741128822, 'max_depth': 157, 'subsample': 0.23342649693879042, 'num_leaves': 800, 'colsample_bytree': 0.8996221059752747, 'importance_type': 'split', 'reg_alpha': 2.620895974684458, 'reg_lambda': 0.7986428247769897}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.395701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:10:42,913] Trial 110 finished with value: 0.7299633215152987 and parameters: {'learning_rate': 0.10017527696222088, 'max_depth': 52, 'subsample': 0.23668172166803997, 'num_leaves': 171, 'colsample_bytree': 0.9054203861820078, 'importance_type': 'split', 'reg_alpha': 2.614317737424812, 'reg_lambda': 0.5525323865115351}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:10:57,308] Trial 111 finished with value: 0.7471468542982029 and parameters: {'learning_rate': 0.12637275934267117, 'max_depth': 253, 'subsample': 0.18449511912303057, 'num_leaves': 768, 'colsample_bytree': 0.886324097131228, 'importance_type': 'split', 'reg_alpha': 2.6750640558705294, 'reg_lambda': 0.796132975486534}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:11:11,492] Trial 112 finished with value: 0.7467637158814959 and parameters: {'learning_rate': 0.13613201756174434, 'max_depth': 249, 'subsample': 0.1836722398206947, 'num_leaves': 761, 'colsample_bytree': 0.8816631708854756, 'importance_type': 'split', 'reg_alpha': 2.680711795918534, 'reg_lambda': 0.9428444690994489}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:11:24,829] Trial 113 finished with value: 0.7443858499271492 and parameters: {'learning_rate': 0.1487933177252141, 'max_depth': 236, 'subsample': 0.21278653847493856, 'num_leaves': 727, 'colsample_bytree': 0.8588185955236542, 'importance_type': 'split', 'reg_alpha': 0.8923106872036286, 'reg_lambda': 0.7802998924468609}. Best is trial 46 with value: 0.7477234429334628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:11:39,481] Trial 114 finished with value: 0.7479804317629917 and parameters: {'learning_rate': 0.12826686804164245, 'max_depth': 266, 'subsample': 0.13261900435764695, 'num_leaves': 744, 'colsample_bytree': 0.8954232540253109, 'importance_type': 'split', 'reg_alpha': 2.8011518057281064, 'reg_lambda': 0.8477017685897223}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:11:55,823] Trial 115 finished with value: 0.7467791146187469 and parameters: {'learning_rate': 0.17890194013777455, 'max_depth': 278, 'subsample': 0.14546149184425358, 'num_leaves': 747, 'colsample_bytree': 0.9233030510845096, 'importance_type': 'split', 'reg_alpha': 2.8028322283225715, 'reg_lambda': 1.0512764167236606}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:12:08,988] Trial 116 finished with value: 0.7442826022340943 and parameters: {'learning_rate': 0.20591269474120236, 'max_depth': 291, 'subsample': 0.12756373068196256, 'num_leaves': 701, 'colsample_bytree': 0.8120830503787543, 'importance_type': 'split', 'reg_alpha': 2.917516226519618, 'reg_lambda': 0.4943907161706372}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:12:24,783] Trial 117 finished with value: 0.738087664885867 and parameters: {'learning_rate': 0.03971707925263697, 'max_depth': 225, 'subsample': 0.29028482678871453, 'num_leaves': 743, 'colsample_bytree': 0.9028728161471146, 'importance_type': 'split', 'reg_alpha': 2.7863310195692517, 'reg_lambda': 0.8353101440737661}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:12:41,437] Trial 118 finished with value: 0.7462305944633317 and parameters: {'learning_rate': 0.11596107714594102, 'max_depth': 12, 'subsample': 0.08715344227852027, 'num_leaves': 782, 'colsample_bytree': 0.9491950371438183, 'importance_type': 'split', 'reg_alpha': 2.6107503871152025, 'reg_lambda': 0.6474098477125134}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:12:49,112] Trial 119 finished with value: 0.7418168275862069 and parameters: {'learning_rate': 0.14194298894747392, 'max_depth': 258, 'subsample': 0.1656628340319403, 'num_leaves': 359, 'colsample_bytree': 0.8553397914541928, 'importance_type': 'split', 'reg_alpha': 2.4358950873270504, 'reg_lambda': 0.2630567924695478}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:13:02,509] Trial 120 finished with value: 0.7454326187469645 and parameters: {'learning_rate': 0.16353561791593058, 'max_depth': 32, 'subsample': 0.2432204271181199, 'num_leaves': 719, 'colsample_bytree': 0.8331170720425187, 'importance_type': 'split', 'reg_alpha': 2.857092761664153, 'reg_lambda': 0.7290243524721607}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:13:17,501] Trial 121 finished with value: 0.7458327955318115 and parameters: {'learning_rate': 0.13084263629932116, 'max_depth': 200, 'subsample': 0.1949176942988205, 'num_leaves': 764, 'colsample_bytree': 0.8763558840859939, 'importance_type': 'split', 'reg_alpha': 2.6849763273291134, 'reg_lambda': 0.8911267789668775}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:13:33,417] Trial 122 finished with value: 0.7472826702282662 and parameters: {'learning_rate': 0.1310869988034054, 'max_depth': 264, 'subsample': 0.27183649781842534, 'num_leaves': 772, 'colsample_bytree': 0.8896538986796088, 'importance_type': 'split', 'reg_alpha': 2.5745433689918826, 'reg_lambda': 0.8285142880569736}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:13:48,014] Trial 123 finished with value: 0.7464331015055852 and parameters: {'learning_rate': 0.15278180588348386, 'max_depth': 316, 'subsample': 0.2691941888064908, 'num_leaves': 775, 'colsample_bytree': 0.9166813119345233, 'importance_type': 'split', 'reg_alpha': 2.3504584779917614, 'reg_lambda': 0.615846930755718}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:14:04,280] Trial 124 finished with value: 0.7471337950461389 and parameters: {'learning_rate': 0.11683618502005964, 'max_depth': 266, 'subsample': 0.21613984611377204, 'num_leaves': 745, 'colsample_bytree': 0.9683576531842709, 'importance_type': 'split', 'reg_alpha': 2.744592186079622, 'reg_lambda': 0.9582577807529411}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:14:21,580] Trial 125 finished with value: 0.7472857372510928 and parameters: {'learning_rate': 0.10649752961265925, 'max_depth': 282, 'subsample': 0.3086169475771704, 'num_leaves': 789, 'colsample_bytree': 0.8931692745287025, 'importance_type': 'split', 'reg_alpha': 2.4518428600968383, 'reg_lambda': 0.8720645287032035}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:14:24,006] Trial 126 finished with value: 0.7158818003885381 and parameters: {'learning_rate': 0.09454060738048996, 'max_depth': 280, 'subsample': 0.23528332489825948, 'num_leaves': 75, 'colsample_bytree': 0.8915023111086818, 'importance_type': 'split', 'reg_alpha': 2.564898753772361, 'reg_lambda': 0.778218452424442}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:14:41,254] Trial 127 finished with value: 0.747344306945119 and parameters: {'learning_rate': 0.14010989279947947, 'max_depth': 296, 'subsample': 0.30953271839198543, 'num_leaves': 800, 'colsample_bytree': 0.9416105701202901, 'importance_type': 'split', 'reg_alpha': 2.439016469902144, 'reg_lambda': 1.1690832775885556}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:14:56,636] Trial 128 finished with value: 0.7465331379310345 and parameters: {'learning_rate': 0.13854817407054526, 'max_depth': 326, 'subsample': 0.3264525912748031, 'num_leaves': 799, 'colsample_bytree': 0.9428413160487341, 'importance_type': 'split', 'reg_alpha': 2.469296423750165, 'reg_lambda': 1.09039660893116}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:15:09,868] Trial 129 finished with value: 0.7459532598348714 and parameters: {'learning_rate': 0.17551286188404683, 'max_depth': 246, 'subsample': 0.31282993634915346, 'num_leaves': 687, 'colsample_bytree': 0.9870653296627176, 'importance_type': 'split', 'reg_alpha': 2.6410427458487593, 'reg_lambda': 1.4209114179332725}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:15:21,594] Trial 130 finished with value: 0.7423316765420107 and parameters: {'learning_rate': 0.10220939188996998, 'max_depth': 306, 'subsample': 0.36490095675465656, 'num_leaves': 504, 'colsample_bytree': 0.9193876426901693, 'importance_type': 'split', 'reg_alpha': 2.929711605586873, 'reg_lambda': 0.9947653752303816}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:15:35,890] Trial 131 finished with value: 0.7476470437105391 and parameters: {'learning_rate': 0.1278527586588863, 'max_depth': 296, 'subsample': 0.27954834775975357, 'num_leaves': 762, 'colsample_bytree': 0.8690223955723501, 'importance_type': 'split', 'reg_alpha': 2.4459973324182736, 'reg_lambda': 0.8545859710789672}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:15:49,829] Trial 132 finished with value: 0.7461457717338514 and parameters: {'learning_rate': 0.14987847854077502, 'max_depth': 287, 'subsample': 0.2887251263032297, 'num_leaves': 762, 'colsample_bytree': 0.8447724650119538, 'importance_type': 'split', 'reg_alpha': 2.438450163614214, 'reg_lambda': 0.8612728382506929}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:16:04,287] Trial 133 finished with value: 0.7466888470131132 and parameters: {'learning_rate': 0.13611292527781768, 'max_depth': 300, 'subsample': 0.27264557942314227, 'num_leaves': 739, 'colsample_bytree': 0.9100581415595678, 'importance_type': 'split', 'reg_alpha': 2.5507373830112248, 'reg_lambda': 1.2065380411266409}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:16:20,348] Trial 134 finished with value: 0.744834486644002 and parameters: {'learning_rate': 0.11036630675942877, 'max_depth': 269, 'subsample': 0.3068813204496492, 'num_leaves': 727, 'colsample_bytree': 0.9587377157844004, 'importance_type': 'split', 'reg_alpha': 2.5907181132592063, 'reg_lambda': 0.8940061077731056}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:16:35,354] Trial 135 finished with value: 0.7457915726080622 and parameters: {'learning_rate': 0.12293674859050725, 'max_depth': 331, 'subsample': 0.33527710030331664, 'num_leaves': 754, 'colsample_bytree': 0.9366727282325716, 'importance_type': 'split', 'reg_alpha': 2.7352313539825994, 'reg_lambda': 1.1465377864596595}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:16:52,062] Trial 136 finished with value: 0.7479768266148615 and parameters: {'learning_rate': 0.16237460322844088, 'max_depth': 350, 'subsample': 0.260442045528515, 'num_leaves': 799, 'colsample_bytree': 0.8938699230318983, 'importance_type': 'split', 'reg_alpha': 2.827726539850961, 'reg_lambda': 0.735619428344533}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:17:06,868] Trial 137 finished with value: 0.7453202792617776 and parameters: {'learning_rate': 0.18964426913853427, 'max_depth': 351, 'subsample': 0.2496465772513261, 'num_leaves': 790, 'colsample_bytree': 0.8980706688828822, 'importance_type': 'split', 'reg_alpha': 2.9621482589916197, 'reg_lambda': 0.734818164313829}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:17:21,959] Trial 138 finished with value: 0.7467249179213211 and parameters: {'learning_rate': 0.16349244685919467, 'max_depth': 416, 'subsample': 0.26849685862607, 'num_leaves': 799, 'colsample_bytree': 0.86834541457071, 'importance_type': 'split', 'reg_alpha': 2.503431606091343, 'reg_lambda': 1.0523219352313884}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:17:32,341] Trial 139 finished with value: 0.7440419485186984 and parameters: {'learning_rate': 0.14427417950366875, 'max_depth': 275, 'subsample': 0.2950157051959795, 'num_leaves': 561, 'colsample_bytree': 0.8972337022657342, 'importance_type': 'split', 'reg_alpha': 2.831211331673474, 'reg_lambda': 0.843564810920719}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:17:48,468] Trial 140 finished with value: 0.7447263661971831 and parameters: {'learning_rate': 0.22320545634516842, 'max_depth': 405, 'subsample': 0.34243690289276996, 'num_leaves': 772, 'colsample_bytree': 0.9554948343160106, 'importance_type': 'split', 'reg_alpha': 2.8066137133740003, 'reg_lambda': 0.9363129289209045}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:18:02,582] Trial 141 finished with value: 0.7469090641087907 and parameters: {'learning_rate': 0.1173425379721308, 'max_depth': 260, 'subsample': 0.22372035846553084, 'num_leaves': 761, 'colsample_bytree': 0.8205158625605979, 'importance_type': 'split', 'reg_alpha': 2.685790121711588, 'reg_lambda': 0.568319567305978}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:18:17,330] Trial 142 finished with value: 0.7463220383681399 and parameters: {'learning_rate': 0.13118275916858657, 'max_depth': 318, 'subsample': 0.31474010283046877, 'num_leaves': 787, 'colsample_bytree': 0.9318836819915454, 'importance_type': 'split', 'reg_alpha': 2.610332139152742, 'reg_lambda': 0.6937108949428464}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:18:31,474] Trial 143 finished with value: 0.7476117008256435 and parameters: {'learning_rate': 0.1549163518246418, 'max_depth': 355, 'subsample': 0.019911023218358623, 'num_leaves': 748, 'colsample_bytree': 0.8719204785629502, 'importance_type': 'split', 'reg_alpha': 2.750012039003223, 'reg_lambda': 1.6202139918344822}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:18:47,510] Trial 144 finished with value: 0.7474103584264207 and parameters: {'learning_rate': 0.1496716134321632, 'max_depth': 347, 'subsample': 0.056627471155990164, 'num_leaves': 744, 'colsample_bytree': 0.8825186608515679, 'importance_type': 'split', 'reg_alpha': 2.7351992271098755, 'reg_lambda': 0.778501792778459}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:19:02,134] Trial 145 finished with value: 0.7445660451675571 and parameters: {'learning_rate': 0.15575367234211662, 'max_depth': 370, 'subsample': 0.04152412486612684, 'num_leaves': 710, 'colsample_bytree': 0.9997482418333956, 'importance_type': 'split', 'reg_alpha': 2.8568885540677833, 'reg_lambda': 0.7616062429604139}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:19:16,156] Trial 146 finished with value: 0.7449814006799417 and parameters: {'learning_rate': 0.1807804015376605, 'max_depth': 382, 'subsample': 0.01496032539515178, 'num_leaves': 736, 'colsample_bytree': 0.8818976432450242, 'importance_type': 'split', 'reg_alpha': 2.8036930564715883, 'reg_lambda': 0.8396336111158975}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:19:31,012] Trial 147 finished with value: 0.7458930043710539 and parameters: {'learning_rate': 0.16809871820763497, 'max_depth': 377, 'subsample': 0.0038583135520179994, 'num_leaves': 774, 'colsample_bytree': 0.9256706311778203, 'importance_type': 'split', 'reg_alpha': 2.7444703256597998, 'reg_lambda': 1.7694100480739592}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.363988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:19:44,999] Trial 148 finished with value: 0.7469539650315689 and parameters: {'learning_rate': 0.1411270071904739, 'max_depth': 357, 'subsample': 0.05854954200213832, 'num_leaves': 744, 'colsample_bytree': 0.8482481828485111, 'importance_type': 'split', 'reg_alpha': 2.8793323425843647, 'reg_lambda': 1.0068851723913288}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:20:01,997] Trial 149 finished with value: 0.7473671670713938 and parameters: {'learning_rate': 0.1498786498038034, 'max_depth': 344, 'subsample': 0.0607992690356168, 'num_leaves': 800, 'colsample_bytree': 0.9766325670933165, 'importance_type': 'split', 'reg_alpha': 2.7086372398856686, 'reg_lambda': 0.9074690196064104}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:20:18,307] Trial 150 finished with value: 0.7464668309859155 and parameters: {'learning_rate': 0.15228954149732488, 'max_depth': 339, 'subsample': 0.0821273495405204, 'num_leaves': 790, 'colsample_bytree': 0.9517396897722211, 'importance_type': 'gain', 'reg_alpha': 2.665252850494236, 'reg_lambda': 0.9158351557972315}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:20:32,841] Trial 151 finished with value: 0.7456703637688198 and parameters: {'learning_rate': 0.19686564073978893, 'max_depth': 349, 'subsample': 0.022821677543104546, 'num_leaves': 775, 'colsample_bytree': 0.9098098730494121, 'importance_type': 'split', 'reg_alpha': 2.7410835155858093, 'reg_lambda': 0.7555126309818887}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:20:49,367] Trial 152 finished with value: 0.74723386838271 and parameters: {'learning_rate': 0.12670172452948453, 'max_depth': 290, 'subsample': 0.06059111396010211, 'num_leaves': 749, 'colsample_bytree': 0.9765131984259987, 'importance_type': 'split', 'reg_alpha': 2.7202841186689293, 'reg_lambda': 0.8151234498416691}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:21:02,754] Trial 153 finished with value: 0.7445901510441963 and parameters: {'learning_rate': 0.1411531254074767, 'max_depth': 393, 'subsample': 0.0750952606410101, 'num_leaves': 724, 'colsample_bytree': 0.8727172635607552, 'importance_type': 'split', 'reg_alpha': 2.4140333765196877, 'reg_lambda': 1.0993828836686392}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:21:17,540] Trial 154 finished with value: 0.7463669878581836 and parameters: {'learning_rate': 0.16143832498576777, 'max_depth': 342, 'subsample': 0.10625427010832379, 'num_leaves': 800, 'colsample_bytree': 0.8942686856759454, 'importance_type': 'split', 'reg_alpha': 2.985025834533344, 'reg_lambda': 0.8955879682477361}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:21:32,084] Trial 155 finished with value: 0.7455449922292375 and parameters: {'learning_rate': 0.14769338985217573, 'max_depth': 326, 'subsample': 0.03234212974332054, 'num_leaves': 770, 'colsample_bytree': 0.93596523524669, 'importance_type': 'split', 'reg_alpha': 2.645395466191038, 'reg_lambda': 0.6012548586357078}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:21:48,972] Trial 156 finished with value: 0.746534474016513 and parameters: {'learning_rate': 0.11885613695862747, 'max_depth': 355, 'subsample': 0.0011489765189790259, 'num_leaves': 753, 'colsample_bytree': 0.9750535048823288, 'importance_type': 'split', 'reg_alpha': 2.5285647658680137, 'reg_lambda': 0.9694887507748685}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:22:04,022] Trial 157 finished with value: 0.747334733851384 and parameters: {'learning_rate': 0.1340098740594165, 'max_depth': 301, 'subsample': 0.045977144688355676, 'num_leaves': 787, 'colsample_bytree': 0.9159553097954338, 'importance_type': 'split', 'reg_alpha': 2.7842334411066907, 'reg_lambda': 1.6252505566887523}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:22:15,919] Trial 158 finished with value: 0.7457896750849926 and parameters: {'learning_rate': 0.13266020575143878, 'max_depth': 303, 'subsample': 0.11744838869501684, 'num_leaves': 787, 'colsample_bytree': 0.3527704015823302, 'importance_type': 'split', 'reg_alpha': 2.8093213199485945, 'reg_lambda': 1.5265665715748902}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:22:27,887] Trial 159 finished with value: 0.7458327260806217 and parameters: {'learning_rate': 0.16754029615983662, 'max_depth': 314, 'subsample': 0.09661082036414995, 'num_leaves': 731, 'colsample_bytree': 0.8632710686934485, 'importance_type': 'split', 'reg_alpha': 2.4740156797263526, 'reg_lambda': 1.6066995454835475}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:22:45,636] Trial 160 finished with value: 0.7469747591063622 and parameters: {'learning_rate': 0.11111344559466213, 'max_depth': 296, 'subsample': 0.04596241731210405, 'num_leaves': 799, 'colsample_bytree': 0.9148867021072303, 'importance_type': 'split', 'reg_alpha': 2.6279697951230228, 'reg_lambda': 1.680481260251128}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:23:00,243] Trial 161 finished with value: 0.7473022559494902 and parameters: {'learning_rate': 0.1354521061825418, 'max_depth': 334, 'subsample': 0.06694814045560098, 'num_leaves': 778, 'colsample_bytree': 0.8929330221775813, 'importance_type': 'split', 'reg_alpha': 2.906432852097639, 'reg_lambda': 1.972842820603596}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:23:15,149] Trial 162 finished with value: 0.7469773482272948 and parameters: {'learning_rate': 0.1245275405546651, 'max_depth': 361, 'subsample': 0.06837001595952166, 'num_leaves': 781, 'colsample_bytree': 0.8475441272374363, 'importance_type': 'split', 'reg_alpha': 2.9012387995146325, 'reg_lambda': 1.9419734520587322}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:23:29,205] Trial 163 finished with value: 0.7475107799902865 and parameters: {'learning_rate': 0.1521634562563075, 'max_depth': 342, 'subsample': 0.09019664215783164, 'num_leaves': 763, 'colsample_bytree': 0.8938573776889058, 'importance_type': 'split', 'reg_alpha': 2.77543045321963, 'reg_lambda': 2.1499368188911}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:23:45,299] Trial 164 finished with value: 0.7474482850898494 and parameters: {'learning_rate': 0.14536338693466752, 'max_depth': 333, 'subsample': 0.09158606365224625, 'num_leaves': 760, 'colsample_bytree': 0.9389382704023143, 'importance_type': 'split', 'reg_alpha': 2.7701454551005122, 'reg_lambda': 2.1716494383566984}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:23:59,634] Trial 165 finished with value: 0.7464144239922292 and parameters: {'learning_rate': 0.1516989945087296, 'max_depth': 332, 'subsample': 0.09603438021093502, 'num_leaves': 751, 'colsample_bytree': 0.9585256982038687, 'importance_type': 'split', 'reg_alpha': 2.7724624568280514, 'reg_lambda': 2.290900082924715}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:24:15,889] Trial 166 finished with value: 0.7468410291403593 and parameters: {'learning_rate': 0.180201122955132, 'max_depth': 338, 'subsample': 0.13659664634814378, 'num_leaves': 711, 'colsample_bytree': 0.9315865256469017, 'importance_type': 'split', 'reg_alpha': 2.8638941306697268, 'reg_lambda': 2.1511626438764986}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:24:30,748] Trial 167 finished with value: 0.7453684963574552 and parameters: {'learning_rate': 0.15796482530122993, 'max_depth': 368, 'subsample': 0.05086456420157446, 'num_leaves': 761, 'colsample_bytree': 0.9413590401697348, 'importance_type': 'split', 'reg_alpha': 2.9186147795971795, 'reg_lambda': 2.0623590646101673}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:24:43,404] Trial 168 finished with value: 0.7471333020883925 and parameters: {'learning_rate': 0.14515909253759351, 'max_depth': 322, 'subsample': 0.07670772214815921, 'num_leaves': 735, 'colsample_bytree': 0.9169723822351638, 'importance_type': 'split', 'reg_alpha': 2.704337269615895, 'reg_lambda': 2.0127064416748643}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:24:57,123] Trial 169 finished with value: 0.7460856964545897 and parameters: {'learning_rate': 0.1712418855326553, 'max_depth': 387, 'subsample': 0.1152238631243349, 'num_leaves': 699, 'colsample_bytree': 0.8695695035956936, 'importance_type': 'split', 'reg_alpha': 2.7571924078235317, 'reg_lambda': 2.1406514095426283}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:25:12,600] Trial 170 finished with value: 0.7467198169014084 and parameters: {'learning_rate': 0.13905481378004164, 'max_depth': 347, 'subsample': 0.02871654339056225, 'num_leaves': 761, 'colsample_bytree': 0.9698852591748313, 'importance_type': 'split', 'reg_alpha': 2.8128858291962415, 'reg_lambda': 2.4340699455627925}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:25:29,522] Trial 171 finished with value: 0.7468935031568722 and parameters: {'learning_rate': 0.12304691418794866, 'max_depth': 310, 'subsample': 0.09337315998425375, 'num_leaves': 785, 'colsample_bytree': 0.8881258408092433, 'importance_type': 'split', 'reg_alpha': 2.694247661570884, 'reg_lambda': 1.8719542132540974}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:25:44,433] Trial 172 finished with value: 0.7467959723166586 and parameters: {'learning_rate': 0.13545728463533402, 'max_depth': 363, 'subsample': 0.06850333469994993, 'num_leaves': 782, 'colsample_bytree': 0.8993821882028091, 'importance_type': 'split', 'reg_alpha': 2.9954086872804258, 'reg_lambda': 2.1817121281788365}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:25:58,620] Trial 173 finished with value: 0.7464051136474016 and parameters: {'learning_rate': 0.15206658395950262, 'max_depth': 336, 'subsample': 0.1564790547790415, 'num_leaves': 748, 'colsample_bytree': 0.9099561183916282, 'importance_type': 'split', 'reg_alpha': 1.3962817634953746, 'reg_lambda': 2.2167563831298382}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:26:15,542] Trial 174 finished with value: 0.7477181665857213 and parameters: {'learning_rate': 0.11641840797062658, 'max_depth': 347, 'subsample': 0.1357515192305067, 'num_leaves': 800, 'colsample_bytree': 0.9485383203640101, 'importance_type': 'split', 'reg_alpha': 2.8696271597101735, 'reg_lambda': 2.356575360631339}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:26:31,638] Trial 175 finished with value: 0.7477433375424964 and parameters: {'learning_rate': 0.14010164653271856, 'max_depth': 344, 'subsample': 0.1462223400086849, 'num_leaves': 762, 'colsample_bytree': 0.9559463367258864, 'importance_type': 'split', 'reg_alpha': 2.8863634199266084, 'reg_lambda': 2.68779788993513}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:26:45,598] Trial 176 finished with value: 0.7473459358912093 and parameters: {'learning_rate': 0.11744792621367978, 'max_depth': 325, 'subsample': 0.11628997064718372, 'num_leaves': 798, 'colsample_bytree': 0.9900079748226553, 'importance_type': 'split', 'reg_alpha': 2.8662206944420023, 'reg_lambda': 2.0974588746419363}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:27:01,590] Trial 177 finished with value: 0.7445704749878582 and parameters: {'learning_rate': 0.11417871685432283, 'max_depth': 347, 'subsample': 0.131624789504115, 'num_leaves': 767, 'colsample_bytree': 0.9913508706928451, 'importance_type': 'split', 'reg_alpha': 1.029856966025452, 'reg_lambda': 2.6306391615724602}. Best is trial 114 with value: 0.7479804317629917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:27:19,565] Trial 178 finished with value: 0.7483657455075279 and parameters: {'learning_rate': 0.11903348377736542, 'max_depth': 323, 'subsample': 0.10992452825503304, 'num_leaves': 798, 'colsample_bytree': 0.9828576409353381, 'importance_type': 'gain', 'reg_alpha': 2.852218476148978, 'reg_lambda': 2.5563522897780744}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:27:35,557] Trial 179 finished with value: 0.7479170257406509 and parameters: {'learning_rate': 0.11751270331679206, 'max_depth': 325, 'subsample': 0.11166278468657745, 'num_leaves': 800, 'colsample_bytree': 0.9798132237973305, 'importance_type': 'gain', 'reg_alpha': 2.856027634634014, 'reg_lambda': 2.820684806851934}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:27:53,546] Trial 180 finished with value: 0.7477227566779989 and parameters: {'learning_rate': 0.11673726231017437, 'max_depth': 322, 'subsample': 0.11356921126815812, 'num_leaves': 798, 'colsample_bytree': 0.986447416613211, 'importance_type': 'gain', 'reg_alpha': 2.851723377846738, 'reg_lambda': 2.8636584813994226}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:28:09,797] Trial 181 finished with value: 0.747556851384167 and parameters: {'learning_rate': 0.11729353349838106, 'max_depth': 321, 'subsample': 0.1093183120358927, 'num_leaves': 798, 'colsample_bytree': 0.9810458501063344, 'importance_type': 'gain', 'reg_alpha': 2.8645668357521052, 'reg_lambda': 2.9074648561907934}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:28:26,407] Trial 182 finished with value: 0.7476245774647887 and parameters: {'learning_rate': 0.11142490073897486, 'max_depth': 325, 'subsample': 0.11899646075299336, 'num_leaves': 797, 'colsample_bytree': 0.9924328295632595, 'importance_type': 'gain', 'reg_alpha': 2.8640613708383156, 'reg_lambda': 2.8867763695959416}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:28:44,351] Trial 183 finished with value: 0.7464387056823701 and parameters: {'learning_rate': 0.10597261093814624, 'max_depth': 322, 'subsample': 0.11311063595327912, 'num_leaves': 771, 'colsample_bytree': 0.9992691425026318, 'importance_type': 'gain', 'reg_alpha': 2.858537581916611, 'reg_lambda': 2.8652512859083306}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:29:02,400] Trial 184 finished with value: 0.7467945080135989 and parameters: {'learning_rate': 0.09610558997342022, 'max_depth': 329, 'subsample': 0.13260921345818555, 'num_leaves': 798, 'colsample_bytree': 0.9813634092218293, 'importance_type': 'gain', 'reg_alpha': 2.9220416909861995, 'reg_lambda': 2.8945313275538416}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:29:19,433] Trial 185 finished with value: 0.7462962039825157 and parameters: {'learning_rate': 0.11566876661037362, 'max_depth': 315, 'subsample': 0.164081546172583, 'num_leaves': 772, 'colsample_bytree': 0.9678004721557814, 'importance_type': 'gain', 'reg_alpha': 2.943222455670803, 'reg_lambda': 2.7627987495199497}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:29:35,677] Trial 186 finished with value: 0.7463692316658572 and parameters: {'learning_rate': 0.08789468977897527, 'max_depth': 345, 'subsample': 0.1483131979295936, 'num_leaves': 800, 'colsample_bytree': 0.9816190989896161, 'importance_type': 'gain', 'reg_alpha': 2.848899020824477, 'reg_lambda': 2.9585071109803964}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:29:52,737] Trial 187 finished with value: 0.7474804628460417 and parameters: {'learning_rate': 0.11103860439852038, 'max_depth': 357, 'subsample': 0.112698255765211, 'num_leaves': 758, 'colsample_bytree': 0.957848392682601, 'importance_type': 'gain', 'reg_alpha': 2.877926309362269, 'reg_lambda': 2.7744377521068295}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:30:07,554] Trial 188 finished with value: 0.7458186245750364 and parameters: {'learning_rate': 0.10749954411152973, 'max_depth': 359, 'subsample': 0.09524583515846588, 'num_leaves': 756, 'colsample_bytree': 0.9637047128235696, 'importance_type': 'gain', 'reg_alpha': 2.963699860558264, 'reg_lambda': 2.7883920140675444}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:30:24,698] Trial 189 finished with value: 0.7472776551724138 and parameters: {'learning_rate': 0.1199423464813966, 'max_depth': 374, 'subsample': 0.13544820156141082, 'num_leaves': 778, 'colsample_bytree': 0.955066917815971, 'importance_type': 'gain', 'reg_alpha': 2.797451285095663, 'reg_lambda': 2.6346088319751306}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:30:39,676] Trial 190 finished with value: 0.745885219038368 and parameters: {'learning_rate': 0.0948607363144821, 'max_depth': 352, 'subsample': 0.10158998467820272, 'num_leaves': 760, 'colsample_bytree': 0.9984978670973664, 'importance_type': 'gain', 'reg_alpha': 2.8836493633463225, 'reg_lambda': 2.533031076917277}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:30:57,265] Trial 191 finished with value: 0.7471515648372997 and parameters: {'learning_rate': 0.11225980264546895, 'max_depth': 326, 'subsample': 0.11366566742321663, 'num_leaves': 785, 'colsample_bytree': 0.9753743955142212, 'importance_type': 'gain', 'reg_alpha': 2.8346043213386194, 'reg_lambda': 2.8141809287881943}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:31:15,234] Trial 192 finished with value: 0.7480151559009227 and parameters: {'learning_rate': 0.12434573111858423, 'max_depth': 340, 'subsample': 0.1482955117782183, 'num_leaves': 800, 'colsample_bytree': 0.9972155819534907, 'importance_type': 'gain', 'reg_alpha': 2.8791593055704516, 'reg_lambda': 2.671477561515884}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:31:30,166] Trial 193 finished with value: 0.7482627251092763 and parameters: {'learning_rate': 0.1248222140588219, 'max_depth': 342, 'subsample': 0.15637472106722222, 'num_leaves': 770, 'colsample_bytree': 0.9584382634502805, 'importance_type': 'gain', 'reg_alpha': 2.996678048164567, 'reg_lambda': 2.908990942379789}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:31:46,626] Trial 194 finished with value: 0.7475910660514813 and parameters: {'learning_rate': 0.12276890884633312, 'max_depth': 336, 'subsample': 0.15175322647928324, 'num_leaves': 748, 'colsample_bytree': 0.9542553379011025, 'importance_type': 'gain', 'reg_alpha': 2.9948878524796143, 'reg_lambda': 2.6897013147899984}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:31:55,796] Trial 195 finished with value: 0.7420150393394851 and parameters: {'learning_rate': 0.10618282953088688, 'max_depth': 336, 'subsample': 0.17748216396713717, 'num_leaves': 427, 'colsample_bytree': 0.949678712172475, 'importance_type': 'gain', 'reg_alpha': 2.9706283552168276, 'reg_lambda': 2.716038964064353}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:32:12,715] Trial 196 finished with value: 0.7459011724137931 and parameters: {'learning_rate': 0.1008943991962781, 'max_depth': 361, 'subsample': 0.15478735193966925, 'num_leaves': 741, 'colsample_bytree': 0.957252574836746, 'importance_type': 'gain', 'reg_alpha': 2.9961777738799347, 'reg_lambda': 2.9881686342626987}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:32:27,391] Trial 197 finished with value: 0.7470771024769305 and parameters: {'learning_rate': 0.12492375394775197, 'max_depth': 314, 'subsample': 0.1349236067511683, 'num_leaves': 768, 'colsample_bytree': 0.9977043848213479, 'importance_type': 'gain', 'reg_alpha': 2.928108038880446, 'reg_lambda': 2.6801056838259774}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:32:42,682] Trial 198 finished with value: 0.7472056192326373 and parameters: {'learning_rate': 0.11973106962052728, 'max_depth': 344, 'subsample': 0.16472743302172765, 'num_leaves': 749, 'colsample_bytree': 0.9633769023832657, 'importance_type': 'gain', 'reg_alpha': 2.898247708441471, 'reg_lambda': 2.8602808252384624}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:32:59,986] Trial 199 finished with value: 0.7467810383681399 and parameters: {'learning_rate': 0.10898935725258799, 'max_depth': 355, 'subsample': 0.08598727996452671, 'num_leaves': 780, 'colsample_bytree': 0.9374104039514687, 'importance_type': 'gain', 'reg_alpha': 2.857590109665026, 'reg_lambda': 2.899324520032917}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:33:15,740] Trial 200 finished with value: 0.7478236542010684 and parameters: {'learning_rate': 0.12736197209265618, 'max_depth': 368, 'subsample': 0.14143087220755354, 'num_leaves': 764, 'colsample_bytree': 0.9780446779523382, 'importance_type': 'gain', 'reg_alpha': 2.9442631744334715, 'reg_lambda': 2.5836068658849967}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:33:32,943] Trial 201 finished with value: 0.7481406517727052 and parameters: {'learning_rate': 0.12820297528021016, 'max_depth': 370, 'subsample': 0.1433184804494344, 'num_leaves': 763, 'colsample_bytree': 0.978936962700136, 'importance_type': 'gain', 'reg_alpha': 2.9905364674437944, 'reg_lambda': 2.470966445811978}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:33:48,546] Trial 202 finished with value: 0.7464820728508985 and parameters: {'learning_rate': 0.12642406422567834, 'max_depth': 371, 'subsample': 0.14795630194690618, 'num_leaves': 764, 'colsample_bytree': 0.980054937965346, 'importance_type': 'gain', 'reg_alpha': 2.993400337237689, 'reg_lambda': 2.4713968716610966}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:34:06,459] Trial 203 finished with value: 0.7471352360369112 and parameters: {'learning_rate': 0.11550038364261338, 'max_depth': 394, 'subsample': 0.1266996209581946, 'num_leaves': 777, 'colsample_bytree': 0.9972268162600808, 'importance_type': 'gain', 'reg_alpha': 2.938447057628768, 'reg_lambda': 2.5888904223517866}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:34:24,383] Trial 204 finished with value: 0.7472596828557552 and parameters: {'learning_rate': 0.12995876084542174, 'max_depth': 366, 'subsample': 0.17680377644562853, 'num_leaves': 785, 'colsample_bytree': 0.9658616652457698, 'importance_type': 'gain', 'reg_alpha': 2.9162969077239307, 'reg_lambda': 2.3552779408667033}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:34:41,560] Trial 205 finished with value: 0.7475283176299174 and parameters: {'learning_rate': 0.11936747412556281, 'max_depth': 332, 'subsample': 0.14240891930603256, 'num_leaves': 764, 'colsample_bytree': 0.9513543618019363, 'importance_type': 'gain', 'reg_alpha': 2.837487371962582, 'reg_lambda': 2.81977752045737}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:34:55,420] Trial 206 finished with value: 0.7469423491986401 and parameters: {'learning_rate': 0.12138011429954942, 'max_depth': 334, 'subsample': 0.14754357798200107, 'num_leaves': 722, 'colsample_bytree': 0.9451039073614143, 'importance_type': 'gain', 'reg_alpha': 2.996581949703689, 'reg_lambda': 2.6888022536984333}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:35:12,634] Trial 207 finished with value: 0.7472994973288003 and parameters: {'learning_rate': 0.12863408121708517, 'max_depth': 321, 'subsample': 0.11306127370000163, 'num_leaves': 762, 'colsample_bytree': 0.9793132461054896, 'importance_type': 'gain', 'reg_alpha': 2.83058585310726, 'reg_lambda': 2.816583125738445}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:35:27,571] Trial 208 finished with value: 0.7458093593977659 and parameters: {'learning_rate': 0.09953236538972866, 'max_depth': 307, 'subsample': 0.1665352284727152, 'num_leaves': 734, 'colsample_bytree': 0.9586414505966213, 'importance_type': 'gain', 'reg_alpha': 2.889917494332537, 'reg_lambda': 2.562338829918732}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:35:42,667] Trial 209 finished with value: 0.7467696274890723 and parameters: {'learning_rate': 0.11355726794486248, 'max_depth': 353, 'subsample': 0.13810819401417623, 'num_leaves': 754, 'colsample_bytree': 0.9358616288296392, 'importance_type': 'gain', 'reg_alpha': 2.7946927500446894, 'reg_lambda': 2.930635251742569}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:36:05,320] Trial 210 finished with value: 0.7365490038853812 and parameters: {'learning_rate': 0.03185947308155339, 'max_depth': 330, 'subsample': 0.1936528492989107, 'num_leaves': 784, 'colsample_bytree': 0.9981162289015988, 'importance_type': 'gain', 'reg_alpha': 2.9502158006825736, 'reg_lambda': 2.7406000746901853}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:36:20,762] Trial 211 finished with value: 0.7465617022826615 and parameters: {'learning_rate': 0.10760485956995576, 'max_depth': 344, 'subsample': 0.10580528442179173, 'num_leaves': 766, 'colsample_bytree': 0.9722227991940507, 'importance_type': 'gain', 'reg_alpha': 2.8486353466273524, 'reg_lambda': 2.362535174489305}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:36:38,025] Trial 212 finished with value: 0.7471860913064594 and parameters: {'learning_rate': 0.11902570430345616, 'max_depth': 339, 'subsample': 0.12827694752130006, 'num_leaves': 785, 'colsample_bytree': 0.9511718274385945, 'importance_type': 'gain', 'reg_alpha': 2.9015362540383807, 'reg_lambda': 2.833341069163399}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:36:52,852] Trial 213 finished with value: 0.7468117435648374 and parameters: {'learning_rate': 0.1407558974425695, 'max_depth': 360, 'subsample': 0.15357461684569146, 'num_leaves': 771, 'colsample_bytree': 0.9290464570916552, 'importance_type': 'gain', 'reg_alpha': 2.789148251476901, 'reg_lambda': 2.6795148271191493}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:37:10,748] Trial 214 finished with value: 0.7470899800874211 and parameters: {'learning_rate': 0.12704006655018088, 'max_depth': 318, 'subsample': 0.09254531007314577, 'num_leaves': 799, 'colsample_bytree': 0.9791076438833404, 'importance_type': 'gain', 'reg_alpha': 2.8408767507925337, 'reg_lambda': 2.4893940349556694}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:37:25,553] Trial 215 finished with value: 0.7465533890237979 and parameters: {'learning_rate': 0.11221209884713461, 'max_depth': 373, 'subsample': 0.12203548447520618, 'num_leaves': 744, 'colsample_bytree': 0.9559080294907428, 'importance_type': 'gain', 'reg_alpha': 2.999558332377965, 'reg_lambda': 2.6167931987684576}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:37:42,546] Trial 216 finished with value: 0.7474639796017484 and parameters: {'learning_rate': 0.13399244361542212, 'max_depth': 331, 'subsample': 0.17354012346824155, 'num_leaves': 771, 'colsample_bytree': 0.999043530848376, 'importance_type': 'gain', 'reg_alpha': 2.763456941139753, 'reg_lambda': 2.7616300616853215}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:37:57,482] Trial 217 finished with value: 0.7472693205439533 and parameters: {'learning_rate': 0.1399239000553306, 'max_depth': 330, 'subsample': 0.17108340235294747, 'num_leaves': 761, 'colsample_bytree': 0.973609787722174, 'importance_type': 'gain', 'reg_alpha': 2.9330877627004193, 'reg_lambda': 2.7686110137677318}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:38:07,458] Trial 218 finished with value: 0.696757616804274 and parameters: {'learning_rate': 0.0105318434958353, 'max_depth': 337, 'subsample': 0.1615867049101371, 'num_leaves': 265, 'colsample_bytree': 0.9886693958730071, 'importance_type': 'gain', 'reg_alpha': 2.7732866838661234, 'reg_lambda': 2.9217787891271043}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:38:24,558] Trial 219 finished with value: 0.7472140165128702 and parameters: {'learning_rate': 0.13180228672583522, 'max_depth': 383, 'subsample': 0.14227813554194205, 'num_leaves': 800, 'colsample_bytree': 0.9512204525585575, 'importance_type': 'gain', 'reg_alpha': 2.874134720384278, 'reg_lambda': 2.7459265549891767}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:38:39,059] Trial 220 finished with value: 0.7467683370568237 and parameters: {'learning_rate': 0.1455778549339016, 'max_depth': 352, 'subsample': 0.11063471217746007, 'num_leaves': 739, 'colsample_bytree': 0.9339472246775229, 'importance_type': 'gain', 'reg_alpha': 2.80554232475221, 'reg_lambda': 2.85463404542068}. Best is trial 178 with value: 0.7483657455075279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:38:54,049] Trial 221 finished with value: 0.7484043895094706 and parameters: {'learning_rate': 0.12072533507128125, 'max_depth': 322, 'subsample': 0.20103680279366487, 'num_leaves': 777, 'colsample_bytree': 0.9800370749299788, 'importance_type': 'gain', 'reg_alpha': 2.7687778812016988, 'reg_lambda': 2.660860028179539}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:39:10,810] Trial 222 finished with value: 0.747208192326372 and parameters: {'learning_rate': 0.12353747538059336, 'max_depth': 308, 'subsample': 0.20882848974282908, 'num_leaves': 783, 'colsample_bytree': 0.9799037919804205, 'importance_type': 'gain', 'reg_alpha': 2.8832321491207384, 'reg_lambda': 2.5420114533286373}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:39:27,610] Trial 223 finished with value: 0.7466954375910636 and parameters: {'learning_rate': 0.13385327217225373, 'max_depth': 322, 'subsample': 0.17926744782580964, 'num_leaves': 768, 'colsample_bytree': 0.999296139325032, 'importance_type': 'gain', 'reg_alpha': 2.7525141296004643, 'reg_lambda': 2.670857740659128}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:39:42,315] Trial 224 finished with value: 0.7469668635259835 and parameters: {'learning_rate': 0.11987153969790802, 'max_depth': 337, 'subsample': 0.14349920285923873, 'num_leaves': 753, 'colsample_bytree': 0.9634697167866554, 'importance_type': 'gain', 'reg_alpha': 2.932109194560097, 'reg_lambda': 2.8068681529475006}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:40:00,089] Trial 225 finished with value: 0.7466451534725594 and parameters: {'learning_rate': 0.15708071631467907, 'max_depth': 328, 'subsample': 0.19702097925940104, 'num_leaves': 785, 'colsample_bytree': 0.97927442844412, 'importance_type': 'gain', 'reg_alpha': 2.825765947922087, 'reg_lambda': 2.6023399839124446}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:40:15,277] Trial 226 finished with value: 0.7469843559980573 and parameters: {'learning_rate': 0.13139634166875414, 'max_depth': 315, 'subsample': 0.12606431042710414, 'num_leaves': 772, 'colsample_bytree': 0.9516057130367659, 'importance_type': 'gain', 'reg_alpha': 2.7633126401905455, 'reg_lambda': 2.4126798457826792}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:40:23,257] Trial 227 finished with value: 0.7437237872753764 and parameters: {'learning_rate': 0.11735813058683903, 'max_depth': 348, 'subsample': 0.0887400628073888, 'num_leaves': 786, 'colsample_bytree': 0.16853670462999548, 'importance_type': 'gain', 'reg_alpha': 2.9312471532714155, 'reg_lambda': 2.729616537626498}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:40:35,437] Trial 228 finished with value: 0.7467224288489558 and parameters: {'learning_rate': 0.1434740609213074, 'max_depth': 464, 'subsample': 0.15405665470288063, 'num_leaves': 753, 'colsample_bytree': 0.6182726352493887, 'importance_type': 'gain', 'reg_alpha': 2.863878510768666, 'reg_lambda': 2.889778521240893}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:40:47,649] Trial 229 finished with value: 0.7451682661486159 and parameters: {'learning_rate': 0.10397828247633438, 'max_depth': 365, 'subsample': 0.6536686581542698, 'num_leaves': 726, 'colsample_bytree': 0.49843824329180764, 'importance_type': 'gain', 'reg_alpha': 0.6286180440187602, 'reg_lambda': 2.4886911468446353}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:41:02,691] Trial 230 finished with value: 0.747417117532783 and parameters: {'learning_rate': 0.12553241993282083, 'max_depth': 341, 'subsample': 0.11713109272341106, 'num_leaves': 774, 'colsample_bytree': 0.9987551950263116, 'importance_type': 'gain', 'reg_alpha': 2.795179977541793, 'reg_lambda': 2.6550615847478474}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:41:18,749] Trial 231 finished with value: 0.7467060150558524 and parameters: {'learning_rate': 0.1257842335565141, 'max_depth': 341, 'subsample': 0.10887638210347847, 'num_leaves': 771, 'colsample_bytree': 0.9837661393397364, 'importance_type': 'gain', 'reg_alpha': 2.822942539645643, 'reg_lambda': 2.6388450392304863}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:41:36,648] Trial 232 finished with value: 0.7470178139873725 and parameters: {'learning_rate': 0.11778228253525141, 'max_depth': 355, 'subsample': 0.12691171301316545, 'num_leaves': 788, 'colsample_bytree': 0.9998223058990338, 'importance_type': 'gain', 'reg_alpha': 2.725462190100732, 'reg_lambda': 2.7794134534458426}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:41:51,887] Trial 233 finished with value: 0.7390712248664401 and parameters: {'learning_rate': 0.30106913285895603, 'max_depth': 322, 'subsample': 0.1429607165464171, 'num_leaves': 800, 'colsample_bytree': 0.9641366675963352, 'importance_type': 'gain', 'reg_alpha': 2.8880933383952048, 'reg_lambda': 2.6803948745772748}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:42:08,495] Trial 234 finished with value: 0.7467747945604664 and parameters: {'learning_rate': 0.1363706407933931, 'max_depth': 336, 'subsample': 0.09156138426278007, 'num_leaves': 759, 'colsample_bytree': 0.9984687265403954, 'importance_type': 'gain', 'reg_alpha': 2.78011807413701, 'reg_lambda': 2.555039380595428}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:42:24,354] Trial 235 finished with value: 0.7476358067022826 and parameters: {'learning_rate': 0.112850867864136, 'max_depth': 328, 'subsample': 0.11570671494227586, 'num_leaves': 775, 'colsample_bytree': 0.9321674962714805, 'importance_type': 'gain', 'reg_alpha': 2.94861036565205, 'reg_lambda': 2.94213818770647}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:42:40,644] Trial 236 finished with value: 0.7470341699854297 and parameters: {'learning_rate': 0.1114401101227144, 'max_depth': 310, 'subsample': 0.16916532094662481, 'num_leaves': 743, 'colsample_bytree': 0.9265070065421007, 'importance_type': 'gain', 'reg_alpha': 2.9499471719260573, 'reg_lambda': 2.986365935763036}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:42:57,893] Trial 237 finished with value: 0.7471796435162701 and parameters: {'learning_rate': 0.10388157922696792, 'max_depth': 329, 'subsample': 0.18510328036860968, 'num_leaves': 784, 'colsample_bytree': 0.9405512684136202, 'importance_type': 'gain', 'reg_alpha': 2.9408543108716825, 'reg_lambda': 2.9189377600506314}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:43:13,557] Trial 238 finished with value: 0.7475252933462846 and parameters: {'learning_rate': 0.1128612498289706, 'max_depth': 349, 'subsample': 0.1376612043413293, 'num_leaves': 763, 'colsample_bytree': 0.962170762240658, 'importance_type': 'gain', 'reg_alpha': 2.9911153303347353, 'reg_lambda': 2.8324086783630182}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:43:28,235] Trial 239 finished with value: 0.747310630888781 and parameters: {'learning_rate': 0.11251586772683825, 'max_depth': 353, 'subsample': 0.1487868665951053, 'num_leaves': 772, 'colsample_bytree': 0.9599662746777404, 'importance_type': 'gain', 'reg_alpha': 2.9473284020892687, 'reg_lambda': 2.824387563042549}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:43:35,442] Trial 240 finished with value: 0.7158562841185041 and parameters: {'learning_rate': 0.09873657529754636, 'max_depth': 347, 'subsample': 0.1368243058661653, 'num_leaves': 800, 'colsample_bytree': 0.04628013054954783, 'importance_type': 'gain', 'reg_alpha': 2.9863541943582277, 'reg_lambda': 2.8761517021498215}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:43:51,707] Trial 241 finished with value: 0.7458600796503156 and parameters: {'learning_rate': 0.12353453879231051, 'max_depth': 330, 'subsample': 0.10379766666541553, 'num_leaves': 763, 'colsample_bytree': 0.929397852464795, 'importance_type': 'gain', 'reg_alpha': 2.8536433663731344, 'reg_lambda': 2.2967353988077384}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:44:06,214] Trial 242 finished with value: 0.7469560432248664 and parameters: {'learning_rate': 0.11378259258767162, 'max_depth': 320, 'subsample': 0.1266041101217295, 'num_leaves': 752, 'colsample_bytree': 0.9778700180838451, 'importance_type': 'gain', 'reg_alpha': 2.88786064473874, 'reg_lambda': 2.998951247113223}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:44:21,090] Trial 243 finished with value: 0.7472466862554639 and parameters: {'learning_rate': 0.13147062181952282, 'max_depth': 363, 'subsample': 0.16217813820321011, 'num_leaves': 784, 'colsample_bytree': 0.9473785469220715, 'importance_type': 'gain', 'reg_alpha': 2.8923156644836476, 'reg_lambda': 2.731653346376087}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:44:30,684] Trial 244 finished with value: 0.7395581850412821 and parameters: {'learning_rate': 0.1439605559972379, 'max_depth': 303, 'subsample': 0.08436676039091244, 'num_leaves': 314, 'colsample_bytree': 0.9666468254247521, 'importance_type': 'gain', 'reg_alpha': 2.998672096416792, 'reg_lambda': 2.8046362495909944}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:44:45,837] Trial 245 finished with value: 0.747415615347256 and parameters: {'learning_rate': 0.12042743060270716, 'max_depth': 343, 'subsample': 0.10667227260864229, 'num_leaves': 734, 'colsample_bytree': 0.968957508079401, 'importance_type': 'gain', 'reg_alpha': 2.8204578153678765, 'reg_lambda': 2.930197082477987}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:44:52,164] Trial 246 finished with value: 0.7321333768819815 and parameters: {'learning_rate': 0.10810771983901692, 'max_depth': 329, 'subsample': 0.13301216591772613, 'num_leaves': 206, 'colsample_bytree': 0.9213438401550343, 'importance_type': 'gain', 'reg_alpha': 2.926181012664538, 'reg_lambda': 2.865024897988049}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:44:58,588] Trial 247 finished with value: 0.7438837323943662 and parameters: {'learning_rate': 0.16092574210925556, 'max_depth': 376, 'subsample': 0.15429770626290812, 'num_leaves': 761, 'colsample_bytree': 0.24516573108803275, 'importance_type': 'gain', 'reg_alpha': 2.8550757949871737, 'reg_lambda': 2.7595343681424866}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:45:15,003] Trial 248 finished with value: 0.746050978630403 and parameters: {'learning_rate': 0.1273948948478225, 'max_depth': 315, 'subsample': 0.11967327969991245, 'num_leaves': 774, 'colsample_bytree': 0.949697742905268, 'importance_type': 'gain', 'reg_alpha': 0.37934679001547256, 'reg_lambda': 2.583864481959129}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:45:32,286] Trial 249 finished with value: 0.7474330791646431 and parameters: {'learning_rate': 0.1382188508619756, 'max_depth': 356, 'subsample': 0.07705609254118556, 'num_leaves': 751, 'colsample_bytree': 0.9762246067776837, 'importance_type': 'gain', 'reg_alpha': 2.7542557389115148, 'reg_lambda': 2.819509010764977}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:45:49,077] Trial 250 finished with value: 0.7476622253521127 and parameters: {'learning_rate': 0.11786221085612679, 'max_depth': 338, 'subsample': 0.17806116994366747, 'num_leaves': 788, 'colsample_bytree': 0.9396120960541812, 'importance_type': 'gain', 'reg_alpha': 2.997371073731782, 'reg_lambda': 2.406902826826034}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:46:03,955] Trial 251 finished with value: 0.7476837610490529 and parameters: {'learning_rate': 0.11542698039711184, 'max_depth': 347, 'subsample': 0.19855937221261216, 'num_leaves': 787, 'colsample_bytree': 0.9550075121014837, 'importance_type': 'gain', 'reg_alpha': 2.97257480443202, 'reg_lambda': 2.3995132704617843}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:46:21,459] Trial 252 finished with value: 0.7466897824186498 and parameters: {'learning_rate': 0.1030725266259394, 'max_depth': 364, 'subsample': 0.18863717628655768, 'num_leaves': 800, 'colsample_bytree': 0.9184021519074631, 'importance_type': 'gain', 'reg_alpha': 2.9876404007658746, 'reg_lambda': 2.4164150937236646}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:46:36,276] Trial 253 finished with value: 0.7473267289946576 and parameters: {'learning_rate': 0.11255493180455768, 'max_depth': 347, 'subsample': 0.19436653800575332, 'num_leaves': 787, 'colsample_bytree': 0.9519399882831296, 'importance_type': 'gain', 'reg_alpha': 2.995498448574121, 'reg_lambda': 2.450369470040842}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.370016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:46:53,038] Trial 254 finished with value: 0.7476176211753278 and parameters: {'learning_rate': 0.11392073442765488, 'max_depth': 351, 'subsample': 0.21148521944419346, 'num_leaves': 781, 'colsample_bytree': 0.9309622017417126, 'importance_type': 'gain', 'reg_alpha': 2.9271158582601178, 'reg_lambda': 2.505544091027199}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:47:08,451] Trial 255 finished with value: 0.7472039028654687 and parameters: {'learning_rate': 0.0914290508954322, 'max_depth': 341, 'subsample': 0.21285013125455304, 'num_leaves': 788, 'colsample_bytree': 0.9186728301664434, 'importance_type': 'gain', 'reg_alpha': 2.946490638194977, 'reg_lambda': 2.366789173313136}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:47:25,434] Trial 256 finished with value: 0.7464134681884409 and parameters: {'learning_rate': 0.1172479819770561, 'max_depth': 349, 'subsample': 0.2053681375371881, 'num_leaves': 799, 'colsample_bytree': 0.9357592486599366, 'importance_type': 'gain', 'reg_alpha': 2.929916899183073, 'reg_lambda': 2.5060658586190825}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:47:40,904] Trial 257 finished with value: 0.7476918989800874 and parameters: {'learning_rate': 0.12081588456510985, 'max_depth': 324, 'subsample': 0.18092786553149298, 'num_leaves': 784, 'colsample_bytree': 0.9362775950768392, 'importance_type': 'gain', 'reg_alpha': 2.9104284064210515, 'reg_lambda': 2.5211742056573208}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:47:56,523] Trial 258 finished with value: 0.7474522778047595 and parameters: {'learning_rate': 0.1187302058125311, 'max_depth': 322, 'subsample': 0.17844916196075578, 'num_leaves': 784, 'colsample_bytree': 0.9439663927881582, 'importance_type': 'gain', 'reg_alpha': 2.99474716585757, 'reg_lambda': 2.51908637860818}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:48:14,745] Trial 259 finished with value: 0.7471477532782904 and parameters: {'learning_rate': 0.09943536886383472, 'max_depth': 295, 'subsample': 0.19691625183663683, 'num_leaves': 782, 'colsample_bytree': 0.9697291801765253, 'importance_type': 'gain', 'reg_alpha': 2.9106842258545846, 'reg_lambda': 2.444032425995876}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:48:15,738] Trial 260 finished with value: 0.6521540930063138 and parameters: {'learning_rate': 0.10722095087291653, 'max_depth': 309, 'subsample': 0.22875338838719228, 'num_leaves': 6, 'colsample_bytree': 0.9268405390657827, 'importance_type': 'gain', 'reg_alpha': 2.924450704029483, 'reg_lambda': 2.576702983098139}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:48:32,756] Trial 261 finished with value: 0.7469901092763478 and parameters: {'learning_rate': 0.12206253408572097, 'max_depth': 320, 'subsample': 0.15959670196520484, 'num_leaves': 785, 'colsample_bytree': 0.9706059253581235, 'importance_type': 'gain', 'reg_alpha': 2.999064110621197, 'reg_lambda': 2.393572784930664}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:48:47,774] Trial 262 finished with value: 0.7470541835842642 and parameters: {'learning_rate': 0.1254698597634851, 'max_depth': 337, 'subsample': 0.17026317285818027, 'num_leaves': 800, 'colsample_bytree': 0.9124187136517896, 'importance_type': 'gain', 'reg_alpha': 2.869661430451785, 'reg_lambda': 2.9443999539527415}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:49:04,689] Trial 263 finished with value: 0.7466507139388052 and parameters: {'learning_rate': 0.10893008628903171, 'max_depth': 368, 'subsample': 0.14348135766822165, 'num_leaves': 773, 'colsample_bytree': 0.9485689790836657, 'importance_type': 'gain', 'reg_alpha': 2.9353249817810454, 'reg_lambda': 2.3198939641985445}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:49:20,179] Trial 264 finished with value: 0.7480360432248665 and parameters: {'learning_rate': 0.11654339128655652, 'max_depth': 326, 'subsample': 0.20856608803610988, 'num_leaves': 800, 'colsample_bytree': 0.9791314370785217, 'importance_type': 'gain', 'reg_alpha': 2.853103722739602, 'reg_lambda': 2.505222004749816}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:49:36,857] Trial 265 finished with value: 0.7483801758135017 and parameters: {'learning_rate': 0.1294070622732975, 'max_depth': 326, 'subsample': 0.20564551752006388, 'num_leaves': 799, 'colsample_bytree': 0.9827015615177384, 'importance_type': 'gain', 'reg_alpha': 2.845824239553044, 'reg_lambda': 2.5259912076037545}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:49:54,328] Trial 266 finished with value: 0.7472139373482274 and parameters: {'learning_rate': 0.12813802784920214, 'max_depth': 311, 'subsample': 0.22446148033778904, 'num_leaves': 788, 'colsample_bytree': 0.9828409061614441, 'importance_type': 'gain', 'reg_alpha': 2.885487550480468, 'reg_lambda': 2.5056719113816626}. Best is trial 221 with value: 0.7484043895094706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:50:11,522] Trial 267 finished with value: 0.7484858164157359 and parameters: {'learning_rate': 0.13360363547386694, 'max_depth': 322, 'subsample': 0.21094851527736244, 'num_leaves': 796, 'colsample_bytree': 0.9758389256032252, 'importance_type': 'gain', 'reg_alpha': 2.8306809455658577, 'reg_lambda': 2.4797492082749333}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:50:26,732] Trial 268 finished with value: 0.7470563899951432 and parameters: {'learning_rate': 0.13478421532807217, 'max_depth': 302, 'subsample': 0.21200331971317446, 'num_leaves': 800, 'colsample_bytree': 0.983599444684533, 'importance_type': 'gain', 'reg_alpha': 2.8546064317717734, 'reg_lambda': 2.4484566527859895}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.540719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:50:44,201] Trial 269 finished with value: 0.748052055366683 and parameters: {'learning_rate': 0.1282028827615046, 'max_depth': 286, 'subsample': 0.23240348580287662, 'num_leaves': 785, 'colsample_bytree': 0.9344633482460045, 'importance_type': 'gain', 'reg_alpha': 2.9191644583571406, 'reg_lambda': 2.558728611891577}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:51:00,911] Trial 270 finished with value: 0.7409800213695968 and parameters: {'learning_rate': 0.05176673664254568, 'max_depth': 284, 'subsample': 0.2102260868816141, 'num_leaves': 784, 'colsample_bytree': 0.9110411969031348, 'importance_type': 'gain', 'reg_alpha': 2.827842564918557, 'reg_lambda': 2.5569058223582184}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:51:13,570] Trial 271 finished with value: 0.7469373739679456 and parameters: {'learning_rate': 0.13557954008393674, 'max_depth': 275, 'subsample': 0.24460650147120766, 'num_leaves': 800, 'colsample_bytree': 0.4508117784305087, 'importance_type': 'gain', 'reg_alpha': 2.9096972408735846, 'reg_lambda': 2.497652205777681}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:51:30,237] Trial 272 finished with value: 0.7469860645944633 and parameters: {'learning_rate': 0.1306249651304466, 'max_depth': 293, 'subsample': 0.23763581982173715, 'num_leaves': 785, 'colsample_bytree': 0.9373072955081695, 'importance_type': 'gain', 'reg_alpha': 2.825959846234232, 'reg_lambda': 2.5787071349434907}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:51:45,788] Trial 273 finished with value: 0.7476306794560466 and parameters: {'learning_rate': 0.14034979641009876, 'max_depth': 326, 'subsample': 0.1991275990885299, 'num_leaves': 776, 'colsample_bytree': 0.9801961623846518, 'importance_type': 'gain', 'reg_alpha': 2.910843034040536, 'reg_lambda': 2.443572715093536}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.243809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:52:07,795] Trial 274 finished with value: 0.7314740645944634 and parameters: {'learning_rate': 0.021001061443915288, 'max_depth': 312, 'subsample': 0.20239665625288766, 'num_leaves': 775, 'colsample_bytree': 0.9802953507428105, 'importance_type': 'gain', 'reg_alpha': 2.9224969714803497, 'reg_lambda': 2.453673966205427}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:52:23,431] Trial 275 finished with value: 0.7481599188926664 and parameters: {'learning_rate': 0.1406756934942385, 'max_depth': 323, 'subsample': 0.21922319123287431, 'num_leaves': 800, 'colsample_bytree': 0.9672150092404976, 'importance_type': 'gain', 'reg_alpha': 2.9003106546311197, 'reg_lambda': 2.391542231166573}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:52:40,397] Trial 276 finished with value: 0.7481396629431762 and parameters: {'learning_rate': 0.1366784903570943, 'max_depth': 323, 'subsample': 0.2324274756069315, 'num_leaves': 798, 'colsample_bytree': 0.999233130860423, 'importance_type': 'gain', 'reg_alpha': 2.8749619036624607, 'reg_lambda': 2.3862100402879425}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:52:57,177] Trial 277 finished with value: 0.7475683477416222 and parameters: {'learning_rate': 0.1457684351910427, 'max_depth': 306, 'subsample': 0.2513021968533762, 'num_leaves': 800, 'colsample_bytree': 0.9675632263135904, 'importance_type': 'gain', 'reg_alpha': 2.8293102695572165, 'reg_lambda': 2.2546756383636}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:53:12,728] Trial 278 finished with value: 0.747142998542982 and parameters: {'learning_rate': 0.1391109050602475, 'max_depth': 289, 'subsample': 0.23026181281542643, 'num_leaves': 777, 'colsample_bytree': 0.9835658622781617, 'importance_type': 'gain', 'reg_alpha': 2.8822512907038154, 'reg_lambda': 2.4033544712099966}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:53:17,178] Trial 279 finished with value: 0.7255540543953375 and parameters: {'learning_rate': 0.1455019042078482, 'max_depth': 319, 'subsample': 0.22503311815252475, 'num_leaves': 94, 'colsample_bytree': 0.9654389058012517, 'importance_type': 'gain', 'reg_alpha': 2.9312988989686177, 'reg_lambda': 2.362056445146498}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:53:32,936] Trial 280 finished with value: 0.7471667761049052 and parameters: {'learning_rate': 0.1300434144489202, 'max_depth': 326, 'subsample': 0.18639317197823452, 'num_leaves': 800, 'colsample_bytree': 0.9948089800828291, 'importance_type': 'gain', 'reg_alpha': 1.9469583790799618, 'reg_lambda': 2.298448575521903}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:53:49,687] Trial 281 finished with value: 0.7472909320058281 and parameters: {'learning_rate': 0.1362223549059537, 'max_depth': 301, 'subsample': 0.253849418292144, 'num_leaves': 776, 'colsample_bytree': 0.9617100629323094, 'importance_type': 'gain', 'reg_alpha': 2.8222021176900496, 'reg_lambda': 2.397773367276167}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:54:05,996] Trial 282 finished with value: 0.7473390063137445 and parameters: {'learning_rate': 0.12640867495483385, 'max_depth': 315, 'subsample': 0.19453705310557276, 'num_leaves': 788, 'colsample_bytree': 0.9806644535899026, 'importance_type': 'gain', 'reg_alpha': 2.8846674813361792, 'reg_lambda': 2.614828361634425}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:54:16,310] Trial 283 finished with value: 0.744473241864983 and parameters: {'learning_rate': 0.14998911466078968, 'max_depth': 326, 'subsample': 0.2364419797976626, 'num_leaves': 538, 'colsample_bytree': 0.9415170841766898, 'importance_type': 'gain', 'reg_alpha': 1.67449078217961, 'reg_lambda': 2.4621011950402933}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:54:33,764] Trial 284 finished with value: 0.7472403933948519 and parameters: {'learning_rate': 0.13980682035322856, 'max_depth': 334, 'subsample': 0.20688337155268385, 'num_leaves': 773, 'colsample_bytree': 0.9612287641711994, 'importance_type': 'gain', 'reg_alpha': 2.94663269860261, 'reg_lambda': 2.531053384593393}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:54:49,258] Trial 285 finished with value: 0.7448809558037882 and parameters: {'learning_rate': 0.1645170371627735, 'max_depth': 298, 'subsample': 0.8485679287275731, 'num_leaves': 800, 'colsample_bytree': 0.9955492104517352, 'importance_type': 'gain', 'reg_alpha': 1.854936706937169, 'reg_lambda': 2.3772404736454997}. Best is trial 267 with value: 0.7484858164157359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.293007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:55:05,797] Trial 286 finished with value: 0.7486957940747936 and parameters: {'learning_rate': 0.12457135642732306, 'max_depth': 314, 'subsample': 0.18331318829770638, 'num_leaves': 785, 'colsample_bytree': 0.9413679345498897, 'importance_type': 'gain', 'reg_alpha': 2.7815667819632477, 'reg_lambda': 2.6078548972943905}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:55:20,881] Trial 287 finished with value: 0.7460213778533268 and parameters: {'learning_rate': 0.12243089143378547, 'max_depth': 308, 'subsample': 0.18499482989567212, 'num_leaves': 788, 'colsample_bytree': 0.9311049239740601, 'importance_type': 'gain', 'reg_alpha': 2.7208310924038024, 'reg_lambda': 2.5824850707533695}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:55:35,459] Trial 288 finished with value: 0.747372500728509 and parameters: {'learning_rate': 0.1280237018616733, 'max_depth': 315, 'subsample': 0.2207777325680123, 'num_leaves': 770, 'colsample_bytree': 0.9116681837984695, 'importance_type': 'gain', 'reg_alpha': 2.7744378225234745, 'reg_lambda': 2.6042005309964735}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:55:50,482] Trial 289 finished with value: 0.747375821758135 and parameters: {'learning_rate': 0.12007383986857363, 'max_depth': 282, 'subsample': 0.17802102471297562, 'num_leaves': 800, 'colsample_bytree': 0.5326895501206903, 'importance_type': 'gain', 'reg_alpha': 2.7940600003479616, 'reg_lambda': 2.640576756625657}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:56:06,309] Trial 290 finished with value: 0.7467654468188442 and parameters: {'learning_rate': 0.13138078939239292, 'max_depth': 296, 'subsample': 0.7523842841318675, 'num_leaves': 784, 'colsample_bytree': 0.9404422198286784, 'importance_type': 'gain', 'reg_alpha': 2.698794653981378, 'reg_lambda': 2.5264190716026804}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:56:23,112] Trial 291 finished with value: 0.7456327003399708 and parameters: {'learning_rate': 0.11997000595050891, 'max_depth': 268, 'subsample': 0.26297754577717525, 'num_leaves': 764, 'colsample_bytree': 0.9602644881135901, 'importance_type': 'gain', 'reg_alpha': 1.5294624642457326, 'reg_lambda': 2.3481491780660084}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:56:39,456] Trial 292 finished with value: 0.7468923326857697 and parameters: {'learning_rate': 0.10394531310024484, 'max_depth': 316, 'subsample': 0.17083397474135664, 'num_leaves': 782, 'colsample_bytree': 0.9986252050006065, 'importance_type': 'gain', 'reg_alpha': 2.8085430891425687, 'reg_lambda': 2.493448854953408}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.559638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:56:56,872] Trial 293 finished with value: 0.7473390801359883 and parameters: {'learning_rate': 0.12944394668736886, 'max_depth': 335, 'subsample': 0.2306585769255608, 'num_leaves': 768, 'colsample_bytree': 0.9468673419737167, 'importance_type': 'gain', 'reg_alpha': 2.863828334444831, 'reg_lambda': 2.645523184659302}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:57:12,019] Trial 294 finished with value: 0.7445477105390966 and parameters: {'learning_rate': 0.15172187843336038, 'max_depth': 325, 'subsample': 0.5743327250668311, 'num_leaves': 788, 'colsample_bytree': 0.9235718738175469, 'importance_type': 'gain', 'reg_alpha': 1.2172009810053126, 'reg_lambda': 2.5553415267028883}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:57:22,372] Trial 295 finished with value: 0.7402617853326858 and parameters: {'learning_rate': 0.11443616618687459, 'max_depth': 305, 'subsample': 0.1869274685801794, 'num_leaves': 379, 'colsample_bytree': 0.9677218555776519, 'importance_type': 'gain', 'reg_alpha': 2.9529759144139316, 'reg_lambda': 2.431249279883773}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:57:36,785] Trial 296 finished with value: 0.7468926687712483 and parameters: {'learning_rate': 0.13537060024642392, 'max_depth': 341, 'subsample': 0.21600802428338298, 'num_leaves': 753, 'colsample_bytree': 0.907750828091822, 'importance_type': 'gain', 'reg_alpha': 2.8377501937373, 'reg_lambda': 2.519594033313812}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:57:53,437] Trial 297 finished with value: 0.747017326857698 and parameters: {'learning_rate': 0.12292919267354857, 'max_depth': 387, 'subsample': 0.1657128800157941, 'num_leaves': 800, 'colsample_bytree': 0.9497440275596198, 'importance_type': 'gain', 'reg_alpha': 2.8776807930731256, 'reg_lambda': 2.6222266180765956}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:58:09,564] Trial 298 finished with value: 0.7434710772219524 and parameters: {'learning_rate': 0.06726890602550543, 'max_depth': 320, 'subsample': 0.24557630219782928, 'num_leaves': 771, 'colsample_bytree': 0.9773655029776689, 'importance_type': 'gain', 'reg_alpha': 2.7364084257912475, 'reg_lambda': 2.6758758632903694}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:58:26,223] Trial 299 finished with value: 0.7478048110733365 and parameters: {'learning_rate': 0.14439988171478252, 'max_depth': 334, 'subsample': 0.19415976856677114, 'num_leaves': 787, 'colsample_bytree': 0.9997431364983252, 'importance_type': 'gain', 'reg_alpha': 2.951610539223958, 'reg_lambda': 2.4647431814987595}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:58:40,976] Trial 300 finished with value: 0.7456954915007286 and parameters: {'learning_rate': 0.15969522129185781, 'max_depth': 338, 'subsample': 0.2059089300876819, 'num_leaves': 788, 'colsample_bytree': 0.9825464159234654, 'importance_type': 'gain', 'reg_alpha': 2.825802534974691, 'reg_lambda': 2.3372750625419783}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:58:52,861] Trial 301 finished with value: 0.7456243428848955 and parameters: {'learning_rate': 0.14172220236102692, 'max_depth': 256, 'subsample': 0.19698848839859315, 'num_leaves': 472, 'colsample_bytree': 0.9938822934963747, 'importance_type': 'gain', 'reg_alpha': 2.8894192394312443, 'reg_lambda': 2.4593032411033873}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:59:09,891] Trial 302 finished with value: 0.748194970373968 and parameters: {'learning_rate': 0.1499091928166167, 'max_depth': 311, 'subsample': 0.17669734431774314, 'num_leaves': 786, 'colsample_bytree': 0.9713552271247328, 'importance_type': 'gain', 'reg_alpha': 2.999922003596833, 'reg_lambda': 2.5597346957341047}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:59:24,845] Trial 303 finished with value: 0.74596122486644 and parameters: {'learning_rate': 0.16840682776160434, 'max_depth': 332, 'subsample': 0.9774906179493285, 'num_leaves': 788, 'colsample_bytree': 0.998970181337708, 'importance_type': 'gain', 'reg_alpha': 2.9570649862875653, 'reg_lambda': 2.5572517933080436}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:59:41,995] Trial 304 finished with value: 0.7475494779018941 and parameters: {'learning_rate': 0.14498434706006347, 'max_depth': 343, 'subsample': 0.1777227512984018, 'num_leaves': 800, 'colsample_bytree': 0.9614198556121657, 'importance_type': 'gain', 'reg_alpha': 2.99815400716101, 'reg_lambda': 2.268043802973062}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:59:57,788] Trial 305 finished with value: 0.7469807731908693 and parameters: {'learning_rate': 0.1580462159305577, 'max_depth': 312, 'subsample': 0.1569710951115848, 'num_leaves': 781, 'colsample_bytree': 0.9698545405462108, 'importance_type': 'gain', 'reg_alpha': 2.9992863378247603, 'reg_lambda': 2.408572988823803}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.349975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:00:15,506] Trial 306 finished with value: 0.7459383491986402 and parameters: {'learning_rate': 0.17487502604717917, 'max_depth': 357, 'subsample': 0.1828768204521367, 'num_leaves': 800, 'colsample_bytree': 0.9786527149395785, 'importance_type': 'gain', 'reg_alpha': 2.9094404155526346, 'reg_lambda': 2.5028894547500617}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:00:30,075] Trial 307 finished with value: 0.7471194769305488 and parameters: {'learning_rate': 0.15104694094085522, 'max_depth': 321, 'subsample': 0.2192725332481524, 'num_leaves': 765, 'colsample_bytree': 0.9564205893268695, 'importance_type': 'gain', 'reg_alpha': 2.7807202079961346, 'reg_lambda': 2.5731764498318555}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:00:46,468] Trial 308 finished with value: 0.7470590990772219 and parameters: {'learning_rate': 0.1368797096091572, 'max_depth': 373, 'subsample': 0.16487229823982555, 'num_leaves': 786, 'colsample_bytree': 0.9999208240490981, 'importance_type': 'gain', 'reg_alpha': 2.9453566896651826, 'reg_lambda': 2.7021490119360525}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:01:03,503] Trial 309 finished with value: 0.7475607688198155 and parameters: {'learning_rate': 0.15249520221559534, 'max_depth': 331, 'subsample': 0.18632021471623028, 'num_leaves': 751, 'colsample_bytree': 0.999924597336027, 'importance_type': 'gain', 'reg_alpha': 2.881429124605709, 'reg_lambda': 2.4616054860372634}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:01:18,982] Trial 310 finished with value: 0.7474252768334142 and parameters: {'learning_rate': 0.12986189260958397, 'max_depth': 344, 'subsample': 0.2015916802363249, 'num_leaves': 771, 'colsample_bytree': 0.9725239795682759, 'importance_type': 'gain', 'reg_alpha': 2.8184346773907833, 'reg_lambda': 2.6163514093648694}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:01:35,634] Trial 311 finished with value: 0.7470754507042254 and parameters: {'learning_rate': 0.14537820301946455, 'max_depth': 313, 'subsample': 0.15762136175844307, 'num_leaves': 785, 'colsample_bytree': 0.9475961414072105, 'importance_type': 'gain', 'reg_alpha': 2.9989831938619966, 'reg_lambda': 2.5409310368507776}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:01:49,657] Trial 312 finished with value: 0.7466642948033027 and parameters: {'learning_rate': 0.12213636458127246, 'max_depth': 331, 'subsample': 0.22630904624624723, 'num_leaves': 759, 'colsample_bytree': 0.5890606167274502, 'importance_type': 'gain', 'reg_alpha': 2.9019055849120514, 'reg_lambda': 2.400835136752414}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:02:06,437] Trial 313 finished with value: 0.7468541685284118 and parameters: {'learning_rate': 0.13640949842420055, 'max_depth': 241, 'subsample': 0.17184318061145468, 'num_leaves': 786, 'colsample_bytree': 0.9785956565874039, 'importance_type': 'gain', 'reg_alpha': 2.8491829245115983, 'reg_lambda': 2.498390019742654}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:02:30,784] Trial 314 finished with value: 0.724672 and parameters: {'learning_rate': 0.012183649522378751, 'max_depth': 364, 'subsample': 0.20208842958788806, 'num_leaves': 800, 'colsample_bytree': 0.9553191338808174, 'importance_type': 'gain', 'reg_alpha': 2.74007661176072, 'reg_lambda': 2.3114357066471114}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:02:48,327] Trial 315 finished with value: 0.7479243725109276 and parameters: {'learning_rate': 0.12736052573477147, 'max_depth': 349, 'subsample': 0.15015129899052607, 'num_leaves': 772, 'colsample_bytree': 0.9999026440978768, 'importance_type': 'gain', 'reg_alpha': 2.941877239168649, 'reg_lambda': 2.6227433383158276}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:03:04,171] Trial 316 finished with value: 0.7452874278776105 and parameters: {'learning_rate': 0.16157041904329514, 'max_depth': 350, 'subsample': 0.14819091537169532, 'num_leaves': 744, 'colsample_bytree': 0.9989848664510359, 'importance_type': 'gain', 'reg_alpha': 2.8103733015921573, 'reg_lambda': 2.6895245881080374}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:03:05,888] Trial 317 finished with value: 0.7059200349684311 and parameters: {'learning_rate': 0.13095616424945872, 'max_depth': 381, 'subsample': 0.13760719272380698, 'num_leaves': 37, 'colsample_bytree': 0.9795895098206177, 'importance_type': 'gain', 'reg_alpha': 2.9295249960399903, 'reg_lambda': 2.607987131998875}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:03:22,386] Trial 318 finished with value: 0.746658857212239 and parameters: {'learning_rate': 0.14540994067695484, 'max_depth': 322, 'subsample': 0.15459391865260041, 'num_leaves': 771, 'colsample_bytree': 0.9697153287761849, 'importance_type': 'gain', 'reg_alpha': 2.7016278279268695, 'reg_lambda': 2.6556578866730027}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:03:33,326] Trial 319 finished with value: 0.7468385245264691 and parameters: {'learning_rate': 0.12433229598937381, 'max_depth': 303, 'subsample': 0.24464315150120972, 'num_leaves': 759, 'colsample_bytree': 0.6822056807121956, 'importance_type': 'gain', 'reg_alpha': 2.8750778327878566, 'reg_lambda': 2.594667559674562}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:03:49,614] Trial 320 finished with value: 0.7468995988343856 and parameters: {'learning_rate': 0.13892367041545098, 'max_depth': 401, 'subsample': 0.2160942734337146, 'num_leaves': 774, 'colsample_bytree': 0.999235582131849, 'importance_type': 'gain', 'reg_alpha': 2.7942666013096282, 'reg_lambda': 2.720830539040355}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:04:03,889] Trial 321 finished with value: 0.7457707659057795 and parameters: {'learning_rate': 0.10774323008809872, 'max_depth': 361, 'subsample': 0.1333777296342461, 'num_leaves': 733, 'colsample_bytree': 0.9810539318515649, 'importance_type': 'gain', 'reg_alpha': 2.923879769652106, 'reg_lambda': 2.559422004070427}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:04:12,933] Trial 322 finished with value: 0.7454982209810588 and parameters: {'learning_rate': 0.129567624446829, 'max_depth': 351, 'subsample': 0.18906741301298102, 'num_leaves': 775, 'colsample_bytree': 0.3851241614757602, 'importance_type': 'gain', 'reg_alpha': 2.856706371316799, 'reg_lambda': 2.4889001047425583}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:04:27,756] Trial 323 finished with value: 0.7470849732880038 and parameters: {'learning_rate': 0.1535217833757132, 'max_depth': 341, 'subsample': 0.1508815791250741, 'num_leaves': 748, 'colsample_bytree': 0.9616042920914848, 'importance_type': 'gain', 'reg_alpha': 2.941037706886273, 'reg_lambda': 2.5518621326179014}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:04:45,466] Trial 324 finished with value: 0.7479109689169499 and parameters: {'learning_rate': 0.11578313634703967, 'max_depth': 322, 'subsample': 0.17117613816309835, 'num_leaves': 786, 'colsample_bytree': 0.9794872243220917, 'importance_type': 'gain', 'reg_alpha': 2.761162733000013, 'reg_lambda': 2.6437387861946133}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:05:00,932] Trial 325 finished with value: 0.7471909737736766 and parameters: {'learning_rate': 0.19376844915421126, 'max_depth': 316, 'subsample': 0.16878114631127547, 'num_leaves': 763, 'colsample_bytree': 0.9825193880956548, 'importance_type': 'gain', 'reg_alpha': 2.6781268564891136, 'reg_lambda': 2.6460114140277473}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:05:15,739] Trial 326 finished with value: 0.7340124575036425 and parameters: {'learning_rate': 0.3834698072202284, 'max_depth': 288, 'subsample': 0.1315077220926153, 'num_leaves': 786, 'colsample_bytree': 0.9788056704902698, 'importance_type': 'gain', 'reg_alpha': 2.7584766325494074, 'reg_lambda': 2.7217743112088506}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:05:33,849] Trial 327 finished with value: 0.748125 and parameters: {'learning_rate': 0.1379486140980734, 'max_depth': 329, 'subsample': 0.16097686321736504, 'num_leaves': 799, 'colsample_bytree': 0.9604601530371082, 'importance_type': 'gain', 'reg_alpha': 2.7795754793600453, 'reg_lambda': 2.628021352010511}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:05:48,476] Trial 328 finished with value: 0.7460833831957261 and parameters: {'learning_rate': 0.17783489793559237, 'max_depth': 307, 'subsample': 0.1575766923381665, 'num_leaves': 770, 'colsample_bytree': 0.9988746416941011, 'importance_type': 'gain', 'reg_alpha': 2.7090167752438536, 'reg_lambda': 2.653760088020525}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:06:04,151] Trial 329 finished with value: 0.7470183341427877 and parameters: {'learning_rate': 0.14770882721873363, 'max_depth': 273, 'subsample': 0.12635420507917272, 'num_leaves': 798, 'colsample_bytree': 0.96388620451648, 'importance_type': 'gain', 'reg_alpha': 2.795451488006604, 'reg_lambda': 2.7036239346416036}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:06:23,083] Trial 330 finished with value: 0.7394454205925206 and parameters: {'learning_rate': 0.04213329017357537, 'max_depth': 333, 'subsample': 0.16387319644489348, 'num_leaves': 756, 'colsample_bytree': 0.9804585534658613, 'importance_type': 'gain', 'reg_alpha': 2.7567769181683173, 'reg_lambda': 2.621179513674695}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:06:40,334] Trial 331 finished with value: 0.7475319315201554 and parameters: {'learning_rate': 0.1373422700746105, 'max_depth': 322, 'subsample': 0.13930127817220322, 'num_leaves': 800, 'colsample_bytree': 0.9615557617920927, 'importance_type': 'gain', 'reg_alpha': 2.8391864304829952, 'reg_lambda': 2.6262846787478313}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:06:55,279] Trial 332 finished with value: 0.7471271806702282 and parameters: {'learning_rate': 0.13142321997219264, 'max_depth': 314, 'subsample': 0.10523455530923789, 'num_leaves': 800, 'colsample_bytree': 0.9829492191712234, 'importance_type': 'gain', 'reg_alpha': 2.669361649060204, 'reg_lambda': 2.6964868509273723}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:07:05,822] Trial 333 finished with value: 0.7473554273919378 and parameters: {'learning_rate': 0.1649374565423914, 'max_depth': 329, 'subsample': 0.17286499576117473, 'num_leaves': 773, 'colsample_bytree': 0.6367002194098583, 'importance_type': 'gain', 'reg_alpha': 2.780515786823713, 'reg_lambda': 2.5812388107906017}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:07:19,947] Trial 334 finished with value: 0.7456365803788246 and parameters: {'learning_rate': 0.1437842629438866, 'max_depth': 338, 'subsample': 0.2314395155871158, 'num_leaves': 738, 'colsample_bytree': 0.9496841188302789, 'importance_type': 'gain', 'reg_alpha': 2.827937389640412, 'reg_lambda': 0.7017689103177939}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:07:37,254] Trial 335 finished with value: 0.746766939290918 and parameters: {'learning_rate': 0.09642344343324935, 'max_depth': 305, 'subsample': 0.1449846428826809, 'num_leaves': 800, 'colsample_bytree': 0.9993889771781658, 'importance_type': 'gain', 'reg_alpha': 2.863551107897982, 'reg_lambda': 2.7608922186520184}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:07:52,621] Trial 336 finished with value: 0.7466792763477417 and parameters: {'learning_rate': 0.154610326475734, 'max_depth': 326, 'subsample': 0.20480941470500466, 'num_leaves': 779, 'colsample_bytree': 0.9674754177861233, 'importance_type': 'gain', 'reg_alpha': 2.7502496214198877, 'reg_lambda': 2.5756665157280505}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:08:07,897] Trial 337 finished with value: 0.7471159635745508 and parameters: {'learning_rate': 0.12547945584216844, 'max_depth': 297, 'subsample': 0.12141071354632241, 'num_leaves': 759, 'colsample_bytree': 0.9346935755530243, 'importance_type': 'gain', 'reg_alpha': 2.7204190697429094, 'reg_lambda': 2.475864564935894}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:08:13,351] Trial 338 finished with value: 0.7345184725594949 and parameters: {'learning_rate': 0.14064986461135148, 'max_depth': 369, 'subsample': 0.18865212766257866, 'num_leaves': 784, 'colsample_bytree': 0.10107683628364317, 'importance_type': 'gain', 'reg_alpha': 2.8766015554340694, 'reg_lambda': 2.6590209674629532}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:08:31,430] Trial 339 finished with value: 0.7475707561923264 and parameters: {'learning_rate': 0.11612543882981338, 'max_depth': 358, 'subsample': 0.15515064115457233, 'num_leaves': 800, 'colsample_bytree': 0.9793547902559726, 'importance_type': 'gain', 'reg_alpha': 2.7938503821429372, 'reg_lambda': 2.5343511036731963}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:08:47,061] Trial 340 finished with value: 0.7430831214181641 and parameters: {'learning_rate': 0.06005506477577831, 'max_depth': 317, 'subsample': 0.25732064854654896, 'num_leaves': 775, 'colsample_bytree': 0.9497723219572667, 'importance_type': 'gain', 'reg_alpha': 2.8338576497438934, 'reg_lambda': 2.746615200933277}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:09:04,432] Trial 341 finished with value: 0.7471030767362798 and parameters: {'learning_rate': 0.13204342866128901, 'max_depth': 341, 'subsample': 0.12913060349832942, 'num_leaves': 750, 'colsample_bytree': 0.9997517642645751, 'importance_type': 'gain', 'reg_alpha': 2.889964091460354, 'reg_lambda': 2.611125472140199}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:09:19,824] Trial 342 finished with value: 0.7470583360854783 and parameters: {'learning_rate': 0.10708973694539113, 'max_depth': 333, 'subsample': 0.22155510297527573, 'num_leaves': 785, 'colsample_bytree': 0.9663055776563596, 'importance_type': 'gain', 'reg_alpha': 2.801085358114804, 'reg_lambda': 2.4827546600703805}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:09:36,381] Trial 343 finished with value: 0.745686728508985 and parameters: {'learning_rate': 0.07782108194037117, 'max_depth': 210, 'subsample': 0.505119793588135, 'num_leaves': 768, 'colsample_bytree': 0.9300333554438598, 'importance_type': 'gain', 'reg_alpha': 2.9521477453981655, 'reg_lambda': 2.564172926000417}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:09:51,506] Trial 344 finished with value: 0.7485534730451675 and parameters: {'learning_rate': 0.12297729931656286, 'max_depth': 312, 'subsample': 0.17218680147120993, 'num_leaves': 786, 'colsample_bytree': 0.980665720492085, 'importance_type': 'gain', 'reg_alpha': 2.6852002971398115, 'reg_lambda': 2.6869279062582074}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:10:06,267] Trial 345 finished with value: 0.7460804560466245 and parameters: {'learning_rate': 0.12521529180617785, 'max_depth': 307, 'subsample': 0.1814121108746342, 'num_leaves': 743, 'colsample_bytree': 0.9840519463977444, 'importance_type': 'gain', 'reg_alpha': 0.7644932334918564, 'reg_lambda': 2.725995491806141}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:10:23,653] Trial 346 finished with value: 0.7476394006799417 and parameters: {'learning_rate': 0.13829876613238407, 'max_depth': 291, 'subsample': 0.20054947500725223, 'num_leaves': 763, 'colsample_bytree': 0.9810425588779482, 'importance_type': 'gain', 'reg_alpha': 2.6750434812951625, 'reg_lambda': 2.6597346968699576}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:10:39,225] Trial 347 finished with value: 0.74613064351627 and parameters: {'learning_rate': 0.15873925478342413, 'max_depth': 313, 'subsample': 0.1688934611906221, 'num_leaves': 785, 'colsample_bytree': 0.9660730531100632, 'importance_type': 'gain', 'reg_alpha': 2.729803516867844, 'reg_lambda': 2.7670581296821277}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:10:54,416] Trial 348 finished with value: 0.7469374249635745 and parameters: {'learning_rate': 0.14539167199807262, 'max_depth': 323, 'subsample': 0.2443269973853302, 'num_leaves': 729, 'colsample_bytree': 0.9804325773822387, 'importance_type': 'gain', 'reg_alpha': 2.7598102667983264, 'reg_lambda': 2.6931443787127773}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:11:17,600] Trial 349 finished with value: 0.7326551039339485 and parameters: {'learning_rate': 0.025477112155603842, 'max_depth': 301, 'subsample': 0.21438692938651518, 'num_leaves': 771, 'colsample_bytree': 0.9997177471969599, 'importance_type': 'gain', 'reg_alpha': 0.1851327828440883, 'reg_lambda': 2.6136892665964155}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:11:33,135] Trial 350 finished with value: 0.7473786372025254 and parameters: {'learning_rate': 0.12919288438983875, 'max_depth': 317, 'subsample': 0.1880106411588489, 'num_leaves': 784, 'colsample_bytree': 0.9525047382027643, 'importance_type': 'gain', 'reg_alpha': 2.6668070251262566, 'reg_lambda': 2.543084862006258}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:11:49,862] Trial 351 finished with value: 0.7410836639145215 and parameters: {'learning_rate': 0.26028863086690834, 'max_depth': 328, 'subsample': 0.15618488699612196, 'num_leaves': 754, 'colsample_bytree': 0.9738743382569196, 'importance_type': 'gain', 'reg_alpha': 2.828181616027292, 'reg_lambda': 2.653226726023538}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:12:05,031] Trial 352 finished with value: 0.7470331219038369 and parameters: {'learning_rate': 0.12053879430539927, 'max_depth': 259, 'subsample': 0.45905371214470436, 'num_leaves': 800, 'colsample_bytree': 0.9401724021118263, 'importance_type': 'gain', 'reg_alpha': 2.8920974436550537, 'reg_lambda': 2.7981607990430333}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:12:21,415] Trial 353 finished with value: 0.7463396857697912 and parameters: {'learning_rate': 0.1739541841987536, 'max_depth': 306, 'subsample': 0.6062752705369319, 'num_leaves': 774, 'colsample_bytree': 0.9998450995422183, 'importance_type': 'gain', 'reg_alpha': 2.9507025835294907, 'reg_lambda': 2.591785180740432}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:12:36,359] Trial 354 finished with value: 0.748172596891695 and parameters: {'learning_rate': 0.13600603484470278, 'max_depth': 280, 'subsample': 0.17166960098187178, 'num_leaves': 785, 'colsample_bytree': 0.9634596363906497, 'importance_type': 'gain', 'reg_alpha': 2.785975888681208, 'reg_lambda': 2.71377138018983}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:12:49,488] Trial 355 finished with value: 0.7458043715395823 and parameters: {'learning_rate': 0.14874301307175938, 'max_depth': 282, 'subsample': 0.9058433355947629, 'num_leaves': 633, 'colsample_bytree': 0.9199466353950234, 'importance_type': 'gain', 'reg_alpha': 2.7144340062141703, 'reg_lambda': 2.7059289341326203}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:13:06,135] Trial 356 finished with value: 0.7463141728994658 and parameters: {'learning_rate': 0.13546989534693232, 'max_depth': 270, 'subsample': 0.194299446864408, 'num_leaves': 757, 'colsample_bytree': 0.9591982177706466, 'importance_type': 'gain', 'reg_alpha': 2.7521714500973697, 'reg_lambda': 2.6668291475947914}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:13:20,636] Trial 357 finished with value: 0.7462447285089849 and parameters: {'learning_rate': 0.16303836767267327, 'max_depth': 285, 'subsample': 0.17284723600166524, 'num_leaves': 718, 'colsample_bytree': 0.9464876265840867, 'importance_type': 'gain', 'reg_alpha': 2.799768426581912, 'reg_lambda': 0.6446719171336573}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:13:35,232] Trial 358 finished with value: 0.7475469252064109 and parameters: {'learning_rate': 0.13737806228739904, 'max_depth': 264, 'subsample': 0.21645778272151464, 'num_leaves': 737, 'colsample_bytree': 0.9211104010601727, 'importance_type': 'gain', 'reg_alpha': 2.6223847654097074, 'reg_lambda': 2.5291035790555125}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:13:50,699] Trial 359 finished with value: 0.7480065463817387 and parameters: {'learning_rate': 0.152307134037967, 'max_depth': 290, 'subsample': 0.17031645030873943, 'num_leaves': 769, 'colsample_bytree': 0.9651385729743823, 'importance_type': 'gain', 'reg_alpha': 2.9045950959149693, 'reg_lambda': 2.6112056234299335}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:14:08,166] Trial 360 finished with value: 0.7464294424477902 and parameters: {'learning_rate': 0.18927084293657065, 'max_depth': 290, 'subsample': 0.17946426041472877, 'num_leaves': 783, 'colsample_bytree': 0.9637593789670386, 'importance_type': 'gain', 'reg_alpha': 2.9357448263345067, 'reg_lambda': 2.6085567285450155}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:14:22,874] Trial 361 finished with value: 0.7466106784847013 and parameters: {'learning_rate': 0.15573706504783455, 'max_depth': 280, 'subsample': 0.20528477143482804, 'num_leaves': 765, 'colsample_bytree': 0.9671568966295425, 'importance_type': 'gain', 'reg_alpha': 2.8981210004413653, 'reg_lambda': 2.7232593353527683}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:14:37,644] Trial 362 finished with value: 0.7479462603205439 and parameters: {'learning_rate': 0.1532152671149321, 'max_depth': 301, 'subsample': 0.23662036068148667, 'num_leaves': 785, 'colsample_bytree': 0.9426254948785519, 'importance_type': 'gain', 'reg_alpha': 2.994496096175813, 'reg_lambda': 2.463155451273664}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:14:54,671] Trial 363 finished with value: 0.7479798120446819 and parameters: {'learning_rate': 0.169021895813957, 'max_depth': 295, 'subsample': 0.2597309729748211, 'num_leaves': 785, 'colsample_bytree': 0.9380401311041899, 'importance_type': 'gain', 'reg_alpha': 2.9884717071490727, 'reg_lambda': 2.4509405864369445}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:15:09,728] Trial 364 finished with value: 0.7463892180670229 and parameters: {'learning_rate': 0.1763763162113578, 'max_depth': 294, 'subsample': 0.2552707664510129, 'num_leaves': 784, 'colsample_bytree': 0.9260196118222416, 'importance_type': 'gain', 'reg_alpha': 2.986799825276676, 'reg_lambda': 2.4507407119365316}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:15:24,880] Trial 365 finished with value: 0.7473404987858183 and parameters: {'learning_rate': 0.17019229392505236, 'max_depth': 278, 'subsample': 0.2397524584980875, 'num_leaves': 800, 'colsample_bytree': 0.9369116327097909, 'importance_type': 'gain', 'reg_alpha': 2.989059540722117, 'reg_lambda': 2.5202311318050374}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:15:39,661] Trial 366 finished with value: 0.745671215152987 and parameters: {'learning_rate': 0.1617648965007976, 'max_depth': 294, 'subsample': 0.2656383990935858, 'num_leaves': 779, 'colsample_bytree': 0.9086463113918962, 'importance_type': 'gain', 'reg_alpha': 2.998844132760254, 'reg_lambda': 2.580664388114076}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:15:54,082] Trial 367 finished with value: 0.7466389169499759 and parameters: {'learning_rate': 0.17109260762973835, 'max_depth': 275, 'subsample': 0.2917891615150878, 'num_leaves': 770, 'colsample_bytree': 0.8978116441332391, 'importance_type': 'gain', 'reg_alpha': 2.9218278133993527, 'reg_lambda': 2.4678644495077413}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:16:08,136] Trial 368 finished with value: 0.7460530276833415 and parameters: {'learning_rate': 0.15299918196462112, 'max_depth': 298, 'subsample': 0.25302915723195896, 'num_leaves': 750, 'colsample_bytree': 0.9434598817324962, 'importance_type': 'gain', 'reg_alpha': 1.2710657062232658, 'reg_lambda': 2.5375995854511206}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:16:23,010] Trial 369 finished with value: 0.7468654973288004 and parameters: {'learning_rate': 0.15228048385938067, 'max_depth': 286, 'subsample': 0.2811669949344106, 'num_leaves': 786, 'colsample_bytree': 0.9220245777217538, 'importance_type': 'gain', 'reg_alpha': 2.85603810376795, 'reg_lambda': 2.635393103022936}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:16:38,257] Trial 370 finished with value: 0.7450963035454105 and parameters: {'learning_rate': 0.1849591814879822, 'max_depth': 303, 'subsample': 0.23014649786266, 'num_leaves': 770, 'colsample_bytree': 0.9555283380693533, 'importance_type': 'gain', 'reg_alpha': 2.9366826025049737, 'reg_lambda': 2.4092315183373025}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:17:02,808] Trial 371 finished with value: 0.7287970471102477 and parameters: {'learning_rate': 0.01676580364394362, 'max_depth': 288, 'subsample': 0.2672071008544602, 'num_leaves': 784, 'colsample_bytree': 0.937909535670621, 'importance_type': 'gain', 'reg_alpha': 2.8126483621424216, 'reg_lambda': 1.3331154843266024}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:17:18,077] Trial 372 finished with value: 0.744084537639631 and parameters: {'learning_rate': 0.21056552302640605, 'max_depth': 301, 'subsample': 0.22775923841167006, 'num_leaves': 758, 'colsample_bytree': 0.9754566298256897, 'importance_type': 'gain', 'reg_alpha': 2.087505179539771, 'reg_lambda': 2.5861661587292337}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:17:36,140] Trial 373 finished with value: 0.747582164157358 and parameters: {'learning_rate': 0.12601839404698179, 'max_depth': 267, 'subsample': 0.23968574986197855, 'num_leaves': 800, 'colsample_bytree': 0.9615724632685587, 'importance_type': 'gain', 'reg_alpha': 2.887655310131144, 'reg_lambda': 2.485179797305724}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:17:51,205] Trial 374 finished with value: 0.7464817571636717 and parameters: {'learning_rate': 0.1323565414850798, 'max_depth': 309, 'subsample': 0.21058757790574398, 'num_leaves': 773, 'colsample_bytree': 0.979144023266174, 'importance_type': 'gain', 'reg_alpha': 2.939817755610407, 'reg_lambda': 2.655991907647996}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:18:03,215] Trial 375 finished with value: 0.7453648567265663 and parameters: {'learning_rate': 0.16321238193881601, 'max_depth': 278, 'subsample': 0.16776232010868825, 'num_leaves': 568, 'colsample_bytree': 0.9436499137054227, 'importance_type': 'gain', 'reg_alpha': 2.770634122467511, 'reg_lambda': 2.522910357423437}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:18:19,616] Trial 376 finished with value: 0.7477884643030597 and parameters: {'learning_rate': 0.14835887618314925, 'max_depth': 296, 'subsample': 0.2754927391073929, 'num_leaves': 786, 'colsample_bytree': 0.9252739273610792, 'importance_type': 'gain', 'reg_alpha': 2.858467417242701, 'reg_lambda': 2.7335283138585353}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:18:28,480] Trial 377 finished with value: 0.7456117829043225 and parameters: {'learning_rate': 0.10892495968114696, 'max_depth': 308, 'subsample': 0.22158784391721295, 'num_leaves': 744, 'colsample_bytree': 0.2739877400375358, 'importance_type': 'gain', 'reg_alpha': 2.991723186768232, 'reg_lambda': 2.598830968174578}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:18:45,384] Trial 378 finished with value: 0.7474014303059737 and parameters: {'learning_rate': 0.12257773526031866, 'max_depth': 287, 'subsample': 0.19420852914049752, 'num_leaves': 770, 'colsample_bytree': 0.9033557884049374, 'importance_type': 'gain', 'reg_alpha': 2.689370495282733, 'reg_lambda': 2.4343452788842375}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:19:00,945] Trial 379 finished with value: 0.7480488678970375 and parameters: {'learning_rate': 0.14084375974780192, 'max_depth': 311, 'subsample': 0.1562567059633521, 'num_leaves': 786, 'colsample_bytree': 0.9806388594176474, 'importance_type': 'gain', 'reg_alpha': 2.999200043678234, 'reg_lambda': 2.546108842763408}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:19:18,199] Trial 380 finished with value: 0.7462846041767848 and parameters: {'learning_rate': 0.17976613135932565, 'max_depth': 491, 'subsample': 0.17045726667341446, 'num_leaves': 786, 'colsample_bytree': 0.9601439215201202, 'importance_type': 'gain', 'reg_alpha': 2.901934441045205, 'reg_lambda': 2.334168090916984}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:19:32,947] Trial 381 finished with value: 0.747033983001457 and parameters: {'learning_rate': 0.1446007106175998, 'max_depth': 313, 'subsample': 0.23267439270419765, 'num_leaves': 789, 'colsample_bytree': 0.9803247505047956, 'importance_type': 'gain', 'reg_alpha': 2.8313626208101508, 'reg_lambda': 2.504832424839268}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:19:42,934] Trial 382 finished with value: 0.746421077707625 and parameters: {'learning_rate': 0.15486153420972987, 'max_depth': 297, 'subsample': 0.20732016389155375, 'num_leaves': 799, 'colsample_bytree': 0.34637828300003104, 'importance_type': 'gain', 'reg_alpha': 2.948080259347527, 'reg_lambda': 2.7937306677193323}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:19:54,018] Trial 383 finished with value: 0.7435989018941234 and parameters: {'learning_rate': 0.13659090175617056, 'max_depth': 315, 'subsample': 0.1573975714046221, 'num_leaves': 421, 'colsample_bytree': 0.9450505661770283, 'importance_type': 'gain', 'reg_alpha': 2.998685095665677, 'reg_lambda': 2.6629573845409635}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:20:07,616] Trial 384 finished with value: 0.7454421486158329 and parameters: {'learning_rate': 0.16449237043019344, 'max_depth': 305, 'subsample': 0.18666881101945934, 'num_leaves': 611, 'colsample_bytree': 0.9818029920735876, 'importance_type': 'gain', 'reg_alpha': 2.7762312912080245, 'reg_lambda': 2.4340737208499132}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:20:22,101] Trial 385 finished with value: 0.745753694511899 and parameters: {'learning_rate': 0.1988741223727497, 'max_depth': 320, 'subsample': 0.18688791884541228, 'num_leaves': 775, 'colsample_bytree': 0.9559188624180218, 'importance_type': 'gain', 'reg_alpha': 2.8870550375310184, 'reg_lambda': 2.55873801461419}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:20:39,276] Trial 386 finished with value: 0.7463016070908207 and parameters: {'learning_rate': 0.14305784018935663, 'max_depth': 292, 'subsample': 0.2426662039320599, 'num_leaves': 799, 'colsample_bytree': 0.9994178081239619, 'importance_type': 'gain', 'reg_alpha': 1.095268992805871, 'reg_lambda': 2.4725558190646346}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:20:53,881] Trial 387 finished with value: 0.7466274720738222 and parameters: {'learning_rate': 0.11664048928265015, 'max_depth': 310, 'subsample': 0.15465785683267894, 'num_leaves': 757, 'colsample_bytree': 0.9238563835777355, 'importance_type': 'gain', 'reg_alpha': 2.7227829923321414, 'reg_lambda': 2.373025885732305}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:21:09,700] Trial 388 finished with value: 0.7466655405536669 and parameters: {'learning_rate': 0.10163763834596311, 'max_depth': 301, 'subsample': 0.21305566760476918, 'num_leaves': 783, 'colsample_bytree': 0.9655693220047663, 'importance_type': 'gain', 'reg_alpha': 2.838336063422932, 'reg_lambda': 2.6277247435793694}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:21:25,869] Trial 389 finished with value: 0.7481238664400194 and parameters: {'learning_rate': 0.13152840304652658, 'max_depth': 273, 'subsample': 0.1718668989592918, 'num_leaves': 800, 'colsample_bytree': 0.9822935052297752, 'importance_type': 'gain', 'reg_alpha': 2.996295358040405, 'reg_lambda': 2.53512917706794}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:21:42,761] Trial 390 finished with value: 0.7466203428848955 and parameters: {'learning_rate': 0.13524749464863842, 'max_depth': 249, 'subsample': 0.1452618196093786, 'num_leaves': 771, 'colsample_bytree': 0.9419119174156456, 'importance_type': 'gain', 'reg_alpha': 2.948604545028159, 'reg_lambda': 2.5209693097089567}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:21:57,738] Trial 391 finished with value: 0.7478660247693054 and parameters: {'learning_rate': 0.1541363548311953, 'max_depth': 258, 'subsample': 0.2571238386011196, 'num_leaves': 799, 'colsample_bytree': 0.9666907487103481, 'importance_type': 'gain', 'reg_alpha': 2.9936895208483385, 'reg_lambda': 2.4339960237138127}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:22:05,825] Trial 392 finished with value: 0.7399477960174843 and parameters: {'learning_rate': 0.12876087170334446, 'max_depth': 266, 'subsample': 0.19928985713089148, 'num_leaves': 323, 'colsample_bytree': 0.9833889095734208, 'importance_type': 'gain', 'reg_alpha': 2.913766299321338, 'reg_lambda': 2.5390950502351832}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:22:10,765] Trial 393 finished with value: 0.7326421733851385 and parameters: {'learning_rate': 0.22353417520755245, 'max_depth': 272, 'subsample': 0.1745478539455086, 'num_leaves': 134, 'colsample_bytree': 0.9036080160297604, 'importance_type': 'gain', 'reg_alpha': 2.997317945586287, 'reg_lambda': 2.3721104043984855}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:22:27,704] Trial 394 finished with value: 0.747931141330743 and parameters: {'learning_rate': 0.14111698516335722, 'max_depth': 278, 'subsample': 0.2180948587928999, 'num_leaves': 783, 'colsample_bytree': 0.9472481086066682, 'importance_type': 'gain', 'reg_alpha': 2.999081590377644, 'reg_lambda': 2.5809863759245237}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:22:42,634] Trial 395 finished with value: 0.7481538222438077 and parameters: {'learning_rate': 0.14776702716765233, 'max_depth': 278, 'subsample': 0.2224178141965183, 'num_leaves': 750, 'colsample_bytree': 0.9304742246039217, 'importance_type': 'gain', 'reg_alpha': 2.9451214086996496, 'reg_lambda': 2.474116997309731}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:22:56,997] Trial 396 finished with value: 0.7479528484701312 and parameters: {'learning_rate': 0.16863956280468037, 'max_depth': 277, 'subsample': 0.22987913397694118, 'num_leaves': 738, 'colsample_bytree': 0.8855902199891033, 'importance_type': 'gain', 'reg_alpha': 2.994007590301424, 'reg_lambda': 2.4695249327388513}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:23:10,934] Trial 397 finished with value: 0.7461088309859155 and parameters: {'learning_rate': 0.17254223953895026, 'max_depth': 278, 'subsample': 0.27148099586827334, 'num_leaves': 741, 'colsample_bytree': 0.8905520571015758, 'importance_type': 'gain', 'reg_alpha': 1.7513232700933377, 'reg_lambda': 2.4175052123639844}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:23:24,767] Trial 398 finished with value: 0.7465212734337057 and parameters: {'learning_rate': 0.16683608898971533, 'max_depth': 255, 'subsample': 0.23573497028187765, 'num_leaves': 727, 'colsample_bytree': 0.8783710687613445, 'importance_type': 'gain', 'reg_alpha': 2.935897450378371, 'reg_lambda': 2.3179037756286807}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:23:38,981] Trial 399 finished with value: 0.7457678280718796 and parameters: {'learning_rate': 0.18602868806807854, 'max_depth': 272, 'subsample': 0.23838583693288468, 'num_leaves': 752, 'colsample_bytree': 0.9192744869260414, 'importance_type': 'gain', 'reg_alpha': 2.9046959375267347, 'reg_lambda': 2.479116420904383}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:23:52,912] Trial 400 finished with value: 0.7474340228266149 and parameters: {'learning_rate': 0.15873431602586782, 'max_depth': 284, 'subsample': 0.2557438607973486, 'num_leaves': 735, 'colsample_bytree': 0.8947372323381573, 'importance_type': 'gain', 'reg_alpha': 2.9383070101176445, 'reg_lambda': 2.2280989797054644}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:24:07,259] Trial 401 finished with value: 0.7467358873239436 and parameters: {'learning_rate': 0.15233181370799867, 'max_depth': 265, 'subsample': 0.21212526987436278, 'num_leaves': 719, 'colsample_bytree': 0.9155568572513708, 'importance_type': 'gain', 'reg_alpha': 2.8898894815131033, 'reg_lambda': 2.473362444467731}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:24:20,878] Trial 402 finished with value: 0.7470070320543953 and parameters: {'learning_rate': 0.18307151460783114, 'max_depth': 251, 'subsample': 0.22975989754087844, 'num_leaves': 707, 'colsample_bytree': 0.9040949728487185, 'importance_type': 'gain', 'reg_alpha': 2.946858420246235, 'reg_lambda': 2.427717784501154}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:24:35,889] Trial 403 finished with value: 0.7464188824672171 and parameters: {'learning_rate': 0.1651588353298712, 'max_depth': 289, 'subsample': 0.2017099277963347, 'num_leaves': 756, 'colsample_bytree': 0.9298213979310657, 'importance_type': 'gain', 'reg_alpha': 2.998216606708447, 'reg_lambda': 2.3780051233096065}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:24:51,941] Trial 404 finished with value: 0.7471734254492473 and parameters: {'learning_rate': 0.14892241929680092, 'max_depth': 281, 'subsample': 0.2497555880499138, 'num_leaves': 745, 'colsample_bytree': 0.8786721227435452, 'importance_type': 'gain', 'reg_alpha': 2.8762480112199142, 'reg_lambda': 2.4934622151393926}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:25:06,809] Trial 405 finished with value: 0.7471872034968431 and parameters: {'learning_rate': 0.1735158894753024, 'max_depth': 260, 'subsample': 0.19259191309350268, 'num_leaves': 761, 'colsample_bytree': 0.9317212992977428, 'importance_type': 'gain', 'reg_alpha': 2.8389377735472148, 'reg_lambda': 2.51982293571106}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:25:22,063] Trial 406 finished with value: 0.7441403433705682 and parameters: {'learning_rate': 0.200611284084019, 'max_depth': 287, 'subsample': 0.21710716560393514, 'num_leaves': 800, 'colsample_bytree': 0.9118497086166721, 'importance_type': 'gain', 'reg_alpha': 2.942572433485511, 'reg_lambda': 2.443335195384008}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:25:38,608] Trial 407 finished with value: 0.7474097693054882 and parameters: {'learning_rate': 0.1448807017449936, 'max_depth': 271, 'subsample': 0.27865172258408294, 'num_leaves': 770, 'colsample_bytree': 0.9409935652924487, 'importance_type': 'gain', 'reg_alpha': 2.872815947292369, 'reg_lambda': 2.529237541632348}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:25:54,462] Trial 408 finished with value: 0.7482459868868383 and parameters: {'learning_rate': 0.15499990485113782, 'max_depth': 296, 'subsample': 0.2281158814271763, 'num_leaves': 785, 'colsample_bytree': 0.9576404123509119, 'importance_type': 'gain', 'reg_alpha': 2.998277252641565, 'reg_lambda': 2.375709312533862}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:26:01,046] Trial 409 finished with value: 0.7354414147644488 and parameters: {'learning_rate': 0.13836092871389308, 'max_depth': 237, 'subsample': 0.5259258537469033, 'num_leaves': 211, 'colsample_bytree': 0.9587537365916033, 'importance_type': 'gain', 'reg_alpha': 2.9054256852420313, 'reg_lambda': 2.2684674778786063}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:26:15,952] Trial 410 finished with value: 0.7463027153958233 and parameters: {'learning_rate': 0.1634988931556242, 'max_depth': 278, 'subsample': 0.19599200029110175, 'num_leaves': 741, 'colsample_bytree': 0.9548255690096806, 'importance_type': 'gain', 'reg_alpha': 2.9990030167354775, 'reg_lambda': 2.373277813733183}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:26:32,364] Trial 411 finished with value: 0.7455626503156872 and parameters: {'learning_rate': 0.14618515668555124, 'max_depth': 295, 'subsample': 0.22481379246075942, 'num_leaves': 762, 'colsample_bytree': 0.9656458963448236, 'importance_type': 'gain', 'reg_alpha': 1.598131847577294, 'reg_lambda': 2.320242231254816}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:26:45,535] Trial 412 finished with value: 0.7459757401651288 and parameters: {'learning_rate': 0.13382165279011313, 'max_depth': 289, 'subsample': 0.18018108001661304, 'num_leaves': 660, 'colsample_bytree': 0.9269826740665946, 'importance_type': 'gain', 'reg_alpha': 2.8152892316176334, 'reg_lambda': 2.568999350536441}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:26:56,927] Trial 413 finished with value: 0.7449504395337543 and parameters: {'learning_rate': 0.18366467368118464, 'max_depth': 267, 'subsample': 0.2066132140837909, 'num_leaves': 526, 'colsample_bytree': 0.9672659646288243, 'importance_type': 'gain', 'reg_alpha': 2.9283877211304143, 'reg_lambda': 2.404356305735554}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:27:12,248] Trial 414 finished with value: 0.7465594103933948 and parameters: {'learning_rate': 0.15554361997574118, 'max_depth': 282, 'subsample': 0.17916703759466143, 'num_leaves': 786, 'colsample_bytree': 0.8895517904321861, 'importance_type': 'gain', 'reg_alpha': 2.8211267801246467, 'reg_lambda': 1.2491245312844224}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:27:27,448] Trial 415 finished with value: 0.7463213404565323 and parameters: {'learning_rate': 0.14220125083120963, 'max_depth': 293, 'subsample': 0.2615247846194276, 'num_leaves': 774, 'colsample_bytree': 0.9508087006059277, 'importance_type': 'gain', 'reg_alpha': 2.8923633131891235, 'reg_lambda': 2.5462233677038224}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:27:44,314] Trial 416 finished with value: 0.7481548630403109 and parameters: {'learning_rate': 0.13234819676743909, 'max_depth': 309, 'subsample': 0.22281330204255986, 'num_leaves': 800, 'colsample_bytree': 0.9750605074906823, 'importance_type': 'gain', 'reg_alpha': 2.9425561506634934, 'reg_lambda': 2.488549089118225}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:28:00,352] Trial 417 finished with value: 0.7471046070908207 and parameters: {'learning_rate': 0.13050097477040928, 'max_depth': 306, 'subsample': 0.1659771530357027, 'num_leaves': 800, 'colsample_bytree': 0.9835262104829026, 'importance_type': 'gain', 'reg_alpha': 2.793246676343155, 'reg_lambda': 2.5770388635964205}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:28:16,469] Trial 418 finished with value: 0.7473894963574551 and parameters: {'learning_rate': 0.12384928517898602, 'max_depth': 310, 'subsample': 0.6948870300302923, 'num_leaves': 786, 'colsample_bytree': 0.9812332570679213, 'importance_type': 'gain', 'reg_alpha': 2.856329277679347, 'reg_lambda': 2.493138744102709}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:28:29,393] Trial 419 finished with value: 0.746955493443419 and parameters: {'learning_rate': 0.13555015413343993, 'max_depth': 314, 'subsample': 0.20127256976098815, 'num_leaves': 799, 'colsample_bytree': 0.42858252057065194, 'importance_type': 'gain', 'reg_alpha': 2.935808751726712, 'reg_lambda': 2.369936931047943}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:28:45,425] Trial 420 finished with value: 0.7477274288489557 and parameters: {'learning_rate': 0.12484563535816573, 'max_depth': 300, 'subsample': 0.1833425127972304, 'num_leaves': 775, 'colsample_bytree': 0.9677652534400708, 'importance_type': 'gain', 'reg_alpha': 2.7834458229513612, 'reg_lambda': 2.5860791228538287}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:29:02,711] Trial 421 finished with value: 0.7474438076736281 and parameters: {'learning_rate': 0.13969605283947914, 'max_depth': 319, 'subsample': 0.21913118641185003, 'num_leaves': 786, 'colsample_bytree': 0.9428596238637634, 'importance_type': 'gain', 'reg_alpha': 2.876858575748796, 'reg_lambda': 2.6933629471095166}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:29:15,194] Trial 422 finished with value: 0.7422243812530356 and parameters: {'learning_rate': 0.13187350551665195, 'max_depth': 299, 'subsample': 0.16253311764623848, 'num_leaves': 469, 'colsample_bytree': 0.9665078584198704, 'importance_type': 'gain', 'reg_alpha': 2.645034822984599, 'reg_lambda': 2.5173022542193304}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:29:30,573] Trial 423 finished with value: 0.7479410097134531 and parameters: {'learning_rate': 0.14874155080768003, 'max_depth': 308, 'subsample': 0.19539302772104256, 'num_leaves': 800, 'colsample_bytree': 0.9986197755814074, 'importance_type': 'gain', 'reg_alpha': 2.707727996850317, 'reg_lambda': 2.6310375313892065}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:29:46,401] Trial 424 finished with value: 0.7468567887323945 and parameters: {'learning_rate': 0.12153326868748494, 'max_depth': 328, 'subsample': 0.21682309420492757, 'num_leaves': 769, 'colsample_bytree': 0.9845769501553603, 'importance_type': 'gain', 'reg_alpha': 2.833974703679415, 'reg_lambda': 2.5493146576651378}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:30:02,999] Trial 425 finished with value: 0.7408437867897036 and parameters: {'learning_rate': 0.047315675699384205, 'max_depth': 317, 'subsample': 0.2433371252565683, 'num_leaves': 785, 'colsample_bytree': 0.9516538097640339, 'importance_type': 'gain', 'reg_alpha': 2.9410780705626354, 'reg_lambda': 2.2992654904319787}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:30:19,614] Trial 426 finished with value: 0.7470502569208354 and parameters: {'learning_rate': 0.1335764049361554, 'max_depth': 290, 'subsample': 0.1482666838500655, 'num_leaves': 765, 'colsample_bytree': 0.929301131316462, 'importance_type': 'gain', 'reg_alpha': 2.893050460408044, 'reg_lambda': 2.4588176322070994}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:30:34,682] Trial 427 finished with value: 0.7468711918406994 and parameters: {'learning_rate': 0.14346340718444436, 'max_depth': 325, 'subsample': 0.8013061631823215, 'num_leaves': 785, 'colsample_bytree': 0.9997312041233349, 'importance_type': 'gain', 'reg_alpha': 2.7459649777046353, 'reg_lambda': 2.406270022095213}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:30:44,535] Trial 428 finished with value: 0.7395543487129674 and parameters: {'learning_rate': 0.11082071613748654, 'max_depth': 301, 'subsample': 0.17325195675243235, 'num_leaves': 351, 'colsample_bytree': 0.9685508001659751, 'importance_type': 'gain', 'reg_alpha': 2.8397664397027818, 'reg_lambda': 2.619295968920742}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:30:59,226] Trial 429 finished with value: 0.7450342030111704 and parameters: {'learning_rate': 0.12814904102614025, 'max_depth': 312, 'subsample': 0.18704741271955744, 'num_leaves': 754, 'colsample_bytree': 0.9497119859610063, 'importance_type': 'gain', 'reg_alpha': 1.82818428524029, 'reg_lambda': 2.5164548844058294}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:31:24,095] Trial 430 finished with value: 0.7473105497814474 and parameters: {'learning_rate': 0.1527904310093989, 'max_depth': 330, 'subsample': 0.21008788045608717, 'num_leaves': 800, 'colsample_bytree': 0.9748306665506268, 'importance_type': 'gain', 'reg_alpha': 2.999105174818796, 'reg_lambda': 2.6834097370914147}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:31:39,051] Trial 431 finished with value: 0.7465498960660515 and parameters: {'learning_rate': 0.12145432381809364, 'max_depth': 317, 'subsample': 0.2925550441209618, 'num_leaves': 776, 'colsample_bytree': 0.931414716186609, 'importance_type': 'gain', 'reg_alpha': 2.9393153597019905, 'reg_lambda': 2.5814301871424665}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:31:48,626] Trial 432 finished with value: 0.743131032540068 and parameters: {'learning_rate': 0.13833355162717645, 'max_depth': 292, 'subsample': 0.2492593611533565, 'num_leaves': 787, 'colsample_bytree': 0.48335716579325366, 'importance_type': 'gain', 'reg_alpha': 0.4365230037380936, 'reg_lambda': 0.010135861919250422}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:32:10,221] Trial 433 finished with value: 0.7469388824672171 and parameters: {'learning_rate': 0.1584114716562019, 'max_depth': 301, 'subsample': 0.1331238511961734, 'num_leaves': 764, 'colsample_bytree': 0.982594816942567, 'importance_type': 'gain', 'reg_alpha': 2.789828033866953, 'reg_lambda': 2.434622492331612}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:32:26,863] Trial 434 finished with value: 0.74789080621661 and parameters: {'learning_rate': 0.1161706320835436, 'max_depth': 309, 'subsample': 0.1626725837900873, 'num_leaves': 776, 'colsample_bytree': 0.9568475645174038, 'importance_type': 'gain', 'reg_alpha': 2.889156580287589, 'reg_lambda': 2.350625170342517}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:32:41,807] Trial 435 finished with value: 0.7473145080135988 and parameters: {'learning_rate': 0.1291020420650814, 'max_depth': 334, 'subsample': 0.2266002035367736, 'num_leaves': 800, 'colsample_bytree': 0.9816775300634161, 'importance_type': 'gain', 'reg_alpha': 2.9411925737561546, 'reg_lambda': 2.733092078506809}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:32:53,828] Trial 436 finished with value: 0.7475278115590093 and parameters: {'learning_rate': 0.14386906845353797, 'max_depth': 284, 'subsample': 0.205407095860068, 'num_leaves': 800, 'colsample_bytree': 0.9171633402133653, 'importance_type': 'gain', 'reg_alpha': 2.842683474805904, 'reg_lambda': 2.4965705680009345}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:33:07,187] Trial 437 finished with value: 0.7442996022340942 and parameters: {'learning_rate': 0.13336071832772498, 'max_depth': 321, 'subsample': 0.14448468581866158, 'num_leaves': 491, 'colsample_bytree': 0.9479468684015688, 'importance_type': 'gain', 'reg_alpha': 2.7031560228088773, 'reg_lambda': 2.6237339997514897}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:33:25,184] Trial 438 finished with value: 0.7477829956289461 and parameters: {'learning_rate': 0.12152268652032763, 'max_depth': 272, 'subsample': 0.2651793133192364, 'num_leaves': 757, 'colsample_bytree': 0.9999360426495062, 'importance_type': 'gain', 'reg_alpha': 2.7748506117414693, 'reg_lambda': 2.5533555074275363}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:33:46,124] Trial 439 finished with value: 0.7372185143273433 and parameters: {'learning_rate': 0.034280519052855, 'max_depth': 336, 'subsample': 0.1835412582620602, 'num_leaves': 775, 'colsample_bytree': 0.9672026058852583, 'importance_type': 'gain', 'reg_alpha': 2.900679274233043, 'reg_lambda': 2.6682612340754717}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:34:04,428] Trial 440 finished with value: 0.7469884720738222 and parameters: {'learning_rate': 0.10934406947996651, 'max_depth': 298, 'subsample': 0.1615306454889785, 'num_leaves': 784, 'colsample_bytree': 0.9375489836273636, 'importance_type': 'gain', 'reg_alpha': 2.944977208795893, 'reg_lambda': 2.413763147984006}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:34:21,029] Trial 441 finished with value: 0.7476106673142302 and parameters: {'learning_rate': 0.14970532756363863, 'max_depth': 322, 'subsample': 0.1966350437687856, 'num_leaves': 754, 'colsample_bytree': 0.9607898359671154, 'importance_type': 'gain', 'reg_alpha': 2.845238278443238, 'reg_lambda': 2.481547531467507}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:34:40,140] Trial 442 finished with value: 0.7468688135016999 and parameters: {'learning_rate': 0.16143513459531278, 'max_depth': 311, 'subsample': 0.23635427066722622, 'num_leaves': 800, 'colsample_bytree': 0.9829691928183878, 'importance_type': 'gain', 'reg_alpha': 2.99943414306679, 'reg_lambda': 2.583925422318603}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:34:57,476] Trial 443 finished with value: 0.7468580553666828 and parameters: {'learning_rate': 0.1379604055812211, 'max_depth': 259, 'subsample': 0.17268447539407175, 'num_leaves': 772, 'colsample_bytree': 0.9191427971595421, 'importance_type': 'gain', 'reg_alpha': 2.800879806370621, 'reg_lambda': 2.535112523120902}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:35:13,892] Trial 444 finished with value: 0.7473316172899465 and parameters: {'learning_rate': 0.12398416411945964, 'max_depth': 291, 'subsample': 0.127023040426611, 'num_leaves': 786, 'colsample_bytree': 0.9623164591003683, 'importance_type': 'gain', 'reg_alpha': 2.8922343144653584, 'reg_lambda': 2.717154296440116}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:35:33,095] Trial 445 finished with value: 0.746008704225352 and parameters: {'learning_rate': 0.11433856052615946, 'max_depth': 328, 'subsample': 0.2163414298515389, 'num_leaves': 763, 'colsample_bytree': 0.9399185090943833, 'importance_type': 'gain', 'reg_alpha': 2.999220044531127, 'reg_lambda': 2.229612744000594}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:35:50,023] Trial 446 finished with value: 0.7369478771248179 and parameters: {'learning_rate': 0.32719834527813524, 'max_depth': 308, 'subsample': 0.19175934872623646, 'num_leaves': 787, 'colsample_bytree': 0.9831633200354029, 'importance_type': 'gain', 'reg_alpha': 2.7373967020744727, 'reg_lambda': 1.4492125623047758}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:36:07,855] Trial 447 finished with value: 0.7474113229723166 and parameters: {'learning_rate': 0.13158254510355674, 'max_depth': 243, 'subsample': 0.1473137427246409, 'num_leaves': 747, 'colsample_bytree': 0.9989856314734682, 'importance_type': 'gain', 'reg_alpha': 2.9272515632082476, 'reg_lambda': 2.3581815792601173}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:36:25,508] Trial 448 finished with value: 0.7475104885866926 and parameters: {'learning_rate': 0.14567459885549042, 'max_depth': 282, 'subsample': 0.2762614053458658, 'num_leaves': 773, 'colsample_bytree': 0.9622009467637096, 'importance_type': 'gain', 'reg_alpha': 2.8529198636237996, 'reg_lambda': 2.447477881390929}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:36:46,611] Trial 449 finished with value: 0.7466367498785818 and parameters: {'learning_rate': 0.1590316956187079, 'max_depth': 340, 'subsample': 0.2490211120347251, 'num_leaves': 800, 'colsample_bytree': 0.9092259915929979, 'importance_type': 'gain', 'reg_alpha': 2.668249544487295, 'reg_lambda': 2.6142141126941643}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:37:05,823] Trial 450 finished with value: 0.7474976561437591 and parameters: {'learning_rate': 0.14015705484916602, 'max_depth': 317, 'subsample': 0.22350109099051987, 'num_leaves': 783, 'colsample_bytree': 0.9389121296763318, 'importance_type': 'gain', 'reg_alpha': 2.9435951878604247, 'reg_lambda': 2.5034270148802933}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:37:22,397] Trial 451 finished with value: 0.74626222486644 and parameters: {'learning_rate': 0.12300475046977853, 'max_depth': 303, 'subsample': 0.17917853399271033, 'num_leaves': 763, 'colsample_bytree': 0.978413950871287, 'importance_type': 'gain', 'reg_alpha': 2.779538031340466, 'reg_lambda': 2.6764453822423193}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:37:39,568] Trial 452 finished with value: 0.7465415900922778 and parameters: {'learning_rate': 0.10559332722920554, 'max_depth': 269, 'subsample': 0.15924099414157988, 'num_leaves': 786, 'colsample_bytree': 0.955013143028421, 'importance_type': 'gain', 'reg_alpha': 2.881484447186622, 'reg_lambda': 2.7740485665800176}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:37:57,959] Trial 453 finished with value: 0.7480403297717338 and parameters: {'learning_rate': 0.17187516738551045, 'max_depth': 328, 'subsample': 0.19788017591686108, 'num_leaves': 800, 'colsample_bytree': 0.9843149339297198, 'importance_type': 'gain', 'reg_alpha': 2.8172764917060067, 'reg_lambda': 2.416402255298248}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:38:12,669] Trial 454 finished with value: 0.744851033997086 and parameters: {'learning_rate': 0.19251246623958893, 'max_depth': 324, 'subsample': 0.19272619503587923, 'num_leaves': 726, 'colsample_bytree': 0.9822310969667625, 'importance_type': 'gain', 'reg_alpha': 2.948618232526628, 'reg_lambda': 2.29600018424471}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:38:28,702] Trial 455 finished with value: 0.7474816784847014 and parameters: {'learning_rate': 0.17432775647188578, 'max_depth': 314, 'subsample': 0.21003259515981182, 'num_leaves': 772, 'colsample_bytree': 0.9824824197888489, 'importance_type': 'gain', 'reg_alpha': 2.8249446842401302, 'reg_lambda': 2.3728199133107726}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:38:46,955] Trial 456 finished with value: 0.7465156561437591 and parameters: {'learning_rate': 0.11623204953041308, 'max_depth': 296, 'subsample': 0.1711574638736489, 'num_leaves': 749, 'colsample_bytree': 0.9673919403564297, 'importance_type': 'gain', 'reg_alpha': 2.7507209984007184, 'reg_lambda': 2.422823698428168}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:39:05,929] Trial 457 finished with value: 0.7464471024769306 and parameters: {'learning_rate': 0.08514314072181044, 'max_depth': 329, 'subsample': 0.13212985142665995, 'num_leaves': 786, 'colsample_bytree': 0.9544376771181228, 'importance_type': 'gain', 'reg_alpha': 2.896966619226487, 'reg_lambda': 2.4639092229339434}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:39:23,939] Trial 458 finished with value: 0.74674738756678 and parameters: {'learning_rate': 0.1311756049019939, 'max_depth': 433, 'subsample': 0.20196554078858153, 'num_leaves': 800, 'colsample_bytree': 0.9988090688031188, 'importance_type': 'gain', 'reg_alpha': 1.4393113306156662, 'reg_lambda': 2.553574637350581}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:39:41,175] Trial 459 finished with value: 0.7466223909664885 and parameters: {'learning_rate': 0.1491660160126048, 'max_depth': 307, 'subsample': 0.15390606254299694, 'num_leaves': 761, 'colsample_bytree': 0.9746486016248962, 'importance_type': 'gain', 'reg_alpha': 2.9492370214082975, 'reg_lambda': 2.3437947890260316}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:39:59,179] Trial 460 finished with value: 0.7467587027683341 and parameters: {'learning_rate': 0.12514329804479252, 'max_depth': 412, 'subsample': 0.18345685457420483, 'num_leaves': 775, 'colsample_bytree': 0.9493834759513042, 'importance_type': 'gain', 'reg_alpha': 2.6066385060562642, 'reg_lambda': 2.412348074718553}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:40:07,048] Trial 461 finished with value: 0.7392520898494415 and parameters: {'learning_rate': 0.14156719738915124, 'max_depth': 319, 'subsample': 0.23050891050876507, 'num_leaves': 300, 'colsample_bytree': 0.9995056447822293, 'importance_type': 'gain', 'reg_alpha': 2.8529218203194295, 'reg_lambda': 2.5068815392475163}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:40:25,228] Trial 462 finished with value: 0.7463770179698883 and parameters: {'learning_rate': 0.11341484367590385, 'max_depth': 287, 'subsample': 0.2018149930814791, 'num_leaves': 786, 'colsample_bytree': 0.9702218584053416, 'importance_type': 'gain', 'reg_alpha': 0.9467947250733206, 'reg_lambda': 2.6242593108067758}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:40:41,642] Trial 463 finished with value: 0.746617063623118 and parameters: {'learning_rate': 0.13394903826879132, 'max_depth': 333, 'subsample': 0.16896883144148053, 'num_leaves': 756, 'colsample_bytree': 0.9355819964585927, 'importance_type': 'gain', 'reg_alpha': 2.8022959660465196, 'reg_lambda': 2.5736442095993035}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:40:59,988] Trial 464 finished with value: 0.7460155662943176 and parameters: {'learning_rate': 0.17226334520668599, 'max_depth': 276, 'subsample': 0.14207191733857708, 'num_leaves': 775, 'colsample_bytree': 0.9832961095626354, 'importance_type': 'gain', 'reg_alpha': 2.7252219373636444, 'reg_lambda': 2.484014404204509}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:41:17,652] Trial 465 finished with value: 0.7471111646430306 and parameters: {'learning_rate': 0.15223103813920222, 'max_depth': 300, 'subsample': 0.12545262946478594, 'num_leaves': 800, 'colsample_bytree': 0.9646903785543226, 'importance_type': 'gain', 'reg_alpha': 2.8959956260904676, 'reg_lambda': 2.25612810704427}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:41:36,836] Trial 466 finished with value: 0.7479165123846527 and parameters: {'learning_rate': 0.12061939705205853, 'max_depth': 316, 'subsample': 0.2159158452158533, 'num_leaves': 733, 'colsample_bytree': 0.9994830479374729, 'importance_type': 'gain', 'reg_alpha': 2.947637979998162, 'reg_lambda': 2.4041442760746277}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:41:56,089] Trial 467 finished with value: 0.746823195240408 and parameters: {'learning_rate': 0.1304611104822014, 'max_depth': 327, 'subsample': 0.18448133456971177, 'num_leaves': 786, 'colsample_bytree': 0.93750999764494, 'importance_type': 'gain', 'reg_alpha': 2.998397796619537, 'reg_lambda': 2.6651378125688865}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:42:15,118] Trial 468 finished with value: 0.7467835211267605 and parameters: {'learning_rate': 0.09981744315768411, 'max_depth': 306, 'subsample': 0.16367558229155577, 'num_leaves': 768, 'colsample_bytree': 0.9569769593109232, 'importance_type': 'gain', 'reg_alpha': 2.8534323605100678, 'reg_lambda': 2.541498283777982}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:42:29,037] Trial 469 finished with value: 0.7467932340942205 and parameters: {'learning_rate': 0.16124056273843418, 'max_depth': 262, 'subsample': 0.11020802422499998, 'num_leaves': 800, 'colsample_bytree': 0.5532241585609746, 'importance_type': 'gain', 'reg_alpha': 2.1796299499439855, 'reg_lambda': 2.457010762488172}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:42:41,559] Trial 470 finished with value: 0.7419675949490044 and parameters: {'learning_rate': 0.1420584833275766, 'max_depth': 292, 'subsample': 0.1984496708250057, 'num_leaves': 747, 'colsample_bytree': 0.2107673553882512, 'importance_type': 'gain', 'reg_alpha': 2.798356047121624, 'reg_lambda': 2.3329565056093213}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:43:03,247] Trial 471 finished with value: 0.7466098547838756 and parameters: {'learning_rate': 0.12698410500748453, 'max_depth': 336, 'subsample': 0.2272911885918234, 'num_leaves': 775, 'colsample_bytree': 0.9744856716011735, 'importance_type': 'gain', 'reg_alpha': 2.998966563296436, 'reg_lambda': 2.601561614296623}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:43:25,075] Trial 472 finished with value: 0.7462836619718309 and parameters: {'learning_rate': 0.11080889775070657, 'max_depth': 321, 'subsample': 0.1452798294007557, 'num_leaves': 787, 'colsample_bytree': 0.9264880127026689, 'importance_type': 'gain', 'reg_alpha': 2.6578761781037965, 'reg_lambda': 2.7158805434942317}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:43:45,853] Trial 473 finished with value: 0.7471762821758136 and parameters: {'learning_rate': 0.13648814767398135, 'max_depth': 282, 'subsample': 0.18671277697596533, 'num_leaves': 762, 'colsample_bytree': 0.9484725346182076, 'importance_type': 'gain', 'reg_alpha': 2.90545822697033, 'reg_lambda': 2.5235824128859385}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:44:07,267] Trial 474 finished with value: 0.7467706415735794 and parameters: {'learning_rate': 0.15226936859974538, 'max_depth': 312, 'subsample': 0.1630080493195435, 'num_leaves': 784, 'colsample_bytree': 0.9999464224481875, 'importance_type': 'gain', 'reg_alpha': 2.726239662664013, 'reg_lambda': 2.6192679154189697}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:44:29,061] Trial 475 finished with value: 0.7467621170471103 and parameters: {'learning_rate': 0.11903728067132217, 'max_depth': 301, 'subsample': 0.20848561572547555, 'num_leaves': 800, 'colsample_bytree': 0.9792678213003907, 'importance_type': 'gain', 'reg_alpha': 2.891248700665753, 'reg_lambda': 2.402971484048541}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:44:50,804] Trial 476 finished with value: 0.7480607547353084 and parameters: {'learning_rate': 0.13924175377927567, 'max_depth': 340, 'subsample': 0.23608967115402363, 'num_leaves': 749, 'colsample_bytree': 0.9653740188450705, 'importance_type': 'gain', 'reg_alpha': 2.8321310703774505, 'reg_lambda': 2.4653893721918556}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:45:12,991] Trial 477 finished with value: 0.747373401651287 and parameters: {'learning_rate': 0.13438032408432884, 'max_depth': 342, 'subsample': 0.17883092384998145, 'num_leaves': 729, 'colsample_bytree': 0.9695191182543076, 'importance_type': 'gain', 'reg_alpha': 2.7832292216931194, 'reg_lambda': 2.5515848010114524}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:45:34,208] Trial 478 finished with value: 0.7465090893637688 and parameters: {'learning_rate': 0.12285760928098502, 'max_depth': 342, 'subsample': 0.2341976677636691, 'num_leaves': 709, 'colsample_bytree': 0.9828695688910856, 'importance_type': 'gain', 'reg_alpha': 2.708303967549648, 'reg_lambda': 2.7567118448436823}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:45:58,501] Trial 479 finished with value: 0.7469314152501214 and parameters: {'learning_rate': 0.13600057920454503, 'max_depth': 329, 'subsample': 0.09811148679545403, 'num_leaves': 746, 'colsample_bytree': 0.958857163015597, 'importance_type': 'gain', 'reg_alpha': 2.819406418001287, 'reg_lambda': 2.6526390021092356}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:46:21,758] Trial 480 finished with value: 0.747245340942205 and parameters: {'learning_rate': 0.14560850174246703, 'max_depth': 332, 'subsample': 0.12756673541176836, 'num_leaves': 749, 'colsample_bytree': 0.9844374923119328, 'importance_type': 'gain', 'reg_alpha': 2.777452320443571, 'reg_lambda': 2.4958225917295667}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:46:44,380] Trial 481 finished with value: 0.7471348280718796 and parameters: {'learning_rate': 0.12716337812264628, 'max_depth': 348, 'subsample': 0.1521584629914694, 'num_leaves': 766, 'colsample_bytree': 0.9592390889111734, 'importance_type': 'gain', 'reg_alpha': 2.846141601613964, 'reg_lambda': 2.5992071961975616}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:47:06,229] Trial 482 finished with value: 0.7483063045167557 and parameters: {'learning_rate': 0.11739921975488209, 'max_depth': 228, 'subsample': 0.20928888720540398, 'num_leaves': 686, 'colsample_bytree': 0.9812149047482076, 'importance_type': 'gain', 'reg_alpha': 2.7457968442093006, 'reg_lambda': 2.559979254513101}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:47:28,374] Trial 483 finished with value: 0.7449671622146672 and parameters: {'learning_rate': 0.09339702411513298, 'max_depth': 207, 'subsample': 0.21393310074520006, 'num_leaves': 693, 'colsample_bytree': 0.985679312641258, 'importance_type': 'gain', 'reg_alpha': 2.6395160801802584, 'reg_lambda': 2.571140569342204}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:47:50,732] Trial 484 finished with value: 0.7450273710539096 and parameters: {'learning_rate': 0.1075607729646546, 'max_depth': 322, 'subsample': 0.24243975316620747, 'num_leaves': 672, 'colsample_bytree': 0.978961938691363, 'importance_type': 'gain', 'reg_alpha': 2.6887387535956426, 'reg_lambda': 2.5057786484962117}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:48:14,923] Trial 485 finished with value: 0.7467333851384167 and parameters: {'learning_rate': 0.10085481011503818, 'max_depth': 230, 'subsample': 0.20082781350186163, 'num_leaves': 771, 'colsample_bytree': 0.9657955656714576, 'importance_type': 'gain', 'reg_alpha': 2.741924310306421, 'reg_lambda': 2.703419494057973}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:48:38,262] Trial 486 finished with value: 0.7478851690140845 and parameters: {'learning_rate': 0.11237495848514197, 'max_depth': 339, 'subsample': 0.2202201703429976, 'num_leaves': 713, 'colsample_bytree': 0.997152417715694, 'importance_type': 'gain', 'reg_alpha': 2.8462455670026037, 'reg_lambda': 2.4568378446024974}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.391531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:49:04,113] Trial 487 finished with value: 0.7471845424963575 and parameters: {'learning_rate': 0.117993389339572, 'max_depth': 222, 'subsample': 0.19085617398133972, 'num_leaves': 785, 'colsample_bytree': 0.9666002876316904, 'importance_type': 'gain', 'reg_alpha': 2.883373253633357, 'reg_lambda': 2.648193951649282}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:49:26,246] Trial 488 finished with value: 0.7471554225352113 and parameters: {'learning_rate': 0.14755329047357807, 'max_depth': 321, 'subsample': 0.23849207144334944, 'num_leaves': 759, 'colsample_bytree': 0.9849655296842251, 'importance_type': 'gain', 'reg_alpha': 2.7590317844017362, 'reg_lambda': 2.5469699932784153}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:49:48,301] Trial 489 finished with value: 0.7465993584264206 and parameters: {'learning_rate': 0.12805218834034748, 'max_depth': 244, 'subsample': 0.21289916337192005, 'num_leaves': 800, 'colsample_bytree': 0.9496238167056132, 'importance_type': 'gain', 'reg_alpha': 2.9247738677379456, 'reg_lambda': 2.3847808219996858}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.242329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:50:11,317] Trial 490 finished with value: 0.7474478795531811 and parameters: {'learning_rate': 0.11513357686481257, 'max_depth': 211, 'subsample': 0.1788820618885471, 'num_leaves': 772, 'colsample_bytree': 0.9978976589985593, 'importance_type': 'gain', 'reg_alpha': 2.83107027006409, 'reg_lambda': 2.6045646836823746}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.559014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:50:34,555] Trial 491 finished with value: 0.7468773370568237 and parameters: {'learning_rate': 0.10374817225050738, 'max_depth': 332, 'subsample': 0.2493959072588245, 'num_leaves': 786, 'colsample_bytree': 0.9712340438633031, 'importance_type': 'gain', 'reg_alpha': 2.945422641656662, 'reg_lambda': 2.493468024192748}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:50:54,306] Trial 492 finished with value: 0.7463061568722681 and parameters: {'learning_rate': 0.14020158944268926, 'max_depth': 312, 'subsample': 0.19738141816811688, 'num_leaves': 730, 'colsample_bytree': 0.9496482832966016, 'importance_type': 'gain', 'reg_alpha': 2.7976050587418637, 'reg_lambda': 2.3013762877998944}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:51:09,896] Trial 493 finished with value: 0.7429594589606605 and parameters: {'learning_rate': 0.12109792344573554, 'max_depth': 324, 'subsample': 0.2222105570329908, 'num_leaves': 410, 'colsample_bytree': 0.9820647072566382, 'importance_type': 'gain', 'reg_alpha': 2.8888178557358652, 'reg_lambda': 2.5617955248365787}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:51:31,598] Trial 494 finished with value: 0.7466899946576007 and parameters: {'learning_rate': 0.135115114421645, 'max_depth': 339, 'subsample': 0.18133177515690135, 'num_leaves': 773, 'colsample_bytree': 0.9638657796335851, 'importance_type': 'gain', 'reg_alpha': 2.714943083490253, 'reg_lambda': 2.4321815287072}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:51:46,799] Trial 495 finished with value: 0.7465226629431763 and parameters: {'learning_rate': 0.1575237125003281, 'max_depth': 312, 'subsample': 0.48035760905121827, 'num_leaves': 754, 'colsample_bytree': 0.9986147516670127, 'importance_type': 'gain', 'reg_alpha': 0.7642963165027357, 'reg_lambda': 2.666662043389693}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:52:04,326] Trial 496 finished with value: 0.748215896551724 and parameters: {'learning_rate': 0.1264108483276429, 'max_depth': 350, 'subsample': 0.16821668657964295, 'num_leaves': 785, 'colsample_bytree': 0.9312301160584129, 'importance_type': 'gain', 'reg_alpha': 2.8515138420750934, 'reg_lambda': 2.7638910943851003}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:52:10,362] Trial 497 finished with value: 0.7396808921806702 and parameters: {'learning_rate': 0.11626699703768467, 'max_depth': 357, 'subsample': 0.4012999934705652, 'num_leaves': 799, 'colsample_bytree': 0.112944190604506, 'importance_type': 'gain', 'reg_alpha': 2.634562711945515, 'reg_lambda': 2.84759513903487}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:52:29,024] Trial 498 finished with value: 0.7465060611947547 and parameters: {'learning_rate': 0.12454533467948847, 'max_depth': 199, 'subsample': 0.2057075291704242, 'num_leaves': 800, 'colsample_bytree': 0.9246005025992804, 'importance_type': 'gain', 'reg_alpha': 2.771217222005033, 'reg_lambda': 2.7200479030475773}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 14:52:46,077] Trial 499 finished with value: 0.7460909218067023 and parameters: {'learning_rate': 0.10848282938529351, 'max_depth': 353, 'subsample': 0.2256812693868844, 'num_leaves': 784, 'colsample_bytree': 0.9418306792295372, 'importance_type': 'gain', 'reg_alpha': 1.9969984102931873, 'reg_lambda': 2.7845894554845367}. Best is trial 286 with value: 0.7486957940747936.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.12457135642732306, 'max_depth': 314, 'subsample': 0.18331318829770638, 'num_leaves': 785, 'colsample_bytree': 0.9413679345498897, 'importance_type': 'gain', 'reg_alpha': 2.7815667819632477, 'reg_lambda': 2.6078548972943905}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    }
   ],
   "source": [
    "best_params = {'learning_rate': 0.12457135642732306, 'max_depth': 314, 'subsample': 0.18331318829770638, 'num_leaves': 785, 'colsample_bytree': 0.9413679345498897, 'importance_type': 'gain', 'reg_alpha': 2.7815667819632477, 'reg_lambda': 2.6078548972943905, 'random_state': 42}\n",
    "clf = LGBMClassifier(**best_params) \n",
    "clf.fit(\n",
    "    X=df.loc[df['sample_part'] == 'train', features_optuna],\n",
    "    y=df.loc[df['sample_part'] == 'train', TARGET]\n",
    ")\n",
    "\n",
    "preds_test = clf.predict_proba(df.loc[df['sample_part'] == 'test', features_optuna])[:, 1]\n",
    "auc_test = roc_auc_score(\n",
    "    y_true=df.loc[df['sample_part'] == 'test', TARGET],\n",
    "    y_score=preds_test\n",
    ")\n",
    "assert auc_test > 0.725, f'Необходимое значение ROC-AUC 0.725 и выше, ваше значение: {auc_test}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7280124315421249"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кривые накопления (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Отрисуйте кривые накопления `ROC AUC` от `n_estimators` для бустинга с гиперпараметрами из предыдущего пункта.\n",
    "\n",
    "**Hint:** для получения auc на каждой итерации обучения `LGBMClassifier`, можно воспользоваться параметрами `eval_set`, `eval_metric` и в методе `fit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.9413679345498897, importance_type=&#x27;gain&#x27;,\n",
       "               learning_rate=0.12457135642732306, max_depth=314, num_leaves=785,\n",
       "               random_state=42, reg_alpha=2.7815667819632477,\n",
       "               reg_lambda=2.6078548972943905, subsample=0.18331318829770638)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.9413679345498897, importance_type=&#x27;gain&#x27;,\n",
       "               learning_rate=0.12457135642732306, max_depth=314, num_leaves=785,\n",
       "               random_state=42, reg_alpha=2.7815667819632477,\n",
       "               reg_lambda=2.6078548972943905, subsample=0.18331318829770638)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.9413679345498897, importance_type='gain',\n",
       "               learning_rate=0.12457135642732306, max_depth=314, num_leaves=785,\n",
       "               random_state=42, reg_alpha=2.7815667819632477,\n",
       "               reg_lambda=2.6078548972943905, subsample=0.18331318829770638)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(**best_params)\n",
    "\n",
    "lgbm.fit(X=df.loc[df['sample_part'] == 'train', features_optuna],\n",
    "    y=df.loc[df['sample_part'] == 'train', TARGET],\n",
    "    eval_set= [(df.loc[df['sample_part'] == 'test', features_optuna], \n",
    "              df.loc[df['sample_part'] == 'test', TARGET])], \n",
    "    eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc_scores = lgbm.evals_result_['valid_0']['auc']\n",
    "\n",
    "plt.plot(range(len(auc_scores)), auc_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.title('Dependence of ROC AUC on n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Что вы видите на полученных графиках? \n",
    "\n",
    "Нужно ли \"обрезать\" количество деревьев? Ответ обоснуйте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** Да, можно обрезать количество деревьев ~ до 85. Это упростит модель и ускорит ее работу, незначительно уменьшив точность.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте проверим auc_test при 85 n_esimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 177320, number of negative: 72680\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13591\n",
      "[LightGBM] [Info] Number of data points in the train set: 250000, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.709280 -> initscore=0.891890\n",
      "[LightGBM] [Info] Start training from score 0.891890\n",
      "ROC AUC при n_estimators = 85:  0.727238033723156\n",
      "Это на 0.0007743978189689305 меньше, чем при n_estimators = 100\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(**best_params, n_estimators=85)\n",
    "\n",
    "lgbm.fit(X=df.loc[df['sample_part'] == 'train', features_optuna],\n",
    "    y=df.loc[df['sample_part'] == 'train', TARGET],\n",
    "    eval_set= [(df.loc[df['sample_part'] == 'test', features_optuna], \n",
    "              df.loc[df['sample_part'] == 'test', TARGET])], \n",
    "    eval_metric='auc')\n",
    "\n",
    "preds_test = lgbm.predict_proba(df.loc[df['sample_part'] == 'test', features_optuna])[:, 1]\n",
    "auc_test2 = roc_auc_score(\n",
    "    y_true=df.loc[df['sample_part'] == 'test', TARGET],\n",
    "    y_score=preds_test\n",
    ")\n",
    "print('ROC AUC при n_estimators = 85: ', auc_test2)\n",
    "print('Это на', auc_test - auc_test2, 'меньше, чем при n_estimators = 100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, auc при уменьшении n_estimators несильно изменился.  \n",
    "Также отмечу, что если наша цель auc >= 0.725, то n_estimators можно еще уменьшить ~ до 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность признаков (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Постойте гистограмму важности признаков по `split` и `gain` для бустинга из предыдущего пункта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "lightgbm.plot_importance(lgbm, importance_type='split', max_num_features=30, ax=plt.gca())\n",
    "plt.title(\"Feature Importance by Split\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "lightgbm.plot_importance(lgbm, importance_type='gain', max_num_features=30, ax=plt.gca())\n",
    "plt.title(\"Feature Importance by Gain\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** Какие выводы можно сделать из полученных графиков?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance by gain:** важность признака, исходя из улучшения метрики от разделения узла по определенному признаку.  \n",
    "**Importance by split:** важность признака, исходя из количества разделений узлов дерева по определенному признаку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** Исходя из графиков и из опредений gain, split получаем:\n",
    "1. Различный порядок важности признаков для split и gain\n",
    "2. Если рассматривать топ 30 по важности признаков, то почти все они есть и в split и в gain\n",
    "3. Небольшое отклонение кол-ва разделений в признаках по split, если не смотреть на 'feature_223'\n",
    "4. По gain отклонение в среднем побольше между признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логрег"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot_metric_time (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Реализуйте функцию plot_metric_time, которая будет принимать на вход четыре аргумента, а именно: \n",
    "- массив значений фичи, \n",
    "- массив значений таргета,\n",
    "- массив времени (аггрегированного по месяцам или кварталам, то есть `month` или `quarter` в вашей задаче, по дням рисовать не надо),\n",
    "- метрику, которую необходимо отрисовать (нужно реализовать функцию для двух метрик: `IV` и `roc_auc`)\n",
    "- число бакетов для вычисления `IV`, если выбрана эта метрика\n",
    "\n",
    "Можете добваить какие-то ещё аргументы, если вам нужно\n",
    "\n",
    "Если в фиче есть пропуски, функция должна убирать строки с пропусками из рассмотрения\n",
    "\n",
    "**Hint**: можно, конечно, реализовать эту функцию через цикл, а можно попробовать разобраться и реализовать её через пандасовские `groupby` -> `apply`, это изящнее и быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_time(\n",
    "        values: pd.Series,\n",
    "        target: pd.Series,\n",
    "        time: pd.Series,\n",
    "        metric: str = 'IV',\n",
    "        n_buckets_for_IV: int = 15\n",
    ") -> go.Figure:\n",
    "    mask = ~values.isna()\n",
    "    values_without_nan = values[mask]\n",
    "    target_without_nan = target[mask]\n",
    "    time_without_nan = time[mask]\n",
    "    data_time = pd.DataFrame({'values': values_without_nan, 'target': target_without_nan, 'time': time_without_nan}).groupby('time')\n",
    "    if metric == 'IV':\n",
    "        metric_values = data_time.apply(lambda x: IV_score(x['target'], calc_buckets(x['values'], n_buckets_for_IV)), include_groups=False)\n",
    "    elif metric == 'roc_auc':\n",
    "        metric_values = data_time.apply(lambda x: roc_auc_score(x['target'], x['values']), include_groups=False)\n",
    "    else:\n",
    "        raise NotImplementedError(\"only 'IV' and 'roc_auc' metrics are implemented\")\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    plot_title = f'{values.name}'\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=metric_values.index,\n",
    "            y=metric_values.values,\n",
    "            mode='markers+lines',\n",
    "            name=values.name\n",
    "            ))\n",
    "    fig.update_layout(\n",
    "            title_text=plot_title,\n",
    "            yaxis=dict(title=metric, range=[0, 0.06]),\n",
    "            width=1000,\n",
    "            height=450,\n",
    "            xaxis=dict(\n",
    "                domain=[0, .95],\n",
    "                showgrid=True,\n",
    "                tickvals=metric_values.index\n",
    "                ),\n",
    "            margin=dict(l=30, r=30, b=30, t=50),\n",
    "            )\n",
    "    fig.show()\n",
    "\n",
    "    # return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# примерно так это должно будет выглядеть\n",
    "# plot_metric_time(df[...], df['target'], df['quarter']) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Возьмите **топ-15** фичей получившегося бустинга по важности по `gain`. Отрисуйте для них графики стабильности по `IV` во времени и удалите из рассмотрения те признаки, качество которых деградирует\n",
    "\n",
    "**NB!** Обращайте внимание на масштаб оси *y!* Иногда признак стабильнее, чем кажется)\n",
    "\n",
    "Если вам это мешает, можете поменять ось *y*, чтобы она начиналась от нуля в прошлом задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = reversed(lgbm.feature_importances_.argsort()[-15:])\n",
    "top15features = [features_optuna[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_124",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.038279438363219453,
          0.05011046287338313,
          0.03843795281338347,
          0.03264979679246477,
          0.024242518800450204,
          0.043345241441916316,
          0.04519608881154284,
          0.04390283921043387,
          0.041365015247600195,
          0.0341155920867964,
          0.03606198670253747,
          0.03671013367511265,
          0.03718193663117445,
          0.05153113867907084,
          0.043161895259118,
          0.04237012890327762,
          0.03607963812484952,
          0.04436085595519422,
          0.03933806121295138,
          0.04247761005636694,
          0.03799929854947712,
          0.03809607174601667,
          0.03879121549746838,
          0.03613907224205464
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_124"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_30",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.03000039770759582,
          0.025604174506041858,
          0.03737701298238197,
          0.04340338055474126,
          0.034278841036287915,
          0.022152505171889995,
          0.027810656829465045,
          0.036704081846568384,
          0.039335566500220395,
          0.029071346865872403,
          0.02941495407687395,
          0.026348748272813322,
          0.032108920782553826,
          0.03056855763430911,
          0.022387770480224237,
          0.035933869193245496,
          0.02639408953012295,
          0.020276329167517572,
          0.04498922974978906,
          0.03909895411393209,
          0.029893541840114737,
          0.02880408364088178,
          0.021905940212483155,
          0.03005668603180585
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_30"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_213",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.006668445304313763,
          0.015114014452872799,
          0.01086775047158391,
          0.0077706143765231455,
          0.006368909994468384,
          0.008658695097782502,
          0.0138481282521651,
          0.014150188675871653,
          0.007365584829637408,
          0.005443161050314104,
          0.007517849493540512,
          0.010466854985482983,
          0.008862668490032023,
          0.010564556594360265,
          0.009335124720368584,
          0.004197765337345809,
          0.005340416936315404,
          0.010406500203622137,
          0.013089093468845134,
          0.00888963192423185,
          0.005823379776094468,
          0.009775478451063347,
          0.006131867057069458,
          0.009152516775246842
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_213"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_154",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.012631421643033816,
          0.009902709469130617,
          0.011467969599231801,
          0.014846681541629641,
          0.014796747834941809,
          0.011520780586360739,
          0.018022923475651226,
          0.014770001501519681,
          0.012672256767088644,
          0.011368908228964886,
          0.015110714614663661,
          0.01698886918089089,
          0.014758840219823245,
          0.012241559580028549,
          0.011279481923899892,
          0.008577911600878257,
          0.006175361172720422,
          0.007615640502528756,
          0.005758768232430239,
          0.003504517360283982,
          0.006079394162146642,
          0.0036040603170041513,
          0.0065835208619488056,
          0.006028107275442827
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_154"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_24",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.016181152774591277,
          0.021803599212459834,
          0.01537270940578122,
          0.012455899960379147,
          0.015947926358213266,
          0.013952157102425741,
          0.008910286636250184,
          0.017343533316665927,
          0.013248168446121849,
          0.016606603856904836,
          0.016013509823187035,
          0.014930706422300759,
          0.016470169792094605,
          0.014106141567360512,
          0.01558530020762566,
          0.015034687248244702,
          0.013335630476646805,
          0.010420079046052312,
          0.012457206407958506,
          0.00969285580455266,
          0.01565958587847212,
          0.020620938072141763,
          0.017630648369626148,
          0.024944547140341222
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_24"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_223",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.014803857434839248,
          0.009971644176550495,
          0.015391591454495274,
          0.014767195427055669,
          0.013267517130975385,
          0.015425572689551208,
          0.015452047602695038,
          0.01586412900299538,
          0.011689297759926928,
          0.011248742914364254,
          0.012938708482483133,
          0.011942267648856444,
          0.02075163891692131,
          0.01647070179609459,
          0.014066138023925473,
          0.018681948004199114,
          0.012463930678026536,
          0.018353824539947033,
          0.01761024887725629,
          0.01618486381017436,
          0.01693390900465506,
          0.019249671586857846,
          0.01562594416538858,
          0.015011458845695491
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_223"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_117",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.026050620858666523,
          0.030959339876569878,
          0.03400038673061678,
          0.02752695037144328,
          0.031326119021890454,
          0.03710919555603767,
          0.033077328364661866,
          0.03139522586143544,
          0.03560089553313764,
          0.026313094655348278,
          0.03554266535927052,
          0.034794981925759264,
          0.02325756915408568,
          0.03455339582283664,
          0.028762951304322916,
          0.024012085936834692,
          0.03258922618718826,
          0.03219827612131788,
          0.02699891153056634,
          0.03328205537399605,
          0.041208769432640825,
          0.028047948672029727,
          0.028203438950382676,
          0.018808629515683337
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_117"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_46",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.016979957858135653,
          0.017037991287258455,
          0.016722236948073826,
          0.020070386284069125,
          0.022232196935787804,
          0.019707000162242604,
          0.015820319102089534,
          0.019685172081973283,
          0.01352770010857926,
          0.017053859335856396,
          0.01703570463750013,
          0.01393052066703249,
          0.017306623337379833,
          0.015857293528581992,
          0.0168053814855494,
          0.017302646595473477,
          0.017705329287975365,
          0.0225898839683997,
          0.01805020650144507,
          0.023521382026550075,
          0.01609402014972001,
          0.022332737715023344,
          0.016268442255068634,
          0.013025223271581215
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_46"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_140",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.012409796651265115,
          0.015699837004980323,
          0.016409018970624738,
          0.013540834481290346,
          0.01470040039486066,
          0.01812937353671546,
          0.015030926145022633,
          0.01101798625052651,
          0.016400583059842003,
          0.015367301355028631,
          0.012116458240530476,
          0.01022164124905786,
          0.015191202032155338,
          0.016471483410171132,
          0.02050842780220323,
          0.018014873426079086,
          0.011909115006956027,
          0.013926515202015481,
          0.018233645329514648,
          0.013833220933375284,
          0.0217555067561989,
          0.013803693792648536,
          0.014258785566003754,
          0.02182827171261171
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_140"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_5",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.010282130441050443,
          0.007968551840275177,
          0.009768724409483603,
          0.004255187942630417,
          0.006999084049235616,
          0.007895314365630339,
          0.009313101856225005,
          0.007602369516600023,
          0.013916872572765172,
          0.011674027761661494,
          0.009356511091741126,
          0.008880167655571503,
          0.006137301141106836,
          0.009288147752473202,
          0.008557327125713159,
          0.009606693154472254,
          0.0069263900649411715,
          0.007188605063236726,
          0.004806595977819498,
          0.009657143349190706,
          0.01421000155073215,
          0.007131349562707919,
          0.004490476552546897,
          0.006120805187064243
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_5"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_75",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.010953245793594387,
          0.0142056958355118,
          0.016578215877226174,
          0.018787931176626922,
          0.0137349007596251,
          0.014215165087128312,
          0.01135893382170947,
          0.012095462838738224,
          0.0098376417706675,
          0.020153963688252036,
          0.015447230001918773,
          0.017001402554951327,
          0.010351685868494144,
          0.019906225438325518,
          0.021504481845706983,
          0.017615365601417854,
          0.016714994663299284,
          0.015216026702788953,
          0.010353872771161687,
          0.007680698990259458,
          0.017643540125272496,
          0.014316566731895339,
          0.011912471543429875,
          0.019878942729319192
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_75"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_38",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.018309809139108086,
          0.02051838198962552,
          0.015431399820400633,
          0.014164043761135746,
          0.015277312448806132,
          0.015538604674126759,
          0.023702591418579944,
          0.015680298107407276,
          0.023783416364190936,
          0.023349095532245918,
          0.02428525251564295,
          0.01665995841848494,
          0.02143608738508096,
          0.020223523597508,
          0.01434584665808436,
          0.019212343187039696,
          0.01636126936869752,
          0.02194913952325205,
          0.01794945048010806,
          0.011753063010017176,
          0.021005727718271208,
          0.021536226594426104,
          0.010680886205918085,
          0.011842305679930814
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_38"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_56",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.011680916908356976,
          0.013584008085479916,
          0.013360661453750573,
          0.013295903547338228,
          0.005678155969906413,
          0.01204957951132289,
          0.011250086203520516,
          0.014268063080326175,
          0.010010684140693811,
          0.008756024591064573,
          0.020186140773135082,
          0.00983385145341455,
          0.012729537781590809,
          0.011796861198838056,
          0.010686750177971271,
          0.011615327900167623,
          0.012013221246267743,
          0.012329458833517935,
          0.016902433126539832,
          0.008257666446254303,
          0.014009857199584351,
          0.013913871342812564,
          0.008864285017978937,
          0.012723963597794787
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_56"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_225",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.015154192850465889,
          0.00894142596010815,
          0.012961241724497677,
          0.018954771114747818,
          0.01280486635310659,
          0.014586467279697705,
          0.01576032918780535,
          0.015230770266365863,
          0.016361622751412768,
          0.026160729769228,
          0.015339485216081899,
          0.011271097974608296,
          0.017624026253402498,
          0.010264776472548776,
          0.016896553413549883,
          0.019946593559767876,
          0.01606972998641417,
          0.014408914490266485,
          0.01695168386266222,
          0.016739024193620597,
          0.007691365330048589,
          0.014841905384404518,
          0.0127764578655577,
          0.011916255067199769
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_225"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers+lines",
         "name": "feature_26",
         "type": "scatter",
         "x": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ],
         "y": [
          0.0048041052997459055,
          0.006708397250229898,
          0.008836105962896692,
          0.010428821900661082,
          0.00572816155864898,
          0.010370126706503906,
          0.0072776469881310575,
          0.006835130228979682,
          0.006844698905291903,
          0.00709950487287764,
          0.007556587982022646,
          0.006048762625813145,
          0.00814857116739077,
          0.00821159694764667,
          0.007474265088109816,
          0.007502446937755192,
          0.013448444040947652,
          0.009956745973416194,
          0.008429652741327575,
          0.009967780461393655,
          0.010907206693366317,
          0.00793522688826519,
          0.008057354183308255,
          0.009155370127936366
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 30,
         "l": 30,
         "r": 30,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "feature_26"
        },
        "width": 1000,
        "xaxis": {
         "domain": [
          0,
          0.95
         ],
         "showgrid": true,
         "tickvals": [
          "2021-01-01T00:00:00",
          "2021-02-01T00:00:00",
          "2021-03-01T00:00:00",
          "2021-04-01T00:00:00",
          "2021-05-01T00:00:00",
          "2021-06-01T00:00:00",
          "2021-07-01T00:00:00",
          "2021-08-01T00:00:00",
          "2021-09-01T00:00:00",
          "2021-10-01T00:00:00",
          "2021-11-01T00:00:00",
          "2021-12-01T00:00:00",
          "2022-01-01T00:00:00",
          "2022-02-01T00:00:00",
          "2022-03-01T00:00:00",
          "2022-04-01T00:00:00",
          "2022-05-01T00:00:00",
          "2022-06-01T00:00:00",
          "2022-07-01T00:00:00",
          "2022-08-01T00:00:00",
          "2022-09-01T00:00:00",
          "2022-10-01T00:00:00",
          "2022-11-01T00:00:00",
          "2022-12-01T00:00:00"
         ]
        },
        "yaxis": {
         "range": [
          0,
          0.06
         ],
         "title": {
          "text": "IV"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feature in top15features:\n",
    "    plot_metric_time(df[feature], df['target'], df['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом моменте предлагаю сделать новый маленький датафрейм, чтобы не \"портить\" исходный\n",
    "\n",
    "И проводить все манипуляции с фичами на нём"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15features_stable = ['feature_26', 'feature_225', 'feature_56', 'feature_38', 'feature_75', 'feature_5', 'feature_140', 'feature_46', 'feature_223', 'feature_24', 'feature_213', 'feature_30', 'feature_124']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_logreg = df[top15features_stable + ['date', 'month', 'quarter', 'target', 'sample_part']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Используя функицю woe_line из предыдущего ДЗ, проверьте **числовые** фичи из полученного списка фичей на линейность по WoE на трейн-выборке (если в фиче есть пропуски - дропаем их при отрисовке)\n",
    "\n",
    "Если фичи нелинейные, **линеаризуйте их**.\n",
    "\n",
    "Преобразования, которые можно/стоит пробовать:\n",
    "- клипы (`np.clip`) - зачастую их достаточно\n",
    "- корень\n",
    "- квадрат\n",
    "- логарифм\n",
    "\n",
    "Если нужно, можно прибавлять к фиче константу или менять её знак\n",
    "\n",
    "При желании можно \"распилить фичу на две половины\" (если она немонотонна) и линеаризовать их по отдельности\n",
    "\n",
    "Однако слишком упираться в линеаризацию фичей не нужно. Если фича ну совсем никак не линеаризуется, в крайнем случае можно её дропнуть или оставить как есть.\n",
    "\n",
    "При отрисовке можно ограничиться 15-20 бакетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from woe import woe_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(top15features_stable) & set(category_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          10.180820513515833,
          26.194398085229224,
          38.023614735959995,
          48.30766773532873,
          57.69085660801678,
          66.59914955038334,
          75.3661018543837,
          83.96572784930787,
          92.65521613157819,
          101.55421200946628,
          110.92843722009545,
          120.7538109708652,
          131.20799800131044,
          142.68686165251293,
          155.39233306171,
          170.1031669476929,
          187.54486131538945,
          209.86953503136576,
          242.0177000628783,
          319.8507543130155
         ],
         "y": [
          -0.10195713566276199,
          -0.08686393480211152,
          -0.07571459967483751,
          -0.06602162027120817,
          -0.057177728034468966,
          -0.04878143719299244,
          -0.040518363468994734,
          -0.03241299901270178,
          -0.024222937083489438,
          -0.01583540895983604,
          -0.006999965200726654,
          0.0022606974392864743,
          0.012114032459440538,
          0.022933151045761657,
          0.034908378389524874,
          0.0487737104600422,
          0.06521294743022032,
          0.08625451562662967,
          0.11655497222035482,
          0.189914589466054
         ]
        },
        {
         "error_y": {
          "array": [
           -0.06597491546161927,
           -0.052209734993118095,
           -0.03589751784021733,
           -0.044635705934334635,
           -0.020053339176721807,
           -0.02215897840932657,
           -0.03323204227209631,
           -0.006804029961396396,
           -0.0037214587918098507,
           0.010780595080694177,
           0.013109052226816131,
           0.021861048792478743,
           0.04772248084902153,
           0.04064095363820697,
           0.04417901800400037,
           0.0900756672683396,
           0.10902411491742459,
           0.10619166545456282,
           0.14124891845787102,
           0.23239798012298796
          ],
          "arrayminus": [
           -0.11959471468620486,
           -0.10597049593999364,
           -0.0898285706235743,
           -0.09847509758201578,
           -0.07415317884200945,
           -0.07623619453570796,
           -0.08719125679613182,
           -0.06104757851354703,
           -0.05799877815442256,
           -0.043657303479963216,
           -0.04135489109287138,
           -0.0327014388014123,
           -0.007137206758297321,
           -0.014136458533379304,
           -0.010639416089577858,
           0.03470976395857772,
           0.0534238534098207,
           0.050626747197854094,
           0.08523883400616161,
           0.17515113668997662
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          10.180820513515833,
          26.194398085229224,
          38.023614735959995,
          48.30766773532873,
          57.69085660801678,
          66.59914955038334,
          75.3661018543837,
          83.96572784930787,
          92.65521613157819,
          101.55421200946628,
          110.92843722009545,
          120.7538109708652,
          131.20799800131044,
          142.68686165251293,
          155.39233306171,
          170.1031669476929,
          187.54486131538945,
          209.86953503136576,
          242.0177000628783,
          319.8507543130155
         ],
         "y": [
          -0.09292152989768732,
          -0.07922965990132469,
          -0.06300597543910569,
          -0.07169651414881695,
          -0.04724951547993139,
          -0.04934339897190043,
          -0.06035513767070311,
          -0.03407486895895673,
          -0.031009840217234408,
          -0.016591185727634294,
          -0.014276253185758314,
          -0.005575423777803179,
          0.020131740062311665,
          0.013092912989792871,
          0.01660968676260066,
          0.062222306533937344,
          0.081049223590546,
          0.07823510008825629,
          0.11306157344448342,
          0.20356989369017875
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.520 IV = 0.005 R_sqr = 0.980 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line((-df_for_logreg[top15features_stable[0]].to_numpy() +300)**2/1000 , df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/4274007021.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[0]] = (-df_for_logreg[top15features_stable[0]].to_numpy() +300)**2/1000\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[0]] = (-df_for_logreg[top15features_stable[0]].to_numpy() +300)**2/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -68.58767352226157,
          -40.08197156190546,
          -26.38746374771798,
          -16.234101929250453,
          -7.75351388894145,
          -0.3203490745783455,
          6.436363425716958,
          12.800740225007504,
          18.875034439002622,
          24.810739235388702,
          30.69141340370366,
          36.68216248724351,
          42.83072803414665,
          49.29966207909716,
          56.19319168281895,
          63.69658268124363,
          72.28772088208714,
          82.69734952781793,
          96.88610360296275,
          126.69835475619415
         ],
         "y": [
          -0.21705820697179845,
          -0.1523362078703271,
          -0.12124292261541292,
          -0.09818978484649599,
          -0.07893466836881136,
          -0.06205771907967039,
          -0.04671665008999237,
          -0.03226637659530818,
          -0.018474733603775495,
          -0.004997756926176433,
          0.008354273091082609,
          0.021956227441872533,
          0.03591650298097171,
          0.05060417297861075,
          0.0662558842551314,
          0.08329228160936719,
          0.10279840146177022,
          0.12643339128916142,
          0.15864885926043437,
          0.22633736926575565
         ]
        },
        {
         "error_y": {
          "array": [
           -0.147651755385372,
           -0.09012334197855709,
           -0.09700921728520229,
           -0.07085995348043606,
           -0.0648462943076733,
           -0.06334070146712556,
           -0.009498088439363617,
           -0.024071644627838507,
           -0.04065028283840888,
           0.0030353323624364714,
           0.01097454676612919,
           0.030645456163250095,
           0.03828522630438069,
           0.06532345257029826,
           0.11267122488669756,
           0.11226568996952613,
           0.1598240048094569,
           0.19031177891292683,
           0.21039521009596684,
           0.27759183535813425
          ],
          "arrayminus": [
           -0.20048642070472267,
           -0.1435018913788989,
           -0.15032038130075331,
           -0.12443032948905797,
           -0.11847755688946238,
           -0.11698728248135526,
           -0.06371222631558182,
           -0.07812836169845083,
           -0.09453135484617792,
           -0.0513164542293324,
           -0.043465518453470464,
           -0.02401697374853662,
           -0.016464965948628785,
           0.010256341417055004,
           0.057025293586115744,
           0.056624845825199666,
           0.10357121501418598,
           0.13365030813463352,
           0.15345748205456877,
           0.21968875176738167
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -68.58767352226157,
          -40.08197156190546,
          -26.38746374771798,
          -16.234101929250453,
          -7.75351388894145,
          -0.3203490745783455,
          6.436363425716958,
          12.800740225007504,
          18.875034439002622,
          24.810739235388702,
          30.69141340370366,
          36.68216248724351,
          42.83072803414665,
          49.29966207909716,
          56.19319168281895,
          63.69658268124363,
          72.28772088208714,
          82.69734952781793,
          96.88610360296275,
          126.69835475619415
         ],
         "y": [
          -0.17418951793592818,
          -0.11694442849636777,
          -0.12379522695331002,
          -0.09778085825565819,
          -0.0917988714625918,
          -0.09030124631462666,
          -0.03675364902071343,
          -0.05124541292841678,
          -0.06773275946414514,
          -0.024291727710847644,
          -0.016398359174074173,
          0.003157098686952242,
          0.010751313629164705,
          0.03762508226893302,
          0.0846726541091457,
          0.08426975679176885,
          0.1315108759841307,
          0.16178689937462487,
          0.18172722457153234,
          0.2484239364742652
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.531 IV = 0.012 R_sqr = 0.950 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-df_for_logreg[top15features_stable[1]].to_numpy(), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/562712436.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[1]] = -df_for_logreg[top15features_stable[1]].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[1]] = -df_for_logreg[top15features_stable[1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -732695.2133161306,
          -527528.0432778582,
          -444483.6091415069,
          -387927.8157032226,
          -344497.5040262442,
          -308356.9047660304,
          -277169.9987063576,
          -249481.44991813044,
          -224539.84306736942,
          -201721.46723937913,
          -180013.7232359525,
          -159626.73795959196,
          -139934.48787086087,
          -120748.07714740348,
          -101937.99977446432,
          -83083.64772918158,
          -63935.17763384386,
          -44319.56340157012,
          -24132.040037375737,
          -5317.31984863617
         ],
         "y": [
          -0.25525766928776483,
          -0.15011409134751497,
          -0.10755567943643474,
          -0.07857210241365076,
          -0.0563150407213443,
          -0.037793793318971036,
          -0.02181120269597403,
          -0.007621441795026107,
          0.0051605729073208595,
          0.0168544792808053,
          0.02797921172754847,
          0.0384270849178443,
          0.04851892188979812,
          0.05835152752021766,
          0.0679912707401239,
          0.07765370373764613,
          0.08746686564620121,
          0.09751942845872297,
          0.10786508188791333,
          0.11750720444689622
         ]
        },
        {
         "error_y": {
          "array": [
           -0.23876578261767145,
           -0.14874653288776207,
           -0.10369209974386706,
           -0.04823617785147227,
           -0.029228505127517845,
           -0.01276546282215163,
           0.03456017590911842,
           0.05522100837208943,
           0.05482574007621599,
           0.06591910780600252,
           0.08286143056754203,
           0.05858353849497355,
           0.08426237724030106,
           0.09168200349306144,
           0.10558518717878951,
           0.10255530187393302,
           0.11044171321757312,
           0.11693389802564058,
           0.11774678219466173,
           0.08726736207791763
          ],
          "arrayminus": [
           -0.2908271466045558,
           -0.20157126738897324,
           -0.15693846046020232,
           -0.10203809602397118,
           -0.08323019579867119,
           -0.06694406108184903,
           -0.020147126562305107,
           0.00027346364728175754,
           -0.00011715451478255812,
           0.010844903770263925,
           0.027583470696443624,
           0.003596349987162628,
           0.028967394759541243,
           0.036296422270292616,
           0.05002782232446801,
           0.04703559772171095,
           0.054823721847652274,
           0.06123435853800052,
           0.06203699153587772,
           0.03193577677543802
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -732695.2133161306,
          -527528.0432778582,
          -444483.6091415069,
          -387927.8157032226,
          -344497.5040262442,
          -308356.9047660304,
          -277169.9987063576,
          -249481.44991813044,
          -224539.84306736942,
          -201721.46723937913,
          -180013.7232359525,
          -159626.73795959196,
          -139934.48787086087,
          -120748.07714740348,
          -101937.99977446432,
          -83083.64772918158,
          -63935.17763384386,
          -44319.56340157012,
          -24132.040037375737,
          -5317.31984863617
         ],
         "y": [
          -0.26489965319660946,
          -0.17527911733327461,
          -0.13044437020608757,
          -0.07527750298434599,
          -0.05637367698401763,
          -0.04000255997783431,
          0.007048525486567869,
          0.02758467598932335,
          0.027191820646303322,
          0.038217057610794636,
          0.0550536824747464,
          0.030926635571983607,
          0.056445799863970914,
          0.06381843725261449,
          0.07763253844074447,
          0.07462218160732159,
          0.08245762895986608,
          0.08890753315828503,
          0.08971510259532034,
          0.059431800140523516
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.524 IV = 0.009 R_sqr = 0.950 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-((df_for_logreg[top15features_stable[2]].to_numpy()-350))**2, df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/1770315705.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[2]] = -((df_for_logreg[top15features_stable[2]].to_numpy()-350))**2\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[2]] = -((df_for_logreg[top15features_stable[2]].to_numpy()-350))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -18529.488188674262,
          -14428.245953982601,
          -12656.622039513448,
          -11430.486458185276,
          -10471.412957028688,
          -9665.935618704325,
          -8958.19133300834,
          -8330.291559945508,
          -7758.209235352602,
          -7224.892423019613,
          -6723.909218209752,
          -6240.6807613249375,
          -5763.262151077156,
          -5290.410517479547,
          -4812.586413620166,
          -4320.794430664929,
          -3800.407708348202,
          -3228.229582564784,
          -2533.779541468941,
          -1427.7936047085734
         ],
         "y": [
          -0.24540966873354575,
          -0.1519238942173189,
          -0.11154060927144127,
          -0.08359145925226763,
          -0.0617298563663915,
          -0.04336940152869173,
          -0.02723672295924484,
          -0.012924060296500062,
          0.00011627142280745684,
          0.01227296259353039,
          0.02369262528136351,
          0.03470757733126384,
          0.0455900968201014,
          0.0563685143503353,
          0.06726027686413238,
          0.0784704302265804,
          0.09033238643395303,
          0.10337490189369314,
          0.11920454477738252,
          0.144414943477441
         ]
        },
        {
         "error_y": {
          "array": [
           -0.21369774691587573,
           -0.13191337046671203,
           -0.08508727867507171,
           -0.06804278130331898,
           -0.028465198988075202,
           -0.004299738158683453,
           -0.000827996429817679,
           0.00033035514194867943,
           0.01097454676612919,
           0.036912149008809014,
           0.054628131406180946,
           0.05719837053303567,
           0.09590416745070907,
           0.10619166545456282,
           0.10215163199433364,
           0.13468336186621122,
           0.1297723584863143,
           0.13652788910326807,
           0.11307683510259625,
           0.1416599364458574
          ],
          "arrayminus": [
           -0.2659611620997455,
           -0.1848925275008515,
           -0.1385155058950417,
           -0.12164162093908526,
           -0.08247501224485776,
           -0.05857071257342905,
           -0.055137130255141664,
           -0.05399154643771853,
           -0.043465518453470464,
           -0.017822212079232957,
           -0.000312439208322135,
           0.002227531463721233,
           0.040466696624652854,
           0.050626747197854094,
           0.046636935911189004,
           0.07875792956514038,
           0.07390985898170666,
           0.08057873438746288,
           0.05742581345502118,
           0.0856445329024016
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -18529.488188674262,
          -14428.245953982601,
          -12656.622039513448,
          -11430.486458185276,
          -10471.412957028688,
          -9665.935618704325,
          -8958.19133300834,
          -8330.291559945508,
          -7758.209235352602,
          -7224.892423019613,
          -6723.909218209752,
          -6240.6807613249375,
          -5763.262151077156,
          -5290.410517479547,
          -4812.586413620166,
          -4320.794430664929,
          -3800.407708348202,
          -3228.229582564784,
          -2533.779541468941,
          -1427.7936047085734
         ],
         "y": [
          -0.23993729702881195,
          -0.1585264523281873,
          -0.1119342202964706,
          -0.09497849307433925,
          -0.05561459223885401,
          -0.03158482374906468,
          -0.028132903070159143,
          -0.026981183120717622,
          -0.016398359174074173,
          0.009386453451374899,
          0.02699541789250748,
          0.029549950947746484,
          0.06801369089509224,
          0.07823510008825629,
          0.07422110865480513,
          0.10653989436781608,
          0.10166151286905856,
          0.10837212530872742,
          0.08507562508415878,
          0.11346983450814763
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.526 IV = 0.009 R_sqr = 0.973 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-df_for_logreg[top15features_stable[3]].to_numpy()**2, df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/1312982803.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[3]] = -df_for_logreg[top15features_stable[3]].to_numpy()**2\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[3]] = -df_for_logreg[top15features_stable[3]].to_numpy()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          17.206734625010977,
          24.84629237245744,
          28.47548025264553,
          31.136688414620004,
          33.34233011191084,
          35.278733637319334,
          37.03799027555699,
          38.70220495709562,
          40.28957425024395,
          41.84206954284573,
          43.37742287989557,
          44.91530832120568,
          46.49393461363584,
          48.13956503911772,
          49.894213698022675,
          51.81732948633331,
          54.03028200212289,
          56.68282187485496,
          60.262954262081124,
          67.75791750972603
         ],
         "y": [
          -0.21846890488145398,
          -0.1519665408650338,
          -0.12037445380044864,
          -0.09720863193461504,
          -0.0780085169682665,
          -0.06115212077537924,
          -0.04583778855588805,
          -0.031350796741454245,
          -0.017532744172020776,
          -0.0040182698404541695,
          0.00934698373701115,
          0.022734279286644954,
          0.036476224019004744,
          0.05080143985083385,
          0.06607565960189532,
          0.08281638601929897,
          0.10208014167390922,
          0.1251705060662015,
          0.15633556497577927,
          0.22157923360976273
         ]
        },
        {
         "error_y": {
          "array": [
           -0.15930791566617886,
           -0.12124906776743061,
           -0.0834064661981202,
           -0.0949639132014467,
           -0.05107506384699256,
           -0.050318336379423845,
           -0.029037700477928086,
           0.0032286608531755245,
           -0.02254162966498041,
           0.02127657970107244,
           0.04201622826168461,
           0.025370893619704682,
           0.08286143056754203,
           0.09107949155685102,
           0.07088898055797077,
           0.11673072441808274,
           0.12364930848786437,
           0.1648051213604299,
           0.19410189973016967,
           0.2758340598586254
          ],
          "arrayminus": [
           -0.21203764859836582,
           -0.174327970755348,
           -0.13685134793452258,
           -0.14829502756618085,
           -0.10484755614349495,
           -0.10409866194427697,
           -0.0830414208367658,
           -0.051125265406154474,
           -0.07661474082107889,
           -0.03327929498933724,
           -0.012777109442133172,
           -0.0292314020726826,
           0.027583470696443624,
           0.035701295326622584,
           0.01575540965242106,
           0.06103374571438713,
           0.06786481088864094,
           0.10848643918325152,
           0.13738872337526875,
           0.2179570387326396
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          17.206734625010977,
          24.84629237245744,
          28.47548025264553,
          31.136688414620004,
          33.34233011191084,
          35.278733637319334,
          37.03799027555699,
          38.70220495709562,
          40.28957425024395,
          41.84206954284573,
          43.37742287989557,
          44.91530832120568,
          46.49393461363584,
          48.13956503911772,
          49.894213698022675,
          51.81732948633331,
          54.03028200212289,
          56.68282187485496,
          60.262954262081124,
          67.75791750972603
         ],
         "y": [
          -0.18579095465433615,
          -0.1479141221720931,
          -0.11026207497133278,
          -0.12176030854318365,
          -0.07810108882503242,
          -0.07734843441083061,
          -0.056183927191319594,
          -0.024099510499024923,
          -0.04972391712897295,
          -0.006156459504403022,
          0.014459922030345962,
          -0.0020862462299396922,
          0.0550536824747464,
          0.06321975535024316,
          0.043156131223464844,
          0.08870568720042715,
          0.0955788985501349,
          0.1364578474327497,
          0.16555023400213142,
          0.24667965488668642
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.530 IV = 0.012 R_sqr = 0.975 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-df_for_logreg[top15features_stable[4]].to_numpy(), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/3092451958.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[4]] = -df_for_logreg[top15features_stable[4]].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[4]] = -df_for_logreg[top15features_stable[4]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -5.0996435984664945,
          -5.077135742215211,
          -5.061643198387425,
          -5.045891034959547,
          -5.029627692516069,
          -5.012732188019861,
          -4.994983661034411,
          -4.976491542524838,
          -4.957071379016822,
          -4.93663537812647,
          -4.914980972408992,
          -4.891489702413225,
          -4.86602779106823,
          -4.83763598262079,
          -4.805887566499142,
          -4.769688830947811,
          -4.726623616016163,
          -4.673968083766013,
          -4.601874599430548,
          -4.447205769528442
         ],
         "y": [
          -0.04606001908744817,
          -0.03705952814325697,
          -0.030864335723874925,
          -0.02456532604915551,
          -0.018061904988055155,
          -0.01130569357822786,
          -0.004208373663712406,
          0.0031862952610475226,
          0.010952072856087902,
          0.01912406573251413,
          0.027783277004618245,
          0.03717701759474645,
          0.04735878257155868,
          0.0587121612304361,
          0.07140778753109855,
          0.08588301733013226,
          0.10310402997010082,
          0.12416003974233536,
          0.15298894044493216,
          0.2148382515184034
         ]
        },
        {
         "error_y": {
          "array": [
           -0.0366804641671763,
           0.05315611144318122,
           0.008356034787603495,
           0.032250587706714406,
           0.0075636285733272635,
           0.005979593162403596,
           0.02226548522918559,
           0.07058673216512268,
           0.037860689856485275,
           0.026653762895976096,
           0.06165223980068801,
           0.043082076869123354,
           0.11164920936762301,
           0.12120194519065486,
           0.08979243342070131,
           0.10048775942145272,
           0.11164920936762301,
           0.1708877011099571,
           0.19833383500758284,
           0.26740000986033585
          ],
          "arrayminus": [
           -0.053535171577938634,
           -0.02529009765645629,
           -0.06936825315345774,
           -0.04585398301665522,
           -0.07014823412945403,
           -0.07170746697361141,
           -0.05567885091531144,
           -0.008150720815651269,
           -0.040334741988760414,
           -0.05136075963946063,
           -0.016935201517630616,
           -0.03519846010331951,
           0.032202563876694845,
           0.041585645677916894,
           0.01072732228888873,
           0.021237101867272123,
           0.032202563876694845,
           0.09036039358608217,
           0.11728259979360545,
           0.20687462160044567
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -5.0996435984664945,
          -5.077135742215211,
          -5.061643198387425,
          -5.045891034959547,
          -5.029627692516069,
          -5.012732188019861,
          -4.994983661034411,
          -4.976491542524838,
          -4.957071379016822,
          -4.93663537812647,
          -4.914980972408992,
          -4.891489702413225,
          -4.86602779106823,
          -4.83763598262079,
          -4.805887566499142,
          -4.769688830947811,
          -4.726623616016163,
          -4.673968083766013,
          -4.601874599430548,
          -4.447205769528442
         ],
         "y": [
          -0.045122045175265746,
          0.013606058779204067,
          -0.03081319754364098,
          -0.00711930152431739,
          -0.0315990453644982,
          -0.033169988842809306,
          -0.017019871399522435,
          0.030883160688590094,
          -0.0015571241234192401,
          -0.012668623622887565,
          0.02202773407310188,
          0.0036193801736180697,
          0.07157204419778451,
          0.08103545166736581,
          0.04991621743892605,
          0.060513807976988354,
          0.07157204419778451,
          0.13024177098231593,
          0.15741233250754594,
          0.23690285829686963
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.516 IV = 0.005 R_sqr = 0.950 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-np.clip(np.log1p(np.clip((-df_for_logreg[top15features_stable[5]].to_numpy()), 0, 1000)), 4.4, 5.1), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/1124901724.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[5]] = -np.clip(np.log1p(np.clip((-df_for_logreg[top15features_stable[5]].to_numpy()), 0, 1000)), 4.4, 5.1)\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[5]] = -np.clip(np.log1p(np.clip((-df_for_logreg[top15features_stable[5]].to_numpy()), 0, 1000)), 4.4, 5.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.6546956365595259,
          5.64563517226802,
          28.22099447513812,
          61.80241343126968,
          116.9289868846227,
          169.43450598802394,
          238.45767385638197,
          335.84088957582003,
          439.7113312740149,
          579.1633055943631,
          679.4342475956089,
          855.0027602070155,
          1013.5943728018757,
          1178.8049347200708,
          1391.5909352352467,
          1565.0888250036858,
          1682.5293978799193,
          1936.523249599145,
          2121.928027110864,
          2483.0280208301797
         ],
         "y": [
          -0.14550076974646076,
          -0.1448694214082753,
          -0.1420136633936091,
          -0.13776565099029592,
          -0.1307922003422478,
          -0.1241503101742053,
          -0.11541895568308691,
          -0.1031000864658248,
          -0.0899605903281554,
          -0.07232006961778192,
          -0.05963590621570525,
          -0.03742668330648913,
          -0.01736501949637803,
          0.003533934091724533,
          0.030451128109663106,
          0.05239841951649071,
          0.06725452225837214,
          0.09938446393469125,
          0.12283796348848208,
          0.16851671381644773
         ]
        },
        {
         "error_y": {
          "array": [
           0.053023561870309766,
           -0.04526464732998392,
           -0.10269526934666251,
           -0.09841887005360384,
           -0.1101502530673314,
           -0.09746033687922895,
           -0.0910167980719303,
           -0.10223886875090937,
           -0.06708392020236342,
           -0.06447871994765386,
           -0.029546171021904377,
           -0.015077964956674572,
           0.02606759640249523,
           0.04820661003916438,
           0.039784996222572255,
           0.08225017590347194,
           0.07166077339320709,
           0.10791687264467231,
           0.12672254907817881,
           0.21335802439710172
          ],
          "arrayminus": [
           -0.06261988211214087,
           -0.13249454565729268,
           -0.16128707730454295,
           -0.18449349803331172,
           -0.16200409665226867,
           -0.2590320088745204,
           -0.14288703056110563,
           -0.18010404407150626,
           -0.11911509638963169,
           -0.11124392512419312,
           -0.07815629614188857,
           -0.07993959477540735,
           -0.030815281091454816,
           -0.016251494084363216,
           -0.05273368986821869,
           0.007378082853747747,
           0.03120887872536038,
           0.02521174829932582,
           0.08926992768953168,
           0.17821248257500877
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.6546956365595259,
          5.64563517226802,
          28.22099447513812,
          61.80241343126968,
          116.9289868846227,
          169.43450598802394,
          238.45767385638197,
          335.84088957582003,
          439.7113312740149,
          579.1633055943631,
          679.4342475956089,
          855.0027602070155,
          1013.5943728018757,
          1178.8049347200708,
          1391.5909352352467,
          1565.0888250036858,
          1682.5293978799193,
          1936.523249599145,
          2121.928027110864,
          2483.0280208301797
         ],
         "y": [
          -0.005495559947634732,
          -0.08924291260111739,
          -0.13214715744888073,
          -0.14178895256756519,
          -0.13619875347248833,
          -0.17936523003197968,
          -0.11707635489658819,
          -0.14144388493100934,
          -0.09322818957785262,
          -0.08796588878218459,
          -0.0539684713644496,
          -0.04771889908935645,
          -0.00254305231661478,
          0.015756371905047306,
          -0.006920069661510708,
          0.04450750010095761,
          0.05134475884253431,
          0.0661827068957005,
          0.10791508455066834,
          0.19570857363417782
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.531 IV = 0.012 R_sqr = 0.951 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(df_for_logreg[top15features_stable[6]].to_numpy()**2, df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/1634906610.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[6]] = df_for_logreg[top15features_stable[6]].to_numpy()**2\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[6]] = df_for_logreg[top15features_stable[6]].to_numpy()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -526.0051156500157,
          -402.81182116187296,
          -345.9921115819885,
          -305.8618344796105,
          -273.34879881396176,
          -245.71534889190943,
          -221.34545224904804,
          -199.16354394279628,
          -178.66369740960545,
          -159.3092279603814,
          -141.00687032932143,
          -123.27802954236188,
          -105.95397509151498,
          -89.17558134299318,
          -72.6110470420409,
          -56.24687035852292,
          -39.638020562811256,
          -22.943502618546773,
          -6.02490634635072,
          19.24185358055026
         ],
         "y": [
          -0.33003671233141396,
          -0.23184306798018994,
          -0.18655379815581585,
          -0.15456716955009886,
          -0.12865201341927046,
          -0.1066262273152665,
          -0.08720172069931964,
          -0.06952119332722972,
          -0.05318138645625936,
          -0.037754524973253045,
          -0.023166269959209562,
          -0.00903514785368198,
          0.0047733313215494455,
          0.018146880875301696,
          0.03134996953974156,
          0.044393359214790484,
          0.05763177041808831,
          0.07093846510829382,
          0.0844237658478878,
          0.10456313502766612
         ]
        },
        {
         "error_y": {
          "array": [
           -0.33736866590344483,
           -0.22073541700962473,
           -0.16415582657273375,
           -0.14961160956891517,
           -0.09284425335992674,
           -0.06367500306121698,
           -0.008737434999925298,
           -0.04916868763615079,
           0.02023587975268193,
           0.03425651048895062,
           0.0549928621538841,
           0.025681688544166525,
           0.07988114797334056,
           0.04204857407651297,
           0.11277675795928588,
           0.09527673438798823,
           0.130191077261956,
           0.11401603624785717,
           0.13456660160965417,
           0.09566933773563868
          ],
          "arrayminus": [
           -0.39942424468410337,
           -0.28524052881248796,
           -0.2292493355574019,
           -0.21486265170119634,
           -0.15875244495556518,
           -0.12994010189923644,
           -0.07571236147198401,
           -0.11561440956331737,
           -0.047133324184028935,
           -0.0333084589298025,
           -0.012867605779115387,
           -0.041761118662884456,
           0.011656584784010104,
           -0.025626598620719587,
           0.04405509327432866,
           0.026823854243489542,
           0.0611989078463846,
           0.04527528978875628,
           0.06550566253596313,
           0.07541265389855656
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -526.0051156500157,
          -402.81182116187296,
          -345.9921115819885,
          -305.8618344796105,
          -273.34879881396176,
          -245.71534889190943,
          -221.34545224904804,
          -199.16354394279628,
          -178.66369740960545,
          -159.3092279603814,
          -141.00687032932143,
          -123.27802954236188,
          -105.95397509151498,
          -89.17558134299318,
          -72.6110470420409,
          -56.24687035852292,
          -39.638020562811256,
          -22.943502618546773,
          -6.02490634635072,
          19.24185358055026
         ],
         "y": [
          -0.36852009878375025,
          -0.2531491560471434,
          -0.19688006891001664,
          -0.1824188864429972,
          -0.12599718355809253,
          -0.09701539667928016,
          -0.042450185957040754,
          -0.08260392458649113,
          -0.013683473120733591,
          0.0002346270190232147,
          0.02081627097899208,
          -0.008276251736641038,
          0.04551402094909773,
          0.0079689861221659,
          0.07814962430581918,
          0.060790137090843244,
          0.09542251391483891,
          0.07937892472140906,
          0.09976208874619241,
          0.08551770853494234
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.530 IV = 0.015 R_sqr = 0.953 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-np.clip(df_for_logreg[top15features_stable[7]].to_numpy(), -20, 700), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/124911854.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[7]] = -np.clip(df_for_logreg[top15features_stable[7]].to_numpy(), -20, 700)\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[7]] = -np.clip(df_for_logreg[top15features_stable[7]].to_numpy(), -20, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          29.39449985168743,
          58.59398143649841,
          72.48425969401929,
          82.71669875707403,
          91.21063181526301,
          98.67134701887264,
          105.42747266567531,
          111.72577370004156,
          117.70009596319976,
          123.53272598030763,
          129.37204691461696,
          135.20327069950096,
          141.23995478216145,
          147.51538222411963,
          154.21851781039874,
          161.5556650558388,
          169.9210319784395,
          180.0230849983195,
          193.61993757160502,
          222.41813490556743
         ],
         "y": [
          -0.22437638239927216,
          -0.15603477349633965,
          -0.12352447150788881,
          -0.09957536999595884,
          -0.07969525502116415,
          -0.06223339429941477,
          -0.04642063079839964,
          -0.03167940928755253,
          -0.01769646255670332,
          -0.0040451476062335345,
          0.009621827486874346,
          0.0232698511401207,
          0.0373987561841862,
          0.05208644187789857,
          0.06777518173892094,
          0.08494783071402934,
          0.10452703566988963,
          0.12817096765532776,
          0.1599945045963973,
          0.22739690465581885
         ]
        },
        {
         "error_y": {
          "array": [
           -0.21662964281981345,
           -0.12187688237574945,
           -0.10723074099204999,
           -0.09498428374144918,
           -0.06275012259762702,
           -0.03129403468428249,
           -0.0011119585558632128,
           0.003801579299246627,
           0.035343237376518566,
           0.016362626816887937,
           0.041945684387471704,
           0.09582825073159007,
           0.09458506641039155,
           0.0922944210647062,
           0.08219502598689832,
           0.11351835753020012,
           0.14591008129119776,
           0.15770208308723088,
           0.17775626565625857,
           0.2250862821984545
          ],
          "arrayminus": [
           -0.27317161365545806,
           -0.1793167178936952,
           -0.1648221955918121,
           -0.15270238303955364,
           -0.12081529720571327,
           -0.08971357419029469,
           -0.05988219681049478,
           -0.055028587282748176,
           -0.023869775621875644,
           -0.04261745110071813,
           -0.017350963773874795,
           0.03583793145033609,
           0.03460986580066283,
           0.03235098925009294,
           0.022384583576456785,
           0.05328915711720983,
           0.08523546412903105,
           0.09685952310096035,
           0.11662715955213288,
           0.16325365632665956
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          29.39449985168743,
          58.59398143649841,
          72.48425969401929,
          82.71669875707403,
          91.21063181526301,
          98.67134701887264,
          105.42747266567531,
          111.72577370004156,
          117.70009596319976,
          123.53272598030763,
          129.37204691461696,
          135.20327069950096,
          141.23995478216145,
          147.51538222411963,
          154.21851781039874,
          161.5556650558388,
          169.9210319784395,
          180.0230849983195,
          193.61993757160502,
          222.41813490556743
         ],
         "y": [
          -0.24502590908025423,
          -0.15074335496135394,
          -0.13617642939626884,
          -0.12399615418594157,
          -0.09194318414826852,
          -0.060671912323651545,
          -0.030672647770630723,
          -0.0257903129,
          0.005551929149419932,
          -0.013307378162526917,
          0.012110852731482824,
          0.06563243704501176,
          0.06439713569957661,
          0.06212299645415742,
          0.05209278439802356,
          0.0831983244886918,
          0.11535845254269184,
          0.1270631800763471,
          0.1469684315069284,
          0.19393295935747878
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.531 IV = 0.012 R_sqr = 0.973 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(df_for_logreg[top15features_stable[8]].to_numpy(), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -31.084438420915657,
          -25.32904581987252,
          -22.605829826010453,
          -20.620723668320256,
          -18.979939882198508,
          -17.544141307613213,
          -16.225673589427018,
          -14.997049086918251,
          -13.811722020714152,
          -12.666632181917297,
          -11.522210330265057,
          -10.384063699645369,
          -9.214036528628533,
          -8.00418372288078,
          -6.702671186499303,
          -5.277079401806667,
          -3.6681873757841026,
          -1.7160046400774744,
          0.9180824809824406,
          6.437931729221885
         ],
         "y": [
          -0.22300868869920398,
          -0.15447776768823185,
          -0.12205174341712466,
          -0.09841458037347739,
          -0.07887735123251238,
          -0.06178093305163346,
          -0.04608160316853249,
          -0.03145205926594763,
          -0.017338068930783157,
          -0.0037031934787014054,
          0.00992372808084474,
          0.02347592899026041,
          0.03740773958874355,
          0.051813764131808826,
          0.06731120436019178,
          0.08428608770228685,
          0.10344357355834233,
          0.12668870905708307,
          0.15805345320966346,
          0.2237796997136824
         ]
        },
        {
         "error_y": {
          "array": [
           -0.2069074593199881,
           -0.14363397251531473,
           -0.10424826142425869,
           -0.08807276327132008,
           -0.04596278905353035,
           -0.041599762483521485,
           -0.033422527304231675,
           0.008841940100176693,
           0.02771368736338098,
           0.029667794328746555,
           0.04299906507945572,
           0.06393419575287773,
           0.07666772494589713,
           0.08626525164343157,
           0.10174803602413207,
           0.11998378200632154,
           0.15671679644627468,
           0.1771011045859051,
           0.173133445314969,
           0.1989550785439057
          ],
          "arrayminus": [
           -0.25922699992687404,
           -0.19650521734127724,
           -0.15748925551543436,
           -0.14147150016078702,
           -0.09978834852152074,
           -0.09547088553267358,
           -0.08737972615336642,
           -0.04557432916603088,
           -0.026915271930236462,
           -0.024983461249736827,
           -0.011805669371172445,
           0.008883608802756737,
           0.02146470438765169,
           0.03094588637710738,
           0.04623834487356682,
           0.0642457342171664,
           0.10050493685242701,
           0.12061829870532204,
           0.11670382717180006,
           0.14217540275937302
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -31.084438420915657,
          -25.32904581987252,
          -22.605829826010453,
          -20.620723668320256,
          -18.979939882198508,
          -17.544141307613213,
          -16.225673589427018,
          -14.997049086918251,
          -13.811722020714152,
          -12.666632181917297,
          -11.522210330265057,
          -10.384063699645369,
          -9.214036528628533,
          -8.00418372288078,
          -6.702671186499303,
          -5.277079401806667,
          -3.6681873757841026,
          -1.7160046400774744,
          0.9180824809824406,
          6.437931729221885
         ],
         "y": [
          -0.233176344093747,
          -0.17019080661809616,
          -0.13099773751553667,
          -0.11490435690948919,
          -0.07301640587823377,
          -0.06867706711375787,
          -0.0605445750320025,
          -0.018518608531811642,
          0.00024270521635338937,
          0.0021852375944200197,
          0.015436843886290075,
          0.03624439858446127,
          0.04889884844410208,
          0.05843602770932721,
          0.07382010799882444,
          0.0919374527338408,
          0.12842487830313953,
          0.14866878968939912,
          0.14472868864951927,
          0.17036896389660294
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.531 IV = 0.012 R_sqr = 0.974 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(df_for_logreg[top15features_stable[9]].to_numpy(), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -10.996935187436243,
          -10.728847348668996,
          -10.545445381198371,
          -10.355878123935131,
          -10.162514735876268,
          -9.963931003327026,
          -9.76021515578804,
          -9.549844824824822,
          -9.33092847376823,
          -9.097306700785895,
          -8.849079775728347,
          -8.588030565533577,
          -8.308351132401306,
          -8.000608602786327,
          -7.657129450585374,
          -7.273089535510356,
          -6.809329552642225,
          -6.2341304831640905,
          -5.428793772942221,
          -3.6683377552358802
         ],
         "y": [
          -0.0438554383313452,
          -0.031890518146734825,
          -0.023705178921437975,
          -0.015244679134502892,
          -0.0066147557653980504,
          0.0022481546927543006,
          0.01134011450470429,
          0.02072906788192319,
          0.030499435234439765,
          0.040926114340715025,
          0.052004630097498006,
          0.06365541208969416,
          0.07613767204632749,
          0.08987240474134583,
          0.10520208422274246,
          0.12234201474964246,
          0.14303989946290996,
          0.16871137709581874,
          0.2046540349345708,
          0.28322423728776835
         ]
        },
        {
         "error_y": {
          "array": [
           -0.03365773765895541,
           0.01621831137634988,
           0.057803259273294993,
           0.03219856539192134,
           0.059711142338404355,
           0.012804838813113673,
           0.03219856539192134,
           0.049237165469683486,
           0.0664011926468957,
           0.059711142338404355,
           0.06770282725962995,
           0.09190698325868918,
           0.0735908144477817,
           0.12998130132564956,
           0.17174603384329135,
           0.16159630843687156,
           0.17677331311456712,
           0.22721503218628392,
           0.21846417371105809,
           0.38890129019133923
          ],
          "arrayminus": [
           -0.04921074706899098,
           -0.06825733126745548,
           -0.027402058277098185,
           -0.05255324994770283,
           -0.025528510638492485,
           -0.07161654142110219,
           -0.05255324994770283,
           -0.03581492155081556,
           -0.01895945546936706,
           -0.025528510638492485,
           -0.0176855616665742,
           0.006076502220730862,
           -0.011900900523961644,
           0.043424183789721016,
           0.08435678884073994,
           0.0744085037831681,
           0.08928141658582589,
           0.13866339339109668,
           0.13010027908987876,
           0.2980745983007259
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -10.996935187436243,
          -10.728847348668996,
          -10.545445381198371,
          -10.355878123935131,
          -10.162514735876268,
          -9.963931003327026,
          -9.76021515578804,
          -9.549844824824822,
          -9.33092847376823,
          -9.097306700785895,
          -8.849079775728347,
          -8.588030565533577,
          -8.308351132401306,
          -8.000608602786327,
          -7.657129450585374,
          -7.273089535510356,
          -6.809329552642225,
          -6.2341304831640905,
          -5.428793772942221,
          -3.6683377552358802
         ],
         "y": [
          -0.04144640357183327,
          -0.026383915882227105,
          0.014814430748284257,
          -0.010550037464611917,
          0.016704132366785918,
          -0.029768532372569045,
          -0.010550037464611917,
          0.006329486998457146,
          0.023330119619502265,
          0.016704132366785918,
          0.02461715140883225,
          0.04858724380652324,
          0.03045035738925439,
          0.08627724183482177,
          0.1276021862661766,
          0.1175589730027885,
          0.13257523378708724,
          0.1824573014594698,
          0.17380556428059413,
          0.34292073474197926
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.516 IV = 0.006 R_sqr = 0.956 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-np.clip(df_for_logreg[top15features_stable[10]].to_numpy(), 1., 11.), df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/2539174893.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[10]] = -np.clip(df_for_logreg[top15features_stable[10]].to_numpy(), 1., 11.)\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[10]] = -np.clip(df_for_logreg[top15features_stable[10]].to_numpy(), 1., 11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -0.3692608071725145,
          -0.2720629258620249,
          -0.2371091928630612,
          -0.214308117806568,
          -0.19726248797306178,
          -0.183332838650301,
          -0.17146536777974583,
          -0.1610590851926817,
          -0.1517228202144093,
          -0.14310006399725536,
          -0.13497930936789182,
          -0.12727159020915665,
          -0.11991187672631692,
          -0.11271549015323909,
          -0.10543892804687956,
          -0.09799993640908411,
          -0.0901688009933973,
          -0.08154142672051261,
          -0.07113054653771532,
          -0.05397707214427799
         ],
         "y": [
          -0.4405914340797028,
          -0.23868013735141058,
          -0.1660699789800506,
          -0.11870480425212349,
          -0.0832955424777907,
          -0.05435917555488834,
          -0.029706617288678405,
          -0.008089417582819558,
          0.011305011009097532,
          0.029217252157810347,
          0.04608667436660674,
          0.06209808890748891,
          0.0773865836033959,
          0.09233579571725536,
          0.10745155822987329,
          0.12290473918080502,
          0.13917252902681232,
          0.1570943633642704,
          0.17872111375686972,
          0.2143544034076047
         ]
        },
        {
         "error_y": {
          "array": [
           -0.3533337147228046,
           -0.23336839585237923,
           -0.1474114236006251,
           -0.13004843456080462,
           -0.09618408007698809,
           -0.06040644316895738,
           -0.02781877689690293,
           -0.009239382680448549,
           0.025020254741006998,
           0.044373875318264866,
           0.039731259722010415,
           0.09548456700418029,
           0.1090782274695844,
           0.12610048834466892,
           0.16211378248237318,
           0.16998536164546374,
           0.17934244527091325,
           0.20625456322775781,
           0.26868591307595346,
           0.3158331270622138
          ],
          "arrayminus": [
           -0.406430877788347,
           -0.28735887246757397,
           -0.2021598268676269,
           -0.1849608284957046,
           -0.151431530268762,
           -0.11602359246839955,
           -0.08378790697300498,
           -0.06541452701860206,
           -0.03155069649021869,
           -0.012427196953605613,
           -0.017014134689753324,
           0.03805182803616336,
           0.05146975432148759,
           0.06826981029883539,
           0.10379943775866662,
           0.11156408391828909,
           0.12079017275166148,
           0.14732211233068682,
           0.20883118478552765,
           0.255245455086082
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -0.3692608071725145,
          -0.2720629258620249,
          -0.2371091928630612,
          -0.214308117806568,
          -0.19726248797306178,
          -0.183332838650301,
          -0.17146536777974583,
          -0.1610590851926817,
          -0.1517228202144093,
          -0.14310006399725536,
          -0.13497930936789182,
          -0.12727159020915665,
          -0.11991187672631692,
          -0.11271549015323909,
          -0.10543892804687956,
          -0.09799993640908411,
          -0.0901688009933973,
          -0.08154142672051261,
          -0.07113054653771532,
          -0.05397707214427799
         ],
         "y": [
          -0.3799709035116352,
          -0.2604753174070702,
          -0.17491479264337273,
          -0.15763743446964262,
          -0.12394782907173663,
          -0.08836283578772641,
          -0.055958420040318035,
          -0.03748623719189703,
          -0.00343241690759144,
          0.01580159211336618,
          0.0111879128412109,
          0.06658413243871597,
          0.08008656197299002,
          0.09699347001823955,
          0.13275575803919037,
          0.14057184082540608,
          0.14986097939750864,
          0.17657589438048726,
          0.23852901552524208,
          0.2852962866400123
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.547 IV = 0.028 R_sqr = 0.960 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-df_for_logreg[top15features_stable[11]].to_numpy()**0.5, df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/4023554359.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[11]] = -df_for_logreg[top15features_stable[11]].to_numpy()**0.5\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[11]] = -df_for_logreg[top15features_stable[11]].to_numpy()**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -438.6010336956904,
          -346.12820027822556,
          -306.7071218376432,
          -279.2876782415088,
          -257.60380268883847,
          -239.2388291822243,
          -222.96931881414994,
          -208.46437403630136,
          -195.08890491525557,
          -182.4074366551539,
          -170.28651259093323,
          -158.46918122876005,
          -146.86941692811152,
          -135.0777288623652,
          -123.15527552675051,
          -110.66014734148534,
          -97.3658501123315,
          -82.46525081211236,
          -64.13097737639636,
          -34.9206096439767
         ],
         "y": [
          -0.4652962155768762,
          -0.2895495969560894,
          -0.2146289853312623,
          -0.1625177401320438,
          -0.12130706596818652,
          -0.08640403687771836,
          -0.05548348077345566,
          -0.027916519712795185,
          -0.0024961515504131615,
          0.02160525297558613,
          0.04464133114169366,
          0.06710042481569656,
          0.08914602758677015,
          0.11155638562165893,
          0.13421526587829724,
          0.15796252706450986,
          0.1832286262918984,
          0.211547537324014,
          0.24639222026618757,
          0.30190715549550984
         ]
        },
        {
         "error_y": {
          "array": [
           -0.48397129299631886,
           -0.2790630806864203,
           -0.1941057537226224,
           -0.11905714809674894,
           -0.0620526689233305,
           -0.07276739770664864,
           -0.025944421139505347,
           0.025241840276507332,
           0.042995490870017194,
           0.11818165042060624,
           0.1119092924252888,
           0.1257959822283018,
           0.13320525569794806,
           0.13924413950198355,
           0.1647491793484942,
           0.19767093513405276,
           0.20108323408446116,
           0.21478589582011465,
           0.24590194953428857,
           0.24271940192080776
          ],
          "arrayminus": [
           -0.5377405175784049,
           -0.3341513057287644,
           -0.24990826619916007,
           -0.1755732623955334,
           -0.1191631599340911,
           -0.1297639823742901,
           -0.0834549991864717,
           -0.0328675066230798,
           -0.015330249911761795,
           0.0588892804708776,
           0.052699352449065096,
           0.0664011588670419,
           0.07370992807244048,
           0.0796663046808822,
           0.10481699933710242,
           0.13726588947501306,
           0.1406297632545329,
           0.15413076919326552,
           0.18477854569475094,
           0.18164455568688787
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -438.6010336956904,
          -346.12820027822556,
          -306.7071218376432,
          -279.2876782415088,
          -257.60380268883847,
          -239.2388291822243,
          -222.96931881414994,
          -208.46437403630136,
          -195.08890491525557,
          -182.4074366551539,
          -170.28651259093323,
          -158.46918122876005,
          -146.86941692811152,
          -135.0777288623652,
          -123.15527552675051,
          -110.66014734148534,
          -97.3658501123315,
          -82.46525081211236,
          -64.13097737639636,
          -34.9206096439767
         ],
         "y": [
          -0.5109241881293036,
          -0.30671538682300625,
          -0.2221329612251033,
          -0.14745757982832353,
          -0.09076328348486551,
          -0.10141858694901229,
          -0.05486356329652686,
          -0.003989073961348399,
          0.013651979247564117,
          0.08833555493350465,
          0.08210605137196747,
          0.09589664879432658,
          0.10325370207652484,
          0.10924972014845069,
          0.13457069717456271,
          0.16724691631426858,
          0.17063405671573706,
          0.1842320267420966,
          0.21510501278299554,
          0.21194766729479586
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.551 IV = 0.036 R_sqr = 0.969 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(-df_for_logreg[top15features_stable[12]].to_numpy()**2/10, df_for_logreg[TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/4110465249.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg[top15features_stable[12]] = -df_for_logreg[top15features_stable[12]].to_numpy()**2/10\n"
     ]
    }
   ],
   "source": [
    "df_for_logreg[top15features_stable[12]] = -df_for_logreg[top15features_stable[12]].to_numpy()**2/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришло время заполнить пропуски.\n",
    "\n",
    "Самый простой вариант для числовых признаков - заполнить их средним значением фичи\n",
    "\n",
    "**Вопрос**: какие проблемы могут возникнуть при таком заполнении пропусков?\n",
    "\n",
    "**Задание**: Проверьте, что заполнение средним значением адекватно для тех признаков, где есть пропуски (hint: в нашем датасете - почти всегда адекватно). Если нет, придумайте, как ещё можно заполнить пропуски. Ну и заполните их)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы, которые могут возникнуть при заполнении пропусков средним:\n",
    "1. Если пропуски не случайны, их заполнение средним может исказить истинное распределение данных.\n",
    "2. Влияние на корреляцию.\n",
    "3. В некоторых случаях пропуски могут нести важную информацию.\n",
    "4. Если данные содержат выбросы, среднее значение может быть искажено, и его использование может быть неприемлемым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_140: 36943\n",
      "Среднее значение: 1170.6308964123207, Медиана: 1024.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_223: 73488\n",
      "Среднее значение: 126.32742768119464, Медиана: 126.48481831008603\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_30: 34475\n",
      "Среднее значение: -0.1547906778877057, Медиана: -0.13897917358256925\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGzCAYAAADNKAZOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGu0lEQVR4nO3deXxUhb3//3cSkskCQwAlIaxREAiySJAwuCGGDDTtBUEU5EpEBOUm2pArFPqAsLVFUTYlmloF7FW+ArZSBRpIw6YybIG0LELRUrHFCSqEKEsyJOf3h7+cMgaYrCQcXs/Hg4fOOZ9z5jOfDPHtWWb8DMMwBAAAYDH+dd0AAABAbSDkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAKiU3bt3q2/fvgoLC5Ofn5/y8vLquiUAuCxCDoAK83g8Gj58uE6dOqWFCxfq//7v/9S2bdsafY4TJ05o5syZ10V4mjhxonr27KmmTZsqNDRUnTt31syZM/X999+Xqy0qKtIvfvELRUVFKSQkRHFxccrOzq6DroEbhx/fXQWgog4fPqzOnTvrd7/7nZ588slaeY49e/bozjvv1LJly/T444/XynPUlLvvvluxsbFq3769goODtW/fPi1dulS9evXStm3b5O//n/+PHDlypN577z2lpqaqQ4cOWr58uXbv3q3Nmzfr7rvvrsNXAVhXg7puAMD14+TJk5Kk8PDwum2kCi5cuKCgoCCv4FFdH3/8cbllt956q5577jnt2rVLffr0kSTt2rVL7777rl588UU999xzkqTRo0fr9ttv1+TJk7V9+/Ya6wnAf3C6CkCFPP7447rvvvskScOHD5efn5/69esn6YcjPA899JCaNm2q4OBg9erVSx988IHX9qdOndJzzz2nrl27qmHDhrLb7Ro0aJD++te/mjVbtmzRnXfeKUkaM2aM/Pz85Ofnp+XLl0uS2rVrd9mjO/369TN7KduPn5+f3n33XU2bNk0tW7ZUaGioCgsLJUk7d+7UwIED1bhxY4WGhuq+++7TJ598UiNzateunSSpoKDAXPbee+8pICBA48ePN5cFBwdr7Nixcrlc+vLLL2vkuQF440gOgAp56qmn1LJlS/3mN7/Rs88+qzvvvFMRERE6ePCg7rrrLrVs2VJTpkxRWFiYVq1apSFDhugPf/iDHnzwQUnSP/7xD61Zs0bDhw9XdHS08vPz9dvf/lb33XefDh06pKioKHXu3FmzZ89Wenq6xo8fr3vuuUeS1Ldv3yr1PGfOHAUFBem5555TUVGRgoKCtGnTJg0aNEixsbGaMWOG/P39tWzZMvXv318fffSRevfuXannuHjxogoKClRcXKwDBw5o2rRpatSokdd+9u3bp9tuu012u91r27KavLw8tW7dukqvEcBVGABQQZs3bzYkGatXrzaXPfDAA0bXrl2NCxcumMtKS0uNvn37Gh06dDCXXbhwwSgpKfHa37FjxwybzWbMnj3bXLZ7925DkrFs2bJyz9+2bVsjKSmp3PL77rvPuO+++8r1ecsttxjnzp3z6qtDhw6G0+k0SktLzeXnzp0zoqOjjQEDBlRoDpdyuVyGJPNPx44djc2bN3vVdOnSxejfv3+5bQ8ePGhIMjIzMyv9vAB843QVgCo7deqUNm3apIcffljfffedvvnmG33zzTf69ttv5XQ6dfToUf373/+WJNlsNvN6mJKSEn377bdq2LChOnbsqL1799ZKf0lJSQoJCTEf5+Xl6ejRo3r00Uf17bffmv2ePXtWDzzwgLZt26bS0tJKPUdMTIyys7O1Zs0aTZ48WWFhYeXurjp//rxsNlu5bYODg831AGoep6sAVNlnn30mwzA0ffp0TZ8+/bI1J0+eVMuWLVVaWqrFixfr1Vdf1bFjx1RSUmLWNGvWrFb6i46O9np89OhRST+Enys5c+aMmjRpUuHnsNvtio+PlyQNHjxYK1as0ODBg7V37151795dkhQSEqKioqJy2164cMFcD6DmEXIAVFnZUY/nnntOTqfzsjXt27eXJP3mN7/R9OnT9cQTT2jOnDlq2rSp/P39lZqaWuGjJ35+fpddXlJSooCAgHLLfxweyp7nxRdfVI8ePS67r4YNG1aolysZOnSoHnvsMb377rtmyGnRooV5ROtSX331lSQpKiqqWs8J4PIIOQCq7JZbbpEkBQYGmkczruS9997T/fffrzfffNNreUFBgW666Sbz8ZWCjCQ1adLE666lMl988YXZy9XceuutkryPvtS0oqIilZaW6syZM+ayHj16aPPmzSosLPS6+Hjnzp3megA1j2tyAFRZ8+bN1a9fP/32t781j0pc6uuvvzb/PSAgQMaPPnt09erV5Y5whIWFSdJlw8ytt96qHTt2qLi42Fy2du3aCt+CHRsbq1tvvVUvvfTSZT+V+NJ+fSkoKJDH4ym3/I033pAk9erVy1z20EMPqaSkRK+//rq5rKioSMuWLVNcXBx3VgG1hCM5AKolIyNDd999t7p27apx48bplltuUX5+vlwul/71r3+Zn4Pz05/+VLNnz9aYMWPUt29f7d+/X++88065IzC33nqrwsPDlZmZqUaNGiksLExxcXGKjo7Wk08+qffee08DBw7Uww8/rM8//1xvv/22eYTGF39/f73xxhsaNGiQunTpojFjxqhly5b697//rc2bN8tut+vDDz+s0L62bNmiZ599Vg899JA6dOig4uJiffTRR/rjH/+oXr166b//+7/N2ri4OA0fPlxTp07VyZMn1b59e7311lv65z//We7IFoAaVNe3dwG4flzuFnLDMIzPP//cGD16tBEZGWkEBgYaLVu2NH76058a7733nllz4cIF43//93+NFi1aGCEhIcZdd91luFyucrd/G4Zh/OlPfzJiYmKMBg0alLudfP78+UbLli0Nm81m3HXXXcaePXuueAv5j/sss2/fPmPo0KFGs2bNDJvNZrRt29Z4+OGHjZycnArP4rPPPjNGjx5t3HLLLUZISIgRHBxsdOnSxZgxY4bx/fffl6s/f/688dxzzxmRkZGGzWYz7rzzTiMrK6vCzweg8vjuKgAAYElckwMAACyJa3IA4BIlJSU+L0Bu2LBhtW81B1D7CDkAcIkvv/yy3IcI/tiMGTM0c+bMa9MQgCoj5ADAJSIjI5WdnX3Vmop8Jg+AuseFxwAAwJK48BgAAFjSDX26qrS0VCdOnFCjRo2u+lHyAACg/jAMQ999952ioqLk73/l4zU3dMg5ceIEH6cOAMB16ssvv1SrVq2uuP6GDjmNGjWS9MOQLv3SvPrC4/Fo48aNSkhIUGBgYF23Uy8xI9+YkW/MyDdm5Bsz8q2mZlRYWKjWrVub/x2/khs65JSdorLb7fU25ISGhsput/MX5gqYkW/MyDdm5Bsz8o0Z+VbTM/J1qUmlLjwuKSnR9OnTFR0drZCQEN16662aM2eO1zcLG4ah9PR0tWjRQiEhIYqPj9fRo0e99nPq1CmNGjVKdrtd4eHhGjt2bLlvBP7b3/6me+65R8HBwWrdurXmzZtXrp/Vq1erU6dOCg4OVteuXbV+/frKvBwAAGBhlQo5L7zwgl577TUtWbJEn376qV544QXNmzdPr7zyilkzb948vfzyy8rMzNTOnTsVFhYmp9OpCxcumDWjRo3SwYMHlZ2drbVr12rbtm0aP368ub6wsFAJCQlq27atcnNz9eKLL2rmzJl6/fXXzZrt27dr5MiRGjt2rPbt26chQ4ZoyJAhOnDgQHXmAQAALKJSIWf79u0aPHiwEhMT1a5dOz300ENKSEjQrl27JP1wFGfRokWaNm2aBg8erG7duun3v/+9Tpw4oTVr1kiSPv30U2VlZemNN95QXFyc7r77br3yyit69913deLECUnSO++8o+LiYi1dulRdunTRiBEj9Oyzz2rBggVmL4sXL9bAgQM1adIkde7cWXPmzFHPnj21ZMmSGhoNAAC4nlXqmpy+ffvq9ddf19///nfddttt+utf/6qPP/7YDB/Hjh2T2+1WfHy8uU3jxo0VFxcnl8ulESNGyOVyKTw8XL169TJr4uPj5e/vr507d+rBBx+Uy+XSvffeq6CgILPG6XTqhRde0OnTp9WkSRO5XC6lpaV59ed0Os0wdTlFRUUqKioyHxcWFkr64Ryhx+OpzCiuibKe6mNv9QUz8o0Z+caMfGNGvjEj32pqRhXdvlIhZ8qUKSosLFSnTp0UEBCgkpIS/frXv9aoUaMkSW63W5IUERHhtV1ERIS5zu12q3nz5t5NNGigpk2betX8+LtjyvbpdrvVpEkTud3uqz7P5cydO1ezZs0qt3zjxo0KDQ31+frriq+PmAczqghm5Bsz8o0Z+caMfKvujM6dO1ehukqFnFWrVumdd97RihUr1KVLF+Xl5Sk1NVVRUVFKSkqqUqPX0tSpU72O/pTdgpaQkFBv767Kzs7WgAEDuFL/CpiRb8zIN2bkGzPyjRn5VlMzKjsT40ulQs6kSZM0ZcoUjRgxQpLUtWtXffHFF5o7d66SkpIUGRkpScrPz1eLFi3M7fLz89WjRw9JP3z53cmTJ732e/HiRZ06dcrcPjIyUvn5+V41ZY991ZStvxybzSabzVZueWBgYL1+Q9b3/uoDZuQbM/KNGfnGjHxjRr5Vd0YV3bZSFx6fO3eu3McnBwQEqLS0VJIUHR2tyMhI5eTkmOsLCwu1c+dOORwOSZLD4VBBQYFyc3PNmk2bNqm0tFRxcXFmzbZt27zOuWVnZ6tjx45q0qSJWXPp85TVlD0PAAC4sVUq5PzsZz/Tr3/9a61bt07//Oc/9f7772vBggV68MEHJf3woTypqan61a9+pQ8++ED79+/X6NGjFRUVpSFDhkiSOnfurIEDB2rcuHHatWuXPvnkE6WkpGjEiBGKioqSJD366KMKCgrS2LFjdfDgQa1cuVKLFy/2OtX085//XFlZWZo/f74OHz6smTNnas+ePUpJSamh0QAAgOtZpU5XvfLKK5o+fbr+53/+RydPnlRUVJSeeuoppaenmzWTJ0/W2bNnNX78eBUUFOjuu+9WVlaWgoODzZp33nlHKSkpeuCBB+Tv769hw4bp5ZdfNtc3btxYGzduVHJysmJjY3XTTTcpPT3d67N0+vbtqxUrVmjatGn65S9/qQ4dOmjNmjW6/fbbqzMPAABgEZUKOY0aNdKiRYu0aNGiK9b4+flp9uzZmj179hVrmjZtqhUrVlz1ubp166aPPvroqjXDhw/X8OHDr1oDAABuTJU6XQUAAHC9IOQAAABLIuQAAABLqtQ1OQAAoG60m7LOZ80/n0+8Bp1cPziSAwAALImQAwAALImQAwAALImQAwAALImQAwAALImQAwAALImQAwAALImQAwAALIkPAwQAwCL4wEBvHMkBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWRMgBAACWVKmQ065dO/n5+ZX7k5ycLEm6cOGCkpOT1axZMzVs2FDDhg1Tfn6+1z6OHz+uxMREhYaGqnnz5po0aZIuXrzoVbNlyxb17NlTNptN7du31/Lly8v1kpGRoXbt2ik4OFhxcXHatWtXJV86AACwskqFnN27d+urr74y/2RnZ0uShg8fLkmaOHGiPvzwQ61evVpbt27ViRMnNHToUHP7kpISJSYmqri4WNu3b9dbb72l5cuXKz093aw5duyYEhMTdf/99ysvL0+pqal68skntWHDBrNm5cqVSktL04wZM7R37151795dTqdTJ0+erNYwAACAdVQq5Nx8882KjIw0/6xdu1a33nqr7rvvPp05c0ZvvvmmFixYoP79+ys2NlbLli3T9u3btWPHDknSxo0bdejQIb399tvq0aOHBg0apDlz5igjI0PFxcWSpMzMTEVHR2v+/Pnq3LmzUlJS9NBDD2nhwoVmHwsWLNC4ceM0ZswYxcTEKDMzU6GhoVq6dGkNjgYAAFzPGlR1w+LiYr399ttKS0uTn5+fcnNz5fF4FB8fb9Z06tRJbdq0kcvlUp8+feRyudS1a1dFRESYNU6nUxMmTNDBgwd1xx13yOVyee2jrCY1NdV83tzcXE2dOtVc7+/vr/j4eLlcrqv2XFRUpKKiIvNxYWGhJMnj8cjj8VR1FLWmrKf62Ft9wYx8Y0a+MSPfmJFvtT0jW4BRI/upy59hTc2oottXOeSsWbNGBQUFevzxxyVJbrdbQUFBCg8P96qLiIiQ2+02ay4NOGXry9ZdraawsFDnz5/X6dOnVVJSctmaw4cPX7XnuXPnatasWeWWb9y4UaGhoVd/wXWo7LQgrowZ+caMfGNGvjEj32prRvN618x+1q9fXzM7qobqzujcuXMVqqtyyHnzzTc1aNAgRUVFVXUX19zUqVOVlpZmPi4sLFTr1q2VkJAgu91eh51dnsfjUXZ2tgYMGKDAwMC6bqdeYka+MSPfmJFvzMi32p7R7TM3+C6qgAMznTWyn6qoqRmVnYnxpUoh54svvtBf/vIX/fGPfzSXRUZGqri4WAUFBV5Hc/Lz8xUZGWnW/PguqLK7ry6t+fEdWfn5+bLb7QoJCVFAQIACAgIuW1O2jyux2Wyy2WzllgcGBtbrv7T1vb/6gBn5xox8Y0a+MSPfamtGRSV+NbKf+vDzq+6MKrptlT4nZ9myZWrevLkSExPNZbGxsQoMDFROTo657MiRIzp+/LgcDockyeFwaP/+/V53QWVnZ8tutysmJsasuXQfZTVl+wgKClJsbKxXTWlpqXJycswaAACASh/JKS0t1bJly5SUlKQGDf6zeePGjTV27FilpaWpadOmstvteuaZZ+RwONSnTx9JUkJCgmJiYvTYY49p3rx5crvdmjZtmpKTk80jLE8//bSWLFmiyZMn64knntCmTZu0atUqrVu3znyutLQ0JSUlqVevXurdu7cWLVqks2fPasyYMdWdBwAAsIhKh5y//OUvOn78uJ544oly6xYuXCh/f38NGzZMRUVFcjqdevXVV831AQEBWrt2rSZMmCCHw6GwsDAlJSVp9uzZZk10dLTWrVuniRMnavHixWrVqpXeeOMNOZ3/OYf4yCOP6Ouvv1Z6errcbrd69OihrKyschcjAwCAG1elQ05CQoIM4/K3sQUHBysjI0MZGRlX3L5t27Y+r+zu16+f9u3bd9WalJQUpaSk+G4YAADckPjuKgAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmV/u4qAABQs9pNWVfXLVgSR3IAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlEXIAAIAlVTrk/Pvf/9Z///d/q1mzZgoJCVHXrl21Z88ec71hGEpPT1eLFi0UEhKi+Ph4HT161Gsfp06d0qhRo2S32xUeHq6xY8fq+++/96r529/+pnvuuUfBwcFq3bq15s2bV66X1atXq1OnTgoODlbXrl21fv36yr4cAABgUZUKOadPn9Zdd92lwMBA/fnPf9ahQ4c0f/58NWnSxKyZN2+eXn75ZWVmZmrnzp0KCwuT0+nUhQsXzJpRo0bp4MGDys7O1tq1a7Vt2zaNHz/eXF9YWKiEhAS1bdtWubm5evHFFzVz5ky9/vrrZs327ds1cuRIjR07Vvv27dOQIUM0ZMgQHThwoDrzAAAAFtGgMsUvvPCCWrdurWXLlpnLoqOjzX83DEOLFi3StGnTNHjwYEnS73//e0VERGjNmjUaMWKEPv30U2VlZWn37t3q1auXJOmVV17RT37yE7300kuKiorSO++8o+LiYi1dulRBQUHq0qWL8vLytGDBAjMMLV68WAMHDtSkSZMkSXPmzFF2draWLFmizMzM6k0FAABc9yoVcj744AM5nU4NHz5cW7duVcuWLfU///M/GjdunCTp2LFjcrvdio+PN7dp3Lix4uLi5HK5NGLECLlcLoWHh5sBR5Li4+Pl7++vnTt36sEHH5TL5dK9996roKAgs8bpdOqFF17Q6dOn1aRJE7lcLqWlpXn153Q6tWbNmiv2X1RUpKKiIvNxYWGhJMnj8cjj8VRmFNdEWU/1sbf6ghn5xox8Y0a+MSPfqjMjW4BR0+1cUV3+DGvqfVTR7SsVcv7xj3/otddeU1pamn75y19q9+7devbZZxUUFKSkpCS53W5JUkREhNd2ERER5jq3263mzZt7N9GggZo2bepVc+kRokv36Xa71aRJE7nd7qs+z+XMnTtXs2bNKrd848aNCg0NrcgI6kR2dnZdt1DvMSPfmJFvzMg3ZuRbVWY0r3ctNHIF9eH61eq+j86dO1ehukqFnNLSUvXq1Uu/+c1vJEl33HGHDhw4oMzMTCUlJVW+y2ts6tSpXkd/CgsL1bp1ayUkJMhut9dhZ5fn8XiUnZ2tAQMGKDAwsK7bqZeYkW/MyDdm5Bsz8q06M7p95oZa6qq8AzOd1+y5fqym3kdlZ2J8qVTIadGihWJiYryWde7cWX/4wx8kSZGRkZKk/Px8tWjRwqzJz89Xjx49zJqTJ0967ePixYs6deqUuX1kZKTy8/O9asoe+6opW385NptNNput3PLAwMB6/Ze2vvdXHzAj35iRb8zIN2bkW1VmVFTiV0vdlFcffn7VfR9VdNtK3V1111136ciRI17L/v73v6tt27aSfrgIOTIyUjk5Oeb6wsJC7dy5Uw6HQ5LkcDhUUFCg3Nxcs2bTpk0qLS1VXFycWbNt2zavc27Z2dnq2LGjeSeXw+Hwep6ymrLnAQAAN7ZKhZyJEydqx44d+s1vfqPPPvtMK1as0Ouvv67k5GRJkp+fn1JTU/WrX/1KH3zwgfbv36/Ro0crKipKQ4YMkfTDkZ+BAwdq3Lhx2rVrlz755BOlpKRoxIgRioqKkiQ9+uijCgoK0tixY3Xw4EGtXLlSixcv9jrV9POf/1xZWVmaP3++Dh8+rJkzZ2rPnj1KSUmpodEAAIDrWaVOV9155516//33NXXqVM2ePVvR0dFatGiRRo0aZdZMnjxZZ8+e1fjx41VQUKC7775bWVlZCg4ONmveeecdpaSk6IEHHpC/v7+GDRuml19+2VzfuHFjbdy4UcnJyYqNjdVNN92k9PR0r8/S6du3r1asWKFp06bpl7/8pTp06KA1a9bo9ttvr848AACARVQq5EjST3/6U/30pz+94no/Pz/Nnj1bs2fPvmJN06ZNtWLFiqs+T7du3fTRRx9dtWb48OEaPnz41RsGAAA3JL67CgAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWBIhBwAAWFKDum4AAABcO+2mrPNZ88/nE69BJ7WPIzkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSuLsKAIBaVJG7mVA7KnUkZ+bMmfLz8/P606lTJ3P9hQsXlJycrGbNmqlhw4YaNmyY8vPzvfZx/PhxJSYmKjQ0VM2bN9ekSZN08eJFr5otW7aoZ8+estlsat++vZYvX16ul4yMDLVr107BwcGKi4vTrl27KvNSAACAxVX6dFWXLl301VdfmX8+/vhjc93EiRP14YcfavXq1dq6datOnDihoUOHmutLSkqUmJio4uJibd++XW+99ZaWL1+u9PR0s+bYsWNKTEzU/fffr7y8PKWmpurJJ5/Uhg0bzJqVK1cqLS1NM2bM0N69e9W9e3c5nU6dPHmyqnMAAAAWU+mQ06BBA0VGRpp/brrpJknSmTNn9Oabb2rBggXq37+/YmNjtWzZMm3fvl07duyQJG3cuFGHDh3S22+/rR49emjQoEGaM2eOMjIyVFxcLEnKzMxUdHS05s+fr86dOyslJUUPPfSQFi5caPawYMECjRs3TmPGjFFMTIwyMzMVGhqqpUuX1sRMAACABVT6mpyjR48qKipKwcHBcjgcmjt3rtq0aaPc3Fx5PB7Fx8ebtZ06dVKbNm3kcrnUp08fuVwude3aVREREWaN0+nUhAkTdPDgQd1xxx1yuVxe+yirSU1NlSQVFxcrNzdXU6dONdf7+/srPj5eLpfrqr0XFRWpqKjIfFxYWChJ8ng88ng8lR1FrSvrqT72Vl8wI9+YkW/MyDdm5NuVZmQLMOqinWqprZ9zTb2PKrp9pUJOXFycli9fro4dO+qrr77SrFmzdM899+jAgQNyu90KCgpSeHi41zYRERFyu92SJLfb7RVwytaXrbtaTWFhoc6fP6/Tp0+rpKTksjWHDx++av9z587VrFmzyi3fuHGjQkNDfQ+gjmRnZ9d1C/UeM/KNGfnGjHxjRr79eEbzetdRI9Wwfv36Wt1/dd9H586dq1BdpULOoEGDzH/v1q2b4uLi1LZtW61atUohISGV67AOTJ06VWlpaebjwsJCtW7dWgkJCbLb7XXY2eV5PB5lZ2drwIABCgwMrOt26iVm5Bsz8o0Z+caMfLvSjG6fueEqW9VPB2Y6a2W/NfU+KjsT40u1biEPDw/Xbbfdps8++0wDBgxQcXGxCgoKvI7m5OfnKzIyUpIUGRlZ7i6osruvLq358R1Z+fn5stvtCgkJUUBAgAICAi5bU7aPK7HZbLLZbOWWBwYG1uu/tPW9v/qAGfnGjHxjRr4xI99+PKOiEr867KZqavtnXN33UUW3rdaHAX7//ff6/PPP1aJFC8XGxiowMFA5OTnm+iNHjuj48eNyOBySJIfDof3793vdBZWdnS273a6YmBiz5tJ9lNWU7SMoKEixsbFeNaWlpcrJyTFrAAAAKhVynnvuOW3dulX//Oc/tX37dj344IMKCAjQyJEj1bhxY40dO1ZpaWnavHmzcnNzNWbMGDkcDvXp00eSlJCQoJiYGD322GP661//qg0bNmjatGlKTk42j7A8/fTT+sc//qHJkyfr8OHDevXVV7Vq1SpNnDjR7CMtLU2/+93v9NZbb+nTTz/VhAkTdPbsWY0ZM6YGRwMAAK5nlTpd9a9//UsjR47Ut99+q5tvvll33323duzYoZtvvlmStHDhQvn7+2vYsGEqKiqS0+nUq6++am4fEBCgtWvXasKECXI4HAoLC1NSUpJmz55t1kRHR2vdunWaOHGiFi9erFatWumNN96Q0/mf84OPPPKIvv76a6Wnp8vtdqtHjx7KysoqdzEyAAC4cVUq5Lz77rtXXR8cHKyMjAxlZGRcsaZt27Y+r9ru16+f9u3bd9WalJQUpaSkXLUGAADcuPiCTgAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEnVCjnPP/+8/Pz8lJqaai67cOGCkpOT1axZMzVs2FDDhg1Tfn6+13bHjx9XYmKiQkND1bx5c02aNEkXL170qtmyZYt69uwpm82m9u3ba/ny5eWePyMjQ+3atVNwcLDi4uK0a9eu6rwcAABgIVUOObt379Zvf/tbdevWzWv5xIkT9eGHH2r16tXaunWrTpw4oaFDh5rrS0pKlJiYqOLiYm3fvl1vvfWWli9frvT0dLPm2LFjSkxM1P3336+8vDylpqbqySef1IYNG8yalStXKi0tTTNmzNDevXvVvXt3OZ1OnTx5sqovCQAAWEiVQs7333+vUaNG6Xe/+52aNGliLj9z5ozefPNNLViwQP3791dsbKyWLVum7du3a8eOHZKkjRs36tChQ3r77bfVo0cPDRo0SHPmzFFGRoaKi4slSZmZmYqOjtb8+fPVuXNnpaSk6KGHHtLChQvN51qwYIHGjRunMWPGKCYmRpmZmQoNDdXSpUurMw8AAGARDaqyUXJyshITExUfH69f/epX5vLc3Fx5PB7Fx8ebyzp16qQ2bdrI5XKpT58+crlc6tq1qyIiIswap9OpCRMm6ODBg7rjjjvkcrm89lFWU3ZarLi4WLm5uZo6daq53t/fX/Hx8XK5XFfsu6ioSEVFRebjwsJCSZLH45HH46nKKGpVWU/1sbf6ghn5xox8Y0a+MSPfrjQjW4BRF+1US239nGvqfVTR7Ssdct59913t3btXu3fvLrfO7XYrKChI4eHhXssjIiLkdrvNmksDTtn6snVXqyksLNT58+d1+vRplZSUXLbm8OHDV+x97ty5mjVrVrnlGzduVGho6BW3q2vZ2dl13UK9x4x8Y0a+MSPfmJFvP57RvN511Eg1rF+/vlb3X9330blz5ypUV6mQ8+WXX+rnP/+5srOzFRwcXKXG6tLUqVOVlpZmPi4sLFTr1q2VkJAgu91eh51dnsfjUXZ2tgYMGKDAwMC6bqdeYka+MSPfmJFvzMi3K83o9pkbrrJV/XRgprNW9ltT76OyMzG+VCrk5Obm6uTJk+rZs6e5rKSkRNu2bdOSJUu0YcMGFRcXq6CgwOtoTn5+viIjIyVJkZGR5e6CKrv76tKaH9+RlZ+fL7vdrpCQEAUEBCggIOCyNWX7uBybzSabzVZueWBgYL3+S1vf+6sPmJFvzMg3ZuQbM/LtxzMqKvGrw26qprZ/xtV9H1V020pdePzAAw9o//79ysvLM//06tVLo0aNMv89MDBQOTk55jZHjhzR8ePH5XA4JEkOh0P79+/3ugsqOztbdrtdMTExZs2l+yirKdtHUFCQYmNjvWpKS0uVk5Nj1gAAgBtbpY7kNGrUSLfffrvXsrCwMDVr1sxcPnbsWKWlpalp06ay2+165pln5HA41KdPH0lSQkKCYmJi9Nhjj2nevHlyu92aNm2akpOTzaMsTz/9tJYsWaLJkyfriSee0KZNm7Rq1SqtW7fOfN60tDQlJSWpV69e6t27txYtWqSzZ89qzJgx1RoIAACwhirdXXU1CxculL+/v4YNG6aioiI5nU69+uqr5vqAgACtXbtWEyZMkMPhUFhYmJKSkjR79myzJjo6WuvWrdPEiRO1ePFitWrVSm+88Yaczv+cI3zkkUf09ddfKz09XW63Wz169FBWVla5i5EBAMCNqdohZ8uWLV6Pg4ODlZGRoYyMjCtu07ZtW59Xbvfr10/79u27ak1KSopSUlIq3CsAALhx8N1VAADAkgg5AADAkgg5AADAkmr8wmMAAG4U7ab8565fW4Cheb1/+PC/6/GzcayIIzkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSCDkAAMCSKhVyXnvtNXXr1k12u112u10Oh0N//vOfzfUXLlxQcnKymjVrpoYNG2rYsGHKz8/32sfx48eVmJio0NBQNW/eXJMmTdLFixe9arZs2aKePXvKZrOpffv2Wr58ebleMjIy1K5dOwUHBysuLk67du2qzEsBAAAWV6mQ06pVKz3//PPKzc3Vnj171L9/fw0ePFgHDx6UJE2cOFEffvihVq9era1bt+rEiRMaOnSouX1JSYkSExNVXFys7du366233tLy5cuVnp5u1hw7dkyJiYm6//77lZeXp9TUVD355JPasGGDWbNy5UqlpaVpxowZ2rt3r7p37y6n06mTJ09Wdx4AAMAiKhVyfvazn+knP/mJOnTooNtuu02//vWv1bBhQ+3YsUNnzpzRm2++qQULFqh///6KjY3VsmXLtH37du3YsUOStHHjRh06dEhvv/22evTooUGDBmnOnDnKyMhQcXGxJCkzM1PR0dGaP3++OnfurJSUFD300ENauHCh2ceCBQs0btw4jRkzRjExMcrMzFRoaKiWLl1ag6MBAADXswZV3bCkpESrV6/W2bNn5XA4lJubK4/Ho/j4eLOmU6dOatOmjVwul/r06SOXy6WuXbsqIiLCrHE6nZowYYIOHjyoO+64Qy6Xy2sfZTWpqamSpOLiYuXm5mrq1Knmen9/f8XHx8vlcl2156KiIhUVFZmPCwsLJUkej0cej6eqo6g1ZT3Vx97qC2bkGzPyjRn5xowuzxZg/Off/Q2vf17PauvnXFPvo4puX+mQs3//fjkcDl24cEENGzbU+++/r5iYGOXl5SkoKEjh4eFe9REREXK73ZIkt9vtFXDK1petu1pNYWGhzp8/r9OnT6ukpOSyNYcPH75q73PnztWsWbPKLd+4caNCQ0N9v/g6kp2dXdct1HvMyDdm5Bsz8o0ZeZvXu/yyOb1Kr30jNWz9+vW1uv/qvo/OnTtXobpKh5yOHTsqLy9PZ86c0XvvvaekpCRt3bq10g3WhalTpyotLc18XFhYqNatWyshIUF2u70OO7s8j8ej7OxsDRgwQIGBgXXdTr3EjHxjRr4xI9+Y0eXdPvM/14va/A3N6VWq6Xv8VVTqV4ddVd+Bmc5a2W9NvY/KzsT4UumQExQUpPbt20uSYmNjtXv3bi1evFiPPPKIiouLVVBQ4HU0Jz8/X5GRkZKkyMjIcndBld19dWnNj+/Iys/Pl91uV0hIiAICAhQQEHDZmrJ9XInNZpPNZiu3PDAwsF7/pa3v/dUHzMg3ZuQbM/KNGXkrKikfZopK/S67/HpS2z/j6r6PKrpttT8np7S0VEVFRYqNjVVgYKBycnLMdUeOHNHx48flcDgkSQ6HQ/v37/e6Cyo7O1t2u10xMTFmzaX7KKsp20dQUJBiY2O9akpLS5WTk2PWAAAAVOpIztSpUzVo0CC1adNG3333nVasWKEtW7Zow4YNaty4scaOHau0tDQ1bdpUdrtdzzzzjBwOh/r06SNJSkhIUExMjB577DHNmzdPbrdb06ZNU3JysnmE5emnn9aSJUs0efJkPfHEE9q0aZNWrVqldevWmX2kpaUpKSlJvXr1Uu/evbVo0SKdPXtWY8aMqcHRAACA61mlQs7Jkyc1evRoffXVV2rcuLG6deumDRs2aMCAAZKkhQsXyt/fX8OGDVNRUZGcTqdeffVVc/uAgACtXbtWEyZMkMPhUFhYmJKSkjR79myzJjo6WuvWrdPEiRO1ePFitWrVSm+88Yaczv+cH3zkkUf09ddfKz09XW63Wz169FBWVla5i5EBAMCNq1Ih580337zq+uDgYGVkZCgjI+OKNW3btvV51Xa/fv20b9++q9akpKQoJSXlqjUAAODGxXdXAQAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAASyLkAAAAS6r0t5ADAHAjaDdlne8i1GscyQEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZEyAEAAJZUqZAzd+5c3XnnnWrUqJGaN2+uIUOG6MiRI141Fy5cUHJyspo1a6aGDRtq2LBhys/P96o5fvy4EhMTFRoaqubNm2vSpEm6ePGiV82WLVvUs2dP2Ww2tW/fXsuXLy/XT0ZGhtq1a6fg4GDFxcVp165dlXk5AADAwioVcrZu3ark5GTt2LFD2dnZ8ng8SkhI0NmzZ82aiRMn6sMPP9Tq1au1detWnThxQkOHDjXXl5SUKDExUcXFxdq+fbveeustLV++XOnp6WbNsWPHlJiYqPvvv195eXlKTU3Vk08+qQ0bNpg1K1euVFpammbMmKG9e/eqe/fucjqdOnnyZHXmAQAALKJBZYqzsrK8Hi9fvlzNmzdXbm6u7r33Xp05c0ZvvvmmVqxYof79+0uSli1bps6dO2vHjh3q06ePNm7cqEOHDukvf/mLIiIi1KNHD82ZM0e/+MUvNHPmTAUFBSkzM1PR0dGaP3++JKlz5876+OOPtXDhQjmdTknSggULNG7cOI0ZM0aSlJmZqXXr1mnp0qWaMmVKtQcDAACub5UKOT925swZSVLTpk0lSbm5ufJ4PIqPjzdrOnXqpDZt2sjlcqlPnz5yuVzq2rWrIiIizBqn06kJEybo4MGDuuOOO+Ryubz2UVaTmpoqSSouLlZubq6mTp1qrvf391d8fLxcLtcV+y0qKlJRUZH5uLCwUJLk8Xjk8XiqOIXaU9ZTfeytvmBGvjEj35iRbzfijGwBRuXq/Q2vf17PauvnXFPvo4puX+WQU1paqtTUVN111126/fbbJUlut1tBQUEKDw/3qo2IiJDb7TZrLg04ZevL1l2tprCwUOfPn9fp06dVUlJy2ZrDhw9fsee5c+dq1qxZ5ZZv3LhRoaGhFXjVdSM7O7uuW6j3mJFvzMg3ZuTbjTSjeb2rtt2cXqU120gdWL9+fa3uv7rvo3PnzlWorsohJzk5WQcOHNDHH39c1V1cc1OnTlVaWpr5uLCwUK1bt1ZCQoLsdnsddnZ5Ho9H2dnZGjBggAIDA+u6nXqJGfnGjHxjRr7diDO6feYG30WXsPkbmtOrVNP3+Kuo1K+Wuro2Dsx01sp+a+p9VHYmxpcqhZyUlBStXbtW27ZtU6tWrczlkZGRKi4uVkFBgdfRnPz8fEVGRpo1P74Lquzuq0trfnxHVn5+vux2u0JCQhQQEKCAgIDL1pTt43JsNptsNlu55YGBgfX6L219768+YEa+MSPfmJFvN9KMikqqFlSKSv2qvG19Uds/4+q+jyq6baXurjIMQykpKXr//fe1adMmRUdHe62PjY1VYGCgcnJyzGVHjhzR8ePH5XA4JEkOh0P79+/3ugsqOztbdrtdMTExZs2l+yirKdtHUFCQYmNjvWpKS0uVk5Nj1gAAgBtbpY7kJCcna8WKFfrTn/6kRo0amdfQNG7cWCEhIWrcuLHGjh2rtLQ0NW3aVHa7Xc8884wcDof69OkjSUpISFBMTIwee+wxzZs3T263W9OmTVNycrJ5lOXpp5/WkiVLNHnyZD3xxBPatGmTVq1apXXr1pm9pKWlKSkpSb169VLv3r21aNEinT171rzbCgAA3NgqFXJee+01SVK/fv28li9btkyPP/64JGnhwoXy9/fXsGHDVFRUJKfTqVdffdWsDQgI0Nq1azVhwgQ5HA6FhYUpKSlJs2fPNmuio6O1bt06TZw4UYsXL1arVq30xhtvmLePS9Ijjzyir7/+Wunp6XK73erRo4eysrLKXYwMAABuTJUKOYbh+7a44OBgZWRkKCMj44o1bdu29Xnldr9+/bRv376r1qSkpCglJcVnTwAA4MZTrc/JAQDgetRuyjrfRbju8QWdAADAkgg5AADAkjhdBQAAvFTkdN4/n0+8Bp1UD0dyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJTWo6wYAAKhJ7aasq+sWUE9wJAcAAFgSIQcAAFgSIQcAAFgSIQcAAFgSIQcAAFgSIQcAAFgSIQcAAFgSIQcAAFhSpUPOtm3b9LOf/UxRUVHy8/PTmjVrvNYbhqH09HS1aNFCISEhio+P19GjR71qTp06pVGjRslutys8PFxjx47V999/71Xzt7/9Tffcc4+Cg4PVunVrzZs3r1wvq1evVqdOnRQcHKyuXbtq/fr1lX05AADAoiodcs6ePavu3bsrIyPjsuvnzZunl19+WZmZmdq5c6fCwsLkdDp14cIFs2bUqFE6ePCgsrOztXbtWm3btk3jx4831xcWFiohIUFt27ZVbm6uXnzxRc2cOVOvv/66WbN9+3aNHDlSY8eO1b59+zRkyBANGTJEBw4cqOxLAgAAFlTpr3UYNGiQBg0adNl1hmFo0aJFmjZtmgYPHixJ+v3vf6+IiAitWbNGI0aM0KeffqqsrCzt3r1bvXr1kiS98sor+slPfqKXXnpJUVFReuedd1RcXKylS5cqKChIXbp0UV5enhYsWGCGocWLF2vgwIGaNGmSJGnOnDnKzs7WkiVLlJmZWaVhAAAA66jR7646duyY3G634uPjzWWNGzdWXFycXC6XRowYIZfLpfDwcDPgSFJ8fLz8/f21c+dOPfjgg3K5XLr33nsVFBRk1jidTr3wwgs6ffq0mjRpIpfLpbS0NK/ndzqd5U6fXaqoqEhFRUXm48LCQkmSx+ORx+Op7suvcWU91cfe6gtm5Bsz8o0Z+XY9zcgWYNTN8/obXv+0uqq8F2rqfVTR7Ws05LjdbklSRESE1/KIiAhzndvtVvPmzb2baNBATZs29aqJjo4ut4+ydU2aNJHb7b7q81zO3LlzNWvWrHLLN27cqNDQ0Iq8xDqRnZ1d1y3Ue8zIN2bkGzPy7XqY0bzedfv8c3qV1m0D10h1roOt7vvo3LlzFaq7ob6FfOrUqV5HfwoLC9W6dWslJCTIbrfXYWeX5/F4lJ2drQEDBigwMLCu26mXmJFvzMg3ZuTb9TSj22duqJPntfkbmtOrVNP3+Kuo1K9OeriWDsx0VnqbmnoflZ2J8aVGQ05kZKQkKT8/Xy1atDCX5+fnq0ePHmbNyZMnvba7ePGiTp06ZW4fGRmp/Px8r5qyx75qytZfjs1mk81mK7c8MDCwXv+lre/91QfMyDdm5Bsz8u16mFFRSd0GjKJSvzrv4Vqozvuguu+jim5bo5+TEx0drcjISOXk5JjLCgsLtXPnTjkcDkmSw+FQQUGBcnNzzZpNmzaptLRUcXFxZs22bdu8zrllZ2erY8eOatKkiVlz6fOU1ZQ9DwAAuLFVOuR8//33ysvLU15enqQfLjbOy8vT8ePH5efnp9TUVP3qV7/SBx98oP3792v06NGKiorSkCFDJEmdO3fWwIEDNW7cOO3atUuffPKJUlJSNGLECEVFRUmSHn30UQUFBWns2LE6ePCgVq5cqcWLF3udavr5z3+urKwszZ8/X4cPH9bMmTO1Z88epaSkVH8qAADgulfp01V79uzR/fffbz4uCx5JSUlavny5Jk+erLNnz2r8+PEqKCjQ3XffraysLAUHB5vbvPPOO0pJSdEDDzwgf39/DRs2TC+//LK5vnHjxtq4caOSk5MVGxurm266Senp6V6fpdO3b1+tWLFC06ZN0y9/+Ut16NBBa9as0e23316lQQAA6r92U9bVdQu4jlQ65PTr10+GceXb4/z8/DR79mzNnj37ijVNmzbVihUrrvo83bp100cffXTVmuHDh2v48OFXbxgAANyQ+O4qAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSYQcAABgSZX+7ioAAGoDX76JmsaRHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEmEHAAAYEl8GCAAoNbxQX+oCxzJAQAAlkTIAQAAlkTIAQAAlkTIAQAAlkTIAQAAlsTdVQCAauHOKdRXHMkBAACWRMgBAACWxOkqAMAVlZ2KsgUYmtdbun3mBhWV+NVxV0DFcCQHAABYEiEHAABYEqerAOAGxV1RsDpCDgAAqLSKhOR/Pp94DTq5sus+5GRkZOjFF1+U2+1W9+7d9corr6h379513RYA1CmO0gDXechZuXKl0tLSlJmZqbi4OC1atEhOp1NHjhxR8+bN67o9AKgVBBigYq7rkLNgwQKNGzdOY8aMkSRlZmZq3bp1Wrp0qaZMmVLH3QFA5RFggJpz3Yac4uJi5ebmaurUqeYyf39/xcfHy+VyXXaboqIiFRUVmY/PnDkjSTp16pQ8Hk/tNlwFHo9H586d07fffqvAwMC6bqdeYka+MSPfamJGcXNzaqSX+vpLuUGpoXPnStXA46+SUj4n53KYUXnffvut1+Oa+n303XffSZIMw7hqXX39++TTN998o5KSEkVERHgtj4iI0OHDhy+7zdy5czVr1qxyy6Ojo2ulRwCwkkfruoHrADPydtP82t3/d999p8aNG19x/XUbcqpi6tSpSktLMx+Xlpbq1KlTatasmfz86l/qLiwsVOvWrfXll1/KbrfXdTv1EjPyjRn5xox8Y0a+MSPfampGhmHou+++U1RU1FXrrtuQc9NNNykgIED5+fley/Pz8xUZGXnZbWw2m2w2m9ey8PDw2mqxxtjtdv7C+MCMfGNGvjEj35iRb8zIt5qY0dWO4JS5bj/xOCgoSLGxscrJ+c958NLSUuXk5MjhcNRhZwAAoD64bo/kSFJaWpqSkpLUq1cv9e7dW4sWLdLZs2fNu60AAMCN67oOOY888oi+/vprpaeny+12q0ePHsrKyip3MfL1ymazacaMGeVOseE/mJFvzMg3ZuQbM/KNGfl2rWfkZ/i6/woAAOA6dN1ekwMAAHA1hBwAAGBJhBwAAGBJhBwAAGBJhBwAAGBJhJx65te//rX69u2r0NDQCn0as8fj0S9+8Qt17dpVYWFhioqK0ujRo3XixInab7aOVHZG0g8fAZ6enq4WLVooJCRE8fHxOnr0aO02WodOnTqlUaNGyW63Kzw8XGPHjtX3339/1W3cbrcee+wxRUZGKiwsTD179tQf/vCHa9TxtVeVGUmSy+VS//79FRYWJrvdrnvvvVfnz5+/Bh1fe1WdkfTD37lBgwbJz89Pa9asqd1G60hl53Pq1Ck988wz6tixo0JCQtSmTRs9++yz5pdFW0FGRobatWun4OBgxcXFadeuXVetX716tTp16qTg4GB17dpV69evr9F+CDn1THFxsYYPH64JEyZUqP7cuXPau3evpk+frr179+qPf/yjjhw5ov/6r/+q5U7rTmVnJEnz5s3Tyy+/rMzMTO3cuVNhYWFyOp26cOFCLXZad0aNGqWDBw8qOztba9eu1bZt2zR+/PirbjN69GgdOXJEH3zwgfbv36+hQ4fq4Ycf1r59+65R19dWVWbkcrk0cOBAJSQkaNeuXdq9e7dSUlLk72/NX6VVmVGZRYsW1cvvBKxJlZ3PiRMndOLECb300ks6cOCAli9frqysLI0dO/Yadl17Vq5cqbS0NM2YMUN79+5V9+7d5XQ6dfLkycvWb9++XSNHjtTYsWO1b98+DRkyREOGDNGBAwdqrikD9dKyZcuMxo0bV2nbXbt2GZKML774omabqmcqOqPS0lIjMjLSePHFF81lBQUFhs1mM/7f//t/tdhh3Th06JAhydi9e7e57M9//rPh5+dn/Pvf/77idmFhYcbvf/97r2VNmzY1fve739Var3WlqjOKi4szpk2bdi1arHNVnZFhGMa+ffuMli1bGl999ZUhyXj//fdrudtrrzrzudSqVauMoKAgw+Px1Eab11Tv3r2N5ORk83FJSYkRFRVlzJ0797L1Dz/8sJGYmOi1LC4uznjqqadqrCdr/u/HDe7MmTPy8/O7Lr589Fo4duyY3G634uPjzWWNGzdWXFycXC5XHXZWO1wul8LDw9WrVy9zWXx8vPz9/bVz584rbte3b1+tXLlSp06dUmlpqd59911duHBB/fr1uwZdX1tVmdHJkye1c+dONW/eXH379lVERITuu+8+ffzxx9eq7Wuqqu+jc+fO6dFHH1VGRsYVvyzZCqo6nx87c+aM7Ha7GjS4rr+AQMXFxcrNzfX6Pevv76/4+Pgr/p51uVxe9ZLkdDpr9PcyIcdiLly4oF/84hcaOXIk34L7/3O73ZJU7us+IiIizHVW4na71bx5c69lDRo0UNOmTa/6eletWiWPx6NmzZrJZrPpqaee0vvvv6/27dvXdsvXXFVm9I9//EOSNHPmTI0bN05ZWVnq2bOnHnjgAUte31XV99HEiRPVt29fDR48uLZbrFNVnc+lvvnmG82ZM6fCpwDrs2+++UYlJSWV+j3rdrtr/fcyIecamDJlivz8/K765/Dhw9V+Ho/Ho4cffliGYei1116rgc6vnWs1o+tZbc9o+vTpKigo0F/+8hft2bNHaWlpevjhh7V///4afBW1qzZnVFpaKkl66qmnNGbMGN1xxx1auHChOnbsqKVLl9bky6hVtTmjDz74QJs2bdKiRYtqtulr6Fr9LiosLFRiYqJiYmI0c+bM6jeOy7q+j49dJ/73f/9Xjz/++FVrbrnllmo9R1nA+eKLL7Rp06br7ihObc6o7JB5fn6+WrRoYS7Pz89Xjx49qrTPulDRGUVGRpa70O/ixYs6derUFU8ffP7551qyZIkOHDigLl26SJK6d++ujz76SBkZGcrMzKyR11DbanNGZe+dmJgYr+WdO3fW8ePHq970NVabM9q0aZM+//zzcqfKhw0bpnvuuUdbtmypRufXRm3Op8x3332ngQMHqlGjRnr//fcVGBhY3bbr3E033aSAgADl5+d7Lc/Pz7/iPCIjIytVXxWEnGvg5ptv1s0331xr+y8LOEePHtXmzZvVrFmzWnuu2lKbM4qOjlZkZKRycnLMUFNYWKidO3dW6g6tulbRGTkcDhUUFCg3N1exsbGSfviPT2lpqeLi4i67zblz5ySp3F1CAQEB5hGM60Ftzqhdu3aKiorSkSNHvJb//e9/16BBg6rf/DVSmzOaMmWKnnzySa9lXbt21cKFC/Wzn/2s+s1fA7U5H+mH3z1Op1M2m00ffPCBgoODa6z3uhQUFKTY2Fjl5ORoyJAhkn44+pmTk6OUlJTLbuNwOJSTk6PU1FRzWXZ2thwOR801VmOXMKNGfPHFF8a+ffuMWbNmGQ0bNjT27dtn7Nu3z/juu+/Mmo4dOxp//OMfDcMwjOLiYuO//uu/jFatWhl5eXnGV199Zf4pKiqqq5dRqyo7I8MwjOeff94IDw83/vSnPxl/+9vfjMGDBxvR0dHG+fPn6+Il1LqBAwcad9xxh7Fz507j448/Njp06GCMHDnSXP+vf/3L6Nixo7Fz507DMH54H7Vv39645557jJ07dxqfffaZ8dJLLxl+fn7GunXr6upl1KrKzsgwDGPhwoWG3W43Vq9ebRw9etSYNm2aERwcbHz22Wd18RJqXVVm9GOy6N1VhlH5+Zw5c8aIi4szunbtanz22Wdev68vXrxYVy+jxrz77ruGzWYzli9fbhw6dMgYP368ER4ebrjdbsMwDOOxxx4zpkyZYtZ/8sknRoMGDYyXXnrJ+PTTT40ZM2YYgYGBxv79+2usJ0JOPZOUlGRIKvdn8+bNZo0kY9myZYZhGMaxY8cuW//jbayksjMyjB9uI58+fboRERFh2Gw244EHHjCOHDly7Zu/Rr799ltj5MiRRsOGDQ273W6MGTPGKwSWvW8undnf//53Y+jQoUbz5s2N0NBQo1u3buVuKbeSqszIMAxj7ty5RqtWrYzQ0FDD4XAYH3300TXu/Nqp6owuZeWQU9n5bN68+Yq/r48dO1Y3L6KGvfLKK0abNm2MoKAgo3fv3saOHTvMdffdd5+RlJTkVb9q1SrjtttuM4KCgowuXbrU+P9U+RmGYdTccSEAAID6gburAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJRFyAACAJf1/JqpugGLa6HQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_124: 58984\n",
      "Среднее значение: -189.99443174525896, Медиана: -176.27659035997902\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feature in top15features_stable:\n",
    "    nan_values = df_for_logreg[feature].isnull().sum()\n",
    "    if nan_values != 0:\n",
    "        mean_value = df_for_logreg[feature].mean()\n",
    "        median_value = df_for_logreg[feature].median()\n",
    "        print(f\"Количество пропусков в признаке {feature}: {nan_values}\")\n",
    "        print(f\"Среднее значение: {mean_value}, Медиана: {median_value}\")\n",
    "        df_for_logreg[feature].hist(bins=50)\n",
    "        plt.title(feature)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки feature_223, feature_124, feature_30: нормальное и логнормальное распредения, поэтому можно заменять на среднее(хотя и пропусков у них много)  \n",
    "Признак feature_140: тут наблюдается несколько мод, поэтому среднее значение может исказить результат, распределение неизвестное, поэтому удалю данный признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df_for_logreg\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_124\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_for_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_124\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df_for_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_124\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m      3\u001b[0m df_for_logreg\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_30\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_for_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_30\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df_for_logreg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_30\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtop15features_stable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_140\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "df_for_logreg.loc[:, 'feature_223'] = df_for_logreg['feature_223'].fillna(df_for_logreg['feature_223'].mean())\n",
    "df_for_logreg.loc[:, 'feature_124'] = df_for_logreg['feature_124'].fillna(df_for_logreg['feature_124'].mean())\n",
    "df_for_logreg.loc[:, 'feature_30'] = df_for_logreg['feature_30'].fillna(df_for_logreg['feature_30'].mean())\n",
    "top15features_stable.remove('feature_140')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_223: 0\n",
      "Среднее значение: 126.32742768119468, Медиана: 126.32742768119464\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_124: 0\n",
      "Среднее значение: -189.9944317452589, Медиана: -189.99443174525896\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в признаке feature_30: 0\n",
      "Среднее значение: -0.15479067788770573, Медиана: -0.14507661112405362\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGzCAYAAADDgXghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3xElEQVR4nO3df1yV9f3/8ScgHH4oojZBzJTS+ZM0NQn7oSWJzjYp02kuyZG2JitlZdpNEbVlaf7WxVpT12f68UdbzmkjGVpanlARl1qaNVctd7AixB8JCNf3j75cH48oB/UcAd+P++3mbZ7rel3X9bpeHtiz65zrHD/LsiwBAAAYyL+2GwAAAKgtBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQBet2vXLvXu3VthYWHy8/PT3r17a7slALggghAAryorK9PQoUNVWFio+fPn63/+53/UunVrrx7j6NGjysjIqBcBa8KECerevbuaNm2q0NBQdezYURkZGTp58mSV2pKSEj3zzDOKjo5WSEiI4uLilJ2dXQtdA+bw47vGAHjTwYMH1bFjR/3+97/Xo48+6pNj7N69W7feequWL1+uRx55xCfH8JY77rhDPXr0UNu2bRUcHKz8/HwtW7ZMPXv21LZt2+Tv/3//PTpixAi9/vrrGj9+vNq1a6cVK1Zo165d2rp1q+64445aPAvg2tWgthsAcG05duyYJCkiIqJ2G7kMZ86cUVBQkFs4uVLvvvtulWU33XSTnnrqKe3cuVO33XabJGnnzp1avXq15syZo6eeekqSNGrUKHXp0kUTJ07Ujh07vNYTgP/DS2MAvOaRRx5Rnz59JElDhw6Vn5+f+vbtK+n7K0UPPvigmjZtquDgYPXs2VMbNmxw276wsFBPPfWUYmNj1bBhQ4WHh2vgwIH65z//ade8/fbbuvXWWyVJo0ePlp+fn/z8/LRixQpJUps2bS54lahv3752L5X78fPz0+rVqzVlyhS1bNlSoaGhKi4uliTl5uZqwIABaty4sUJDQ9WnTx+99957XplTmzZtJElFRUX2stdff10BAQEaO3asvSw4OFgpKSlyOp364osvvHJsAO64IgTAax577DG1bNlSzz//vJ544gndeuutioyM1IEDB3T77berZcuWmjRpksLCwrR27VolJSXpz3/+s+6//35J0r/+9S+tX79eQ4cOVUxMjAoKCvS73/1Offr00Ycffqjo6Gh17NhRM2bMUHp6usaOHas777xTktS7d+/L6nnmzJkKCgrSU089pZKSEgUFBWnLli0aOHCgevTooWnTpsnf31/Lly/XPffco+3bt6tXr16XdIyzZ8+qqKhIpaWl2r9/v6ZMmaJGjRq57Sc/P18//OEPFR4e7rZtZc3evXvVqlWryzpHANWwAMCLtm7dakmy1q1bZy/r16+fFRsba505c8ZeVlFRYfXu3dtq166dvezMmTNWeXm52/6OHDliORwOa8aMGfayXbt2WZKs5cuXVzl+69atreTk5CrL+/TpY/Xp06dKnzfeeKN1+vRpt77atWtnJSYmWhUVFfby06dPWzExMda9995bozmcy+l0WpLsP+3bt7e2bt3qVtO5c2frnnvuqbLtgQMHLElWZmbmJR8XgGe8NAbApwoLC7VlyxYNGzZMJ06c0Ndff62vv/5a33zzjRITE3X48GF9+eWXkiSHw2G/P6e8vFzffPONGjZsqPbt22vPnj0+6S85OVkhISH247179+rw4cN66KGH9M0339j9njp1Sv369dO2bdtUUVFxScfo1KmTsrOztX79ek2cOFFhYWFV7hr77rvv5HA4qmwbHBxsrwfgfbw0BsCnPvnkE1mWpalTp2rq1KkXrDl27JhatmypiooKLVy4UL/97W915MgRlZeX2zXNmjXzSX8xMTFujw8fPizp+4B0McePH1eTJk1qfIzw8HAlJCRIkgYPHqxVq1Zp8ODB2rNnj7p27SpJCgkJUUlJSZVtz5w5Y68H4H0EIQA+VXn15KmnnlJiYuIFa9q2bStJev755zV16lT9/Oc/18yZM9W0aVP5+/tr/PjxNb4K4+fnd8Hl5eXlCggIqLL8/IBReZw5c+aoW7duF9xXw4YNa9TLxTzwwAN6+OGHtXr1ajsItWjRwr4ydq7//ve/kqTo6OgrOiaACyMIAfCpG2+8UZIUGBhoXxW5mNdff1133323/vCHP7gtLyoq0nXXXWc/vljYkaQmTZq43Y1V6bPPPrN7qc5NN90kyf0qjreVlJSooqJCx48ft5d169ZNW7duVXFxsdsbpnNzc+31ALyP9wgB8KnmzZurb9+++t3vfmdf3TjXV199Zf89ICBA1nmf8bpu3boqV0rCwsIk6YKB56abbtL777+v0tJSe9nGjRtrfPt5jx49dNNNN+mll1664Kc/n9uvJ0VFRSorK6uy/NVXX5Uk9ezZ01724IMPqry8XK+88oq9rKSkRMuXL1dcXBx3jAE+whUhAD63dOlS3XHHHYqNjdWYMWN04403qqCgQE6nU//5z3/szwm67777NGPGDI0ePVq9e/fWvn37tHLlyipXcm666SZFREQoMzNTjRo1UlhYmOLi4hQTE6NHH31Ur7/+ugYMGKBhw4bp008/1Z/+9Cf7So8n/v7+evXVVzVw4EB17txZo0ePVsuWLfXll19q69atCg8P19/+9rca7evtt9/WE088oQcffFDt2rVTaWmptm/frr/85S/q2bOnfvazn9m1cXFxGjp0qCZPnqxjx46pbdu2+uMf/6h///vfVa6QAfCi2r5tDcC15UK3z1uWZX366afWqFGjrKioKCswMNBq2bKldd9991mvv/66XXPmzBnr17/+tdWiRQsrJCTEuv322y2n01nl1nfLsqy//vWvVqdOnawGDRpUuZV+7ty5VsuWLS2Hw2Hdfvvt1u7duy96+/z5fVbKz8+3HnjgAatZs2aWw+GwWrdubQ0bNszKycmp8Sw++eQTa9SoUdaNN95ohYSEWMHBwVbnzp2tadOmWSdPnqxS/91331lPPfWUFRUVZTkcDuvWW2+1srKyanw8AJeO7xoDAADG4j1CAADAWLxHCAAuUXl5ucc3TTds2PCKb7MH4HsEIQC4RF988UWVD2I837Rp05SRkXF1GgJw2QhCAHCJoqKilJ2dXW1NTT6zCEDt483SAADAWLxZGgAAGIuXxqpRUVGho0ePqlGjRtV+pD8AAKg7LMvSiRMnFB0dLX//6q/5EISqcfToUT7WHgCAeuqLL77Q9ddfX20NQagajRo1kvT9IM/9EsS6pKysTJs3b1b//v0VGBhY2+3USczIM2bkGTPyjBlVj/l45q0ZFRcXq1WrVvb/j1eHIFSNypfDwsPD63QQCg0NVXh4OD9YF8GMPGNGnjEjz5hR9ZiPZ96eUU3e1sKbpQEAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAw1iUHoW3btunHP/6xoqOj5efnp/Xr17uttyxL6enpatGihUJCQpSQkKDDhw+71RQWFmrkyJEKDw9XRESEUlJSdPLkSbeaDz74QHfeeaeCg4PVqlUrzZ49u0ov69atU4cOHRQcHKzY2Fi9+eabl9wLAAAw1yUHoVOnTqlr165aunTpBdfPnj1bixYtUmZmpnJzcxUWFqbExESdOXPGrhk5cqQOHDig7Oxsbdy4Udu2bdPYsWPt9cXFxerfv79at26tvLw8zZkzRxkZGXrllVfsmh07dmjEiBFKSUlRfn6+kpKSlJSUpP37919SLwAAwFwNLnWDgQMHauDAgRdcZ1mWFixYoClTpmjw4MGSpNdee02RkZFav369hg8fro8++khZWVnatWuXevbsKUlavHixfvSjH+mll15SdHS0Vq5cqdLSUi1btkxBQUHq3Lmz9u7dq3nz5tmBaeHChRowYICefvppSdLMmTOVnZ2tJUuWKDMzs0a9AABQX7SZtMljzb9fGHQVOrm2XHIQqs6RI0fkcrmUkJBgL2vcuLHi4uLkdDo1fPhwOZ1ORURE2CFIkhISEuTv76/c3Fzdf//9cjqduuuuuxQUFGTXJCYm6sUXX9S3336rJk2ayOl0Ki0tze34iYmJ9kt1NenlfCUlJSopKbEfFxcXS5LKyspUVlZ2ZcPxkcq+6mp/dQEz8owZecaMPGNG1bvS+TgCrBofo77y1nPoUrb3ahByuVySpMjISLflkZGR9jqXy6XmzZu7N9GggZo2bepWExMTU2UfleuaNGkil8vl8TieejnfrFmzNH369CrLN2/erNDQ0Iucdd2QnZ1d2y3UeczIM2bkGTPyjBlV73LnM7uX55rz3ytbX13pc+j06dM1rvVqEKrvJk+e7HaVqbi4WK1atVL//v0VHh5ei51dXFlZmbKzs3XvvfcqMDCwttupk5iRZ8zIM2bkGTOq3pXOp0vGWx5r9mckXk5rdYa3nkOVr+jUhFeDUFRUlCSpoKBALVq0sJcXFBSoW7duds2xY8fctjt79qwKCwvt7aOiolRQUOBWU/nYU8256z31cj6HwyGHw1FleWBgYJ3/oa4PPdY2ZuQZM/KMGXnGjKp3ufMpKfer0b6vBVf6HLqUbb36OUIxMTGKiopSTk6Ovay4uFi5ubmKj4+XJMXHx6uoqEh5eXl2zZYtW1RRUaG4uDi7Ztu2bW6v8WVnZ6t9+/Zq0qSJXXPucSprKo9Tk14AAIDZLjkInTx5Unv37tXevXslff+m5L179+rzzz+Xn5+fxo8fr+eee04bNmzQvn37NGrUKEVHRyspKUmS1LFjRw0YMEBjxozRzp079d577yk1NVXDhw9XdHS0JOmhhx5SUFCQUlJSdODAAa1Zs0YLFy50e9nqySefVFZWlubOnauDBw8qIyNDu3fvVmpqqiTVqBcAAGC2S35pbPfu3br77rvtx5XhJDk5WStWrNDEiRN16tQpjR07VkVFRbrjjjuUlZWl4OBge5uVK1cqNTVV/fr1k7+/v4YMGaJFixbZ6xs3bqzNmzdr3Lhx6tGjh6677jqlp6e7fdZQ7969tWrVKk2ZMkXPPvus2rVrp/Xr16tLly52TU16AQAA5rrkINS3b19Z1sVv4fPz89OMGTM0Y8aMi9Y0bdpUq1atqvY4N998s7Zv315tzdChQzV06NAr6gUAAJiL7xoDAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLG8HoTKy8s1depUxcTEKCQkRDfddJNmzpwpy7LsGsuylJ6erhYtWigkJEQJCQk6fPiw234KCws1cuRIhYeHKyIiQikpKTp58qRbzQcffKA777xTwcHBatWqlWbPnl2ln3Xr1qlDhw4KDg5WbGys3nzzTW+fMgAAqKe8HoRefPFFvfzyy1qyZIk++ugjvfjii5o9e7YWL15s18yePVuLFi1SZmamcnNzFRYWpsTERJ05c8auGTlypA4cOKDs7Gxt3LhR27Zt09ixY+31xcXF6t+/v1q3bq28vDzNmTNHGRkZeuWVV+yaHTt2aMSIEUpJSVF+fr6SkpKUlJSk/fv3e/u0AQBAPeT1ILRjxw4NHjxYgwYNUps2bfTggw+qf//+2rlzp6TvrwYtWLBAU6ZM0eDBg3XzzTfrtdde09GjR7V+/XpJ0kcffaSsrCy9+uqriouL0x133KHFixdr9erVOnr0qCRp5cqVKi0t1bJly9S5c2cNHz5cTzzxhObNm2f3snDhQg0YMEBPP/20OnbsqJkzZ6p79+5asmSJt08bAADUQw28vcPevXvrlVde0ccff6wf/vCH+uc//6l3333XDihHjhyRy+VSQkKCvU3jxo0VFxcnp9Op4cOHy+l0KiIiQj179rRrEhIS5O/vr9zcXN1///1yOp266667FBQUZNckJibqxRdf1LfffqsmTZrI6XQqLS3Nrb/ExEQ7cJ2vpKREJSUl9uPi4mJJUllZmcrKyq54Nr5Q2Vdd7a8uYEaeMSPPmJFnzKh6VzofR4Dlsaa+z95bz6FL2d7rQWjSpEkqLi5Whw4dFBAQoPLycv3mN7/RyJEjJUkul0uSFBkZ6bZdZGSkvc7lcql58+bujTZooKZNm7rVxMTEVNlH5bomTZrI5XJVe5zzzZo1S9OnT6+yfPPmzQoNDa3R+deW7Ozs2m6hzmNGnjEjz5iRZ8yoepc7n9m9PNdcK++DvdLn0OnTp2tc6/UgtHbtWq1cuVKrVq1S586dtXfvXo0fP17R0dFKTk729uG8avLkyW5XkIqLi9WqVSv1799f4eHhtdjZxZWVlSk7O1v33nuvAgMDa7udOokZecaMPGNGnjGj6l3pfLpkvOWxZn9G4uW0Vmd46zlU+YpOTXg9CD399NOaNGmShg8fLkmKjY3VZ599plmzZik5OVlRUVGSpIKCArVo0cLerqCgQN26dZMkRUVF6dixY277PXv2rAoLC+3to6KiVFBQ4FZT+dhTTeX68zkcDjkcjirLAwMD6/wPdX3osbYxI8+YkWfMyDNmVL3LnU9JuV+N9n0tuNLn0KVs6/U3S58+fVr+/u67DQgIUEVFhSQpJiZGUVFRysnJsdcXFxcrNzdX8fHxkqT4+HgVFRUpLy/PrtmyZYsqKioUFxdn12zbts3tdcDs7Gy1b99eTZo0sWvOPU5lTeVxAACA2bwehH784x/rN7/5jTZt2qR///vfeuONNzRv3jzdf//9kiQ/Pz+NHz9ezz33nDZs2KB9+/Zp1KhRio6OVlJSkiSpY8eOGjBggMaMGaOdO3fqvffeU2pqqoYPH67o6GhJ0kMPPaSgoCClpKTowIEDWrNmjRYuXOj20taTTz6prKwszZ07VwcPHlRGRoZ2796t1NRUb582AACoh7z+0tjixYs1depU/fKXv9SxY8cUHR2txx57TOnp6XbNxIkTderUKY0dO1ZFRUW64447lJWVpeDgYLtm5cqVSk1NVb9+/eTv768hQ4Zo0aJF9vrGjRtr8+bNGjdunHr06KHrrrtO6enpbp811Lt3b61atUpTpkzRs88+q3bt2mn9+vXq0qWLt08bAADUQ14PQo0aNdKCBQu0YMGCi9b4+flpxowZmjFjxkVrmjZtqlWrVlV7rJtvvlnbt2+vtmbo0KEaOnRotTUAAMBMfNcYAAAwltevCAEAgNrRZtImjzX/fmHQVeik/uCKEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWHyOEAAABuGzhtxxRQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABjLJ0Hoyy+/1M9+9jM1a9ZMISEhio2N1e7du+31lmUpPT1dLVq0UEhIiBISEnT48GG3fRQWFmrkyJEKDw9XRESEUlJSdPLkSbeaDz74QHfeeaeCg4PVqlUrzZ49u0ov69atU4cOHRQcHKzY2Fi9+eabvjhlAABQD3k9CH377be6/fbbFRgYqL///e/68MMPNXfuXDVp0sSumT17thYtWqTMzEzl5uYqLCxMiYmJOnPmjF0zcuRIHThwQNnZ2dq4caO2bdumsWPH2uuLi4vVv39/tW7dWnl5eZozZ44yMjL0yiuv2DU7duzQiBEjlJKSovz8fCUlJSkpKUn79+/39mkDAIB6qIG3d/jiiy+qVatWWr58ub0sJibG/rtlWVqwYIGmTJmiwYMHS5Jee+01RUZGav369Ro+fLg++ugjZWVladeuXerZs6ckafHixfrRj36kl156SdHR0Vq5cqVKS0u1bNkyBQUFqXPnztq7d6/mzZtnB6aFCxdqwIABevrppyVJM2fOVHZ2tpYsWaLMzExvnzoAAKhnvB6ENmzYoMTERA0dOlTvvPOOWrZsqV/+8pcaM2aMJOnIkSNyuVxKSEiwt2ncuLHi4uLkdDo1fPhwOZ1ORURE2CFIkhISEuTv76/c3Fzdf//9cjqduuuuuxQUFGTXJCYm6sUXX9S3336rJk2ayOl0Ki0tza2/xMRErV+//oK9l5SUqKSkxH5cXFwsSSorK1NZWdkVz8YXKvuqq/3VBczIM2bkGTPyjBlV70rn4wiwvNlOtWrr39Bbz6FL2d7rQehf//qXXn75ZaWlpenZZ5/Vrl279MQTTygoKEjJyclyuVySpMjISLftIiMj7XUul0vNmzd3b7RBAzVt2tSt5twrTefu0+VyqUmTJnK5XNUe53yzZs3S9OnTqyzfvHmzQkNDazqCWpGdnV3bLdR5zMgzZuQZM/KMGVXvcuczu5eXG6lGbb+f9kqfQ6dPn65xrdeDUEVFhXr27Knnn39eknTLLbdo//79yszMVHJysrcP51WTJ092u4JUXFysVq1aqX///goPD6/Fzi6urKxM2dnZuvfeexUYGFjb7dRJzMgzZuQZM/KMGVXvSufTJeMtH3R1YfszEq/asc7lredQ5Ss6NeH1INSiRQt16tTJbVnHjh315z//WZIUFRUlSSooKFCLFi3smoKCAnXr1s2uOXbsmNs+zp49q8LCQnv7qKgoFRQUuNVUPvZUU7n+fA6HQw6Ho8rywMDAOv9DXR96rG3MyDNm5Bkz8owZVe9y51NS7ueDbi6stv/9rvQ5dCnbev2usdtvv12HDh1yW/bxxx+rdevWkr5/43RUVJRycnLs9cXFxcrNzVV8fLwkKT4+XkVFRcrLy7NrtmzZooqKCsXFxdk127Ztc3sdMDs7W+3bt7fvUIuPj3c7TmVN5XEAAIDZvB6EJkyYoPfff1/PP/+8PvnkE61atUqvvPKKxo0bJ0ny8/PT+PHj9dxzz2nDhg3at2+fRo0apejoaCUlJUn6/grSgAEDNGbMGO3cuVPvvfeeUlNTNXz4cEVHR0uSHnroIQUFBSklJUUHDhzQmjVrtHDhQreXtp588kllZWVp7ty5OnjwoDIyMrR7926lpqZ6+7QBAEA95PWXxm699Va98cYbmjx5smbMmKGYmBgtWLBAI0eOtGsmTpyoU6dOaezYsSoqKtIdd9yhrKwsBQcH2zUrV65Uamqq+vXrJ39/fw0ZMkSLFi2y1zdu3FibN2/WuHHj1KNHD1133XVKT093+6yh3r17a9WqVZoyZYqeffZZtWvXTuvXr1eXLl28fdoAAKAe8noQkqT77rtP991330XX+/n5acaMGZoxY8ZFa5o2bapVq1ZVe5ybb75Z27dvr7Zm6NChGjp0aPUNAwAAI/FdYwAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABirQW03AAAA6pY2kzZ5rPn3C4OuQie+xxUhAABgLIIQAAAwFkEIAAAYi/cIAQBQy2rynhz4BleEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYPg9CL7zwgvz8/DR+/Hh72ZkzZzRu3Dg1a9ZMDRs21JAhQ1RQUOC23eeff65BgwYpNDRUzZs319NPP62zZ8+61bz99tvq3r27HA6H2rZtqxUrVlQ5/tKlS9WmTRsFBwcrLi5OO3fu9MVpAgCAesinQWjXrl363e9+p5tvvtlt+YQJE/S3v/1N69at0zvvvKOjR4/qgQcesNeXl5dr0KBBKi0t1Y4dO/THP/5RK1asUHp6ul1z5MgRDRo0SHfffbf27t2r8ePH69FHH9Vbb71l16xZs0ZpaWmaNm2a9uzZo65duyoxMVHHjh3z5WkDAIB6wmdB6OTJkxo5cqR+//vfq0mTJvby48eP6w9/+IPmzZune+65Rz169NDy5cu1Y8cOvf/++5KkzZs368MPP9Sf/vQndevWTQMHDtTMmTO1dOlSlZaWSpIyMzMVExOjuXPnqmPHjkpNTdWDDz6o+fPn28eaN2+exowZo9GjR6tTp07KzMxUaGioli1b5qvTBgAA9UgDX+143LhxGjRokBISEvTcc8/Zy/Py8lRWVqaEhAR7WYcOHXTDDTfI6XTqtttuk9PpVGxsrCIjI+2axMREPf744zpw4IBuueUWOZ1Ot31U1lS+BFdaWqq8vDxNnjzZXu/v76+EhAQ5nc4L9lxSUqKSkhL7cXFxsSSprKxMZWVllz8MH6rsq672VxcwI8+YkWfMyDNmVL3q5uMIsK52O1fMF//O3noOXcr2PglCq1ev1p49e7Rr164q61wul4KCghQREeG2PDIyUi6Xy645NwRVrq9cV11NcXGxvvvuO3377bcqLy+/YM3Bgwcv2PesWbM0ffr0Kss3b96s0NDQas649mVnZ9d2C3UeM/KMGXnGjDxjRtW70Hxm96qFRq7Qm2++6bN9X+lz6PTp0zWu9XoQ+uKLL/Tkk08qOztbwcHB3t69T02ePFlpaWn24+LiYrVq1Ur9+/dXeHh4LXZ2cWVlZcrOzta9996rwMDA2m6nTmJGnjEjz5iRZ8yoetXNp0vGWxfZqu7an5Ho9X166zlU+YpOTXg9COXl5enYsWPq3r27vay8vFzbtm3TkiVL9NZbb6m0tFRFRUVuV4UKCgoUFRUlSYqKiqpyd1flXWXn1px/p1lBQYHCw8MVEhKigIAABQQEXLCmch/nczgccjgcVZYHBgbW+R/q+tBjbWNGnjEjz5iRZ8yoeheaT0m5Xy11c/l8+W98pc+hS9nW62+W7tevn/bt26e9e/faf3r27KmRI0fafw8MDFROTo69zaFDh/T5558rPj5ekhQfH699+/a53d2VnZ2t8PBwderUya45dx+VNZX7CAoKUo8ePdxqKioqlJOTY9cAAACzef2KUKNGjdSlSxe3ZWFhYWrWrJm9PCUlRWlpaWratKnCw8P1q1/9SvHx8brtttskSf3791enTp308MMPa/bs2XK5XJoyZYrGjRtnX7H5xS9+oSVLlmjixIn6+c9/ri1btmjt2rXatGmTfdy0tDQlJyerZ8+e6tWrlxYsWKBTp05p9OjR3j5tAABQD/nsrrHqzJ8/X/7+/hoyZIhKSkqUmJio3/72t/b6gIAAbdy4UY8//rji4+MVFham5ORkzZgxw66JiYnRpk2bNGHCBC1cuFDXX3+9Xn31VSUm/t9rlj/96U/11VdfKT09XS6XS926dVNWVlaVN1ADAAAzXZUg9Pbbb7s9Dg4O1tKlS7V06dKLbtO6dWuP70jv27ev8vPzq61JTU1VampqjXsFAADm4LvGAACAsWrlpTEAAEzRZtL37111BFia3ev7W+Xr411i1yquCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYq0FtNwAAQH3VZtKm2m4BV4grQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsrwehWbNm6dZbb1WjRo3UvHlzJSUl6dChQ241Z86c0bhx49SsWTM1bNhQQ4YMUUFBgVvN559/rkGDBik0NFTNmzfX008/rbNnz7rVvP322+revbscDofatm2rFStWVOln6dKlatOmjYKDgxUXF6edO3d6+5QBAEA95fUg9M4772jcuHF6//33lZ2drbKyMvXv31+nTp2yayZMmKC//e1vWrdund555x0dPXpUDzzwgL2+vLxcgwYNUmlpqXbs2KE//vGPWrFihdLT0+2aI0eOaNCgQbr77ru1d+9ejR8/Xo8++qjeeustu2bNmjVKS0vTtGnTtGfPHnXt2lWJiYk6duyYt08bAADUQw28vcOsrCy3xytWrFDz5s2Vl5enu+66S8ePH9cf/vAHrVq1Svfcc48kafny5erYsaPef/993Xbbbdq8ebM+/PBD/eMf/1BkZKS6deummTNn6plnnlFGRoaCgoKUmZmpmJgYzZ07V5LUsWNHvfvuu5o/f74SExMlSfPmzdOYMWM0evRoSVJmZqY2bdqkZcuWadKkSd4+dQAAUM94PQid7/jx45Kkpk2bSpLy8vJUVlamhIQEu6ZDhw664YYb5HQ6ddttt8npdCo2NlaRkZF2TWJioh5//HEdOHBAt9xyi5xOp9s+KmvGjx8vSSotLVVeXp4mT55sr/f391dCQoKcTucFey0pKVFJSYn9uLi4WJJUVlamsrKyK5iC71T2VVf7qwuYkWfMyDNm5JmJM3IEWDWv9bfc/re+88W/s7eeQ5eyvU+DUEVFhcaPH6/bb79dXbp0kSS5XC4FBQUpIiLCrTYyMlIul8uuOTcEVa6vXFddTXFxsb777jt9++23Ki8vv2DNwYMHL9jvrFmzNH369CrLN2/erNDQ0Bqede3Izs6u7RbqPGbkGTPyjBl5ZtKMZve69G1m9qzwfiO14M033/TZvq/0OXT69Oka1/o0CI0bN0779+/Xu+++68vDeM3kyZOVlpZmPy4uLlarVq3Uv39/hYeH12JnF1dWVqbs7Gzde++9CgwMrO126iRm5Bkz8owZeWbijLpkvOW56P9z+Fua2bNCU3f7q6TCz4ddXR37MxK9vk9vPYcqX9GpCZ8FodTUVG3cuFHbtm3T9ddfby+PiopSaWmpioqK3K4KFRQUKCoqyq45/+6uyrvKzq05/06zgoIChYeHKyQkRAEBAQoICLhgTeU+zudwOORwOKosDwwMrPM/1PWhx9rGjDxjRp4xI89MmlFJ+aUHmpIKv8varq7x5b/xlT6HLmVbr981ZlmWUlNT9cYbb2jLli2KiYlxW9+jRw8FBgYqJyfHXnbo0CF9/vnnio+PlyTFx8dr3759bnd3ZWdnKzw8XJ06dbJrzt1HZU3lPoKCgtSjRw+3moqKCuXk5Ng1AADAbF6/IjRu3DitWrVKf/3rX9WoUSP7PT2NGzdWSEiIGjdurJSUFKWlpalp06YKDw/Xr371K8XHx+u2226TJPXv31+dOnXSww8/rNmzZ8vlcmnKlCkaN26cfcXmF7/4hZYsWaKJEyfq5z//ubZs2aK1a9dq06ZNdi9paWlKTk5Wz5491atXLy1YsECnTp2y7yIDAABm83oQevnllyVJffv2dVu+fPlyPfLII5Kk+fPny9/fX0OGDFFJSYkSExP129/+1q4NCAjQxo0b9fjjjys+Pl5hYWFKTk7WjBkz7JqYmBht2rRJEyZM0MKFC3X99dfr1VdftW+dl6Sf/vSn+uqrr5Seni6Xy6Vu3bopKyuryhuoAQCAmbwehCzL822BwcHBWrp0qZYuXXrRmtatW3t8R3rfvn2Vn59fbU1qaqpSU1M99gQAwLnaTNrkuQj1Ht81BgAAjEUQAgAAxvL5J0sDAIBrT01eOvz3C4OuQidXhitCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGM1qO0GAAC42tpM2lTbLaCO4IoQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEa1HYDAAB4U5tJm2q7BdQjXBECAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIzFByoCAOoNPiwR3sYVIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAY3H7PACgTuDWeNQGrggBAABjEYQAAICxCEIAAMBYvEcIAOBzvP8HdRVXhAAAgLEIQgAAwFi8NAYAuCKVL3s5AizN7iV1yXhLJeV+tdwVUDNcEQIAAMYiCAEAAGMZ8dLY0qVLNWfOHLlcLnXt2lWLFy9Wr169arstAKjTuNMLV6omz6F/vzDoKnRycdd8EFqzZo3S0tKUmZmpuLg4LViwQImJiTp06JCaN29e2+0BQK0g5ADfu+aD0Lx58zRmzBiNHj1akpSZmalNmzZp2bJlmjRpUi13BwDeR8gBau6aDkKlpaXKy8vT5MmT7WX+/v5KSEiQ0+msUl9SUqKSkhL78fHjxyVJhYWFKisr833Dl6GsrEynT5/WN998o8DAwNpup05iRp4xI8+udEZxs3J80NWF1dYv9gYVlk6frlCDMn+VV3DX2PmYz4V988039t+99bvoxIkTkiTLsjzWXtNB6Ouvv1Z5ebkiIyPdlkdGRurgwYNV6mfNmqXp06dXWR4TE+OzHgHgWvJQbTdQxzGfqq6b67t9nzhxQo0bN6625poOQpdq8uTJSktLsx9XVFSosLBQzZo1k59f3UzvxcXFatWqlb744guFh4fXdjt1EjPyjBl5xow8Y0bVYz6eeWtGlmXpxIkTio6O9lh7TQeh6667TgEBASooKHBbXlBQoKioqCr1DodDDofDbVlERIQvW/Sa8PBwfrA8YEaeMSPPmJFnzKh6zMczb8zI05WgStf05wgFBQWpR48eysn5v9fmKyoqlJOTo/j4+FrsDAAA1AXX9BUhSUpLS1NycrJ69uypXr16acGCBTp16pR9FxkAADDXNR+EfvrTn+qrr75Senq6XC6XunXrpqysrCpvoK6vHA6Hpk2bVuUlPfwfZuQZM/KMGXnGjKrHfDyrjRn5WTW5twwAAOAadE2/RwgAAKA6BCEAAGAsghAAADAWQQgAABiLIAQAAIxFEKqHfvOb36h3794KDQ2t0Sdfl5WV6ZlnnlFsbKzCwsIUHR2tUaNG6ejRo75vtpZc6oyk7z+SPT09XS1atFBISIgSEhJ0+PBh3zZaSwoLCzVy5EiFh4crIiJCKSkpOnnyZLXbuFwuPfzww4qKilJYWJi6d++uP//5z1ep46vvcmYkSU6nU/fcc4/CwsIUHh6uu+66S999991V6Pjqu9wZSd//vA0cOFB+fn5av369bxutRZc6o8LCQv3qV79S+/btFRISohtuuEFPPPGE/SXg14KlS5eqTZs2Cg4OVlxcnHbu3Flt/bp169ShQwcFBwcrNjZWb775plf7IQjVQ6WlpRo6dKgef/zxGtWfPn1ae/bs0dSpU7Vnzx795S9/0aFDh/STn/zEx53WnkudkSTNnj1bixYtUmZmpnJzcxUWFqbExESdOXPGh53WjpEjR+rAgQPKzs7Wxo0btW3bNo0dO7babUaNGqVDhw5pw4YN2rdvnx544AENGzZM+fn5V6nrq+tyZuR0OjVgwAD1799fO3fu1K5du5Samip//2vzV+3lzKjSggUL6ux3OHrTpc7o6NGjOnr0qF566SXt379fK1asUFZWllJSUq5i176zZs0apaWladq0adqzZ4+6du2qxMREHTt27IL1O3bs0IgRI5SSkqL8/HwlJSUpKSlJ+/fv915TFuqt5cuXW40bN76sbXfu3GlJsj777DPvNlXH1HRGFRUVVlRUlDVnzhx7WVFRkeVwOKz//d//9WGHV9+HH35oSbJ27dplL/v73/9u+fn5WV9++eVFtwsLC7Nee+01t2VNmza1fv/73/us19pyuTOKi4uzpkyZcjVarHWXOyPLsqz8/HyrZcuW1n//+19LkvXGG2/4uNvacSUzOtfatWutoKAgq6yszBdtXlW9evWyxo0bZz8uLy+3oqOjrVmzZl2wftiwYdagQYPclsXFxVmPPfaY13q6Nv8zBR4dP35cfn5+9eZLZX3tyJEjcrlcSkhIsJc1btxYcXFxcjqdtdiZ9zmdTkVERKhnz572soSEBPn7+ys3N/ei2/Xu3Vtr1qxRYWGhKioqtHr1ap05c0Z9+/a9Cl1fXZczo2PHjik3N1fNmzdX7969FRkZqT59+ujdd9+9Wm1fVZf7PDp9+rQeeughLV269IJffn0tudwZne/48eMKDw9Xgwb1+8sgSktLlZeX5/Z71t/fXwkJCRf9Pet0Ot3qJSkxMdGrv5cJQgY6c+aMnnnmGY0YMYJvQP7/XC6XJFX56pXIyEh73bXC5XKpefPmbssaNGigpk2bVnuua9euVVlZmZo1ayaHw6HHHntMb7zxhtq2bevrlq+6y5nRv/71L0lSRkaGxowZo6ysLHXv3l39+vW7Jt9rdrnPowkTJqh3794aPHiwr1usdZc7o3N9/fXXmjlzZo1fcqzLvv76a5WXl1/S71mXy+Xz38sEoTpi0qRJ8vPzq/bPwYMHr/g4ZWVlGjZsmCzL0ssvv+yFzq+eqzWj+srX85k6daqKior0j3/8Q7t371ZaWpqGDRumffv2efEsfMuXM6qoqJAkPfbYYxo9erRuueUWzZ8/X+3bt9eyZcu8eRo+5csZbdiwQVu2bNGCBQu82/RVdrV+FxUXF2vQoEHq1KmTMjIyrrxxXFD9vs52Dfn1r3+tRx55pNqaG2+88YqOURmCPvvsM23ZsqXeXQ3y5YwqL9EXFBSoRYsW9vKCggJ169btsvZ5tdV0PlFRUVXemHj27FkVFhZe9KWKTz/9VEuWLNH+/fvVuXNnSVLXrl21fft2LV26VJmZmV45B1/z5YwqnzedOnVyW96xY0d9/vnnl9/0VebLGW3ZskWffvpplZfkhwwZojvvvFNvv/32FXR+9fhyRpVOnDihAQMGqFGjRnrjjTcUGBh4pW3Xuuuuu04BAQEqKChwW15QUHDReURFRV1S/eUgCNURP/jBD/SDH/zAZ/uvDEGHDx/W1q1b1axZM58dy1d8OaOYmBhFRUUpJyfHDj7FxcXKzc29pDvPalNN5xMfH6+ioiLl5eWpR48ekr7/P6iKigrFxcVdcJvTp09LUpW7nwICAuwrIfWBL2fUpk0bRUdH69ChQ27LP/74Yw0cOPDKm79KfDmjSZMm6dFHH3VbFhsbq/nz5+vHP/7xlTd/lfhyRtL3v3sSExPlcDi0YcMGBQcHe6332hQUFKQePXooJydHSUlJkr6/kpqTk6PU1NQLbhMfH6+cnByNHz/eXpadna34+HjvNea1t13jqvnss8+s/Px8a/r06VbDhg2t/Px8Kz8/3zpx4oRd0759e+svf/mLZVmWVVpaav3kJz+xrr/+emvv3r3Wf//7X/tPSUlJbZ2GT13qjCzLsl544QUrIiLC+utf/2p98MEH1uDBg62YmBjru+++q41T8KkBAwZYt9xyi5Wbm2u9++67Vrt27awRI0bY6//zn/9Y7du3t3Jzcy3L+v451LZtW+vOO++0cnNzrU8++cR66aWXLD8/P2vTpk21dRo+dakzsizLmj9/vhUeHm6tW7fOOnz4sDVlyhQrODjY+uSTT2rjFHzucmZ0Pl3Dd41Z1qXP6Pjx41ZcXJwVGxtrffLJJ26/r8+ePVtbp+E1q1evthwOh7VixQrrww8/tMaOHWtFRERYLpfLsizLevjhh61JkybZ9e+9957VoEED66WXXrI++ugja9q0aVZgYKC1b98+r/VEEKqHkpOTLUlV/mzdutWukWQtX77csizLOnLkyAXrz9/mWnKpM7Ks72+hnzp1qhUZGWk5HA6rX79+1qFDh65+81fBN998Y40YMcJq2LChFR4ebo0ePdotJFY+Z86d18cff2w98MADVvPmza3Q0FDr5ptvrnI7/bXkcmZkWZY1a9Ys6/rrr7dCQ0Ot+Ph4a/v27Ve586vncmd0rms9CF3qjLZu3XrR39dHjhypnZPwssWLF1s33HCDFRQUZPXq1ct6//337XV9+vSxkpOT3erXrl1r/fCHP7SCgoKszp07e/0/vvwsy7K8d30JAACg/uCuMQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAY6/8BiEEgLgk5ndsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feature in ['feature_223', 'feature_124', 'feature_30']:\n",
    "    nan_values = df_for_logreg[feature].isnull().sum()\n",
    "    mean_value = df_for_logreg[feature].mean()\n",
    "    median_value = df_for_logreg[feature].median()\n",
    "    print(f\"Количество пропусков в признаке {feature}: {nan_values}\")\n",
    "    print(f\"Среднее значение: {mean_value}, Медиана: {median_value}\")\n",
    "    df_for_logreg[feature].hist(bins=50)\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним про категориальные признаки, их нужно закодировать.\n",
    "\n",
    "**Задание:** Используя `OneHotEncoder` закодируйте категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# категориальных признаков нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepwise и обучение логрега (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание (boss)**: Реализуйте Stepwise-алгоритм.\n",
    "\n",
    "Ваша функция `stepwise` должна принимать на вход:\n",
    "- Датафрейм со всеми признаками и таргетом\n",
    "- список с именами рассматриваемых признаков\n",
    "- строку-имя таргета\n",
    "- уровни значимости `alpha_in` и `alpha_out`\n",
    "\n",
    "И возвращать список отобранных признаков.\n",
    "\n",
    "Во время работы пусть она также выводит, какой признак был включён или исключён и с каким `p-value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import chi2\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio_test(ll_short, ll_long):\n",
    "    \n",
    "    \"\"\"\n",
    "    вспомогательная функция\n",
    "    рассчитывает значение p-value для теста отношения правдоподобия\n",
    "    ll_short — логарифм правдоподобия модели на k переменных\n",
    "    ll_long — логарифм правдоподобия модели на k+1 переменной\n",
    "\n",
    "    Returns\n",
    "    -----\n",
    "    p-value\n",
    "    \"\"\"\n",
    "    lr = -2 * (ll_short - ll_long)\n",
    "    return chi2.sf(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(predictions, y):\n",
    "    \"\"\"\n",
    "    Расчитывает логарифм правдоподобия для заданной модели и данных.\n",
    "    \"\"\"\n",
    "    return np.sum(y*np.log1p(predictions) + (1-y)*np.log1p(1-predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise(\n",
    "        df: pd.DataFrame, \n",
    "        features: list[str], \n",
    "        target: str, \n",
    "        alpha_in: float = 0.01, \n",
    "        alpha_out:  float = 0.05\n",
    "        ) -> list[str]:\n",
    "\n",
    "\n",
    "    selected_features = list()\n",
    "    mean_target = np.mean(df[target])\n",
    "    baseline_predictions = np.full_like(df[target], mean_target, dtype=np.float64)\n",
    "    cur_ll = log_likelihood(baseline_predictions, df[target])\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # forward:\n",
    "        best_feature = None\n",
    "        p_value = alpha_in\n",
    "        if (len(selected_features) < len(features)):\n",
    "            for feature in features:\n",
    "                if feature in selected_features:\n",
    "                    continue\n",
    "                current_features = selected_features + [feature]\n",
    "                model = make_pipeline(\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression()\n",
    "                ).fit(df[current_features], df[target])\n",
    "                pred = model.predict_proba(df[current_features])[:,1]\n",
    "                ll_long = log_likelihood(pred, df[target])\n",
    "                feature_p_value = likelihood_ratio_test(cur_ll, ll_long)\n",
    "                if (feature_p_value < p_value):\n",
    "                    p_value = feature_p_value\n",
    "                    best_feature = feature\n",
    "            if best_feature:\n",
    "                selected_features.append(best_feature)\n",
    "                model = make_pipeline(\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression()\n",
    "                ).fit(df[selected_features], df[target])\n",
    "                pred = model.predict_proba(df[selected_features])[:,1]\n",
    "                cur_ll = log_likelihood(pred, df[target])\n",
    "                print(f\"В модель была добавлена переменная {best_feature}, p-value: {round(p_value, 6)}\")\n",
    "\n",
    "\n",
    "        # backward\n",
    "        worst_feature = None\n",
    "        p_value = alpha_out\n",
    "        if (len(selected_features) > 1):\n",
    "            for feature in selected_features:\n",
    "                current_features = list(selected_features)\n",
    "                current_features.remove(feature)\n",
    "                model = make_pipeline(\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression()\n",
    "                ).fit(df[current_features], df[target])\n",
    "                pred = model.predict_proba(df[current_features])[:,1]\n",
    "                ll_short = log_likelihood(pred, df[target])\n",
    "                feature_p_value = likelihood_ratio_test(ll_short, cur_ll)\n",
    "                if (feature_p_value > p_value):\n",
    "                    p_value = feature_p_value\n",
    "                    worst_feature = feature\n",
    "\n",
    "            if worst_feature:\n",
    "                selected_features.remove(worst_feature)\n",
    "                model = make_pipeline(\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression()\n",
    "                ).fit(df[selected_features], df[target])\n",
    "                pred = model.predict_proba(df[selected_features])[:,1]\n",
    "                cur_ll = log_likelihood(pred, df[target])\n",
    "                print(f\"Из модели была удалена переменная {worst_feature}, p-value: {round(p_value, 6)}\")\n",
    "\n",
    "        if not (best_feature or worst_feature):\n",
    "            break # но вы можете сформулировать критерий останова по-другому, если вам так будет удобнее писать\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите ваш алгоритм на отобранных фичах со значениями `alpha_in = 0.01`, `alpha_out = 0.02`\n",
    "\n",
    "Если в степвайз заходят *все переменные*, причём с очень маленькими `p-value` - это неудивительно, ведь вы уже провели серьёзный предварительный отбор фичей.\n",
    "\n",
    "Чтобы убедиться в коректности работы своего алгоритма, можете попробовать запустить его на каких-нибудь других фичах, откинутых сильно ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В модель была добавлена переменная feature_124, p-value: 0.0\n",
      "В модель была добавлена переменная feature_30, p-value: 0.0\n",
      "В модель была добавлена переменная feature_225, p-value: 0.0\n",
      "В модель была добавлена переменная feature_24, p-value: 0.0\n",
      "В модель была добавлена переменная feature_46, p-value: 0.0\n",
      "В модель была добавлена переменная feature_213, p-value: 0.0\n",
      "В модель была добавлена переменная feature_38, p-value: 0.0\n",
      "В модель была добавлена переменная feature_223, p-value: 0.0\n",
      "В модель была добавлена переменная feature_5, p-value: 0.0\n",
      "В модель была добавлена переменная feature_75, p-value: 0.0\n",
      "В модель была добавлена переменная feature_56, p-value: 0.0\n",
      "В модель была добавлена переменная feature_26, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "selected_features = stepwise(df_for_logreg, top15features_stable, TARGET, alpha_in = 0.01, alpha_out = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_124',\n",
       " 'feature_30',\n",
       " 'feature_225',\n",
       " 'feature_24',\n",
       " 'feature_46',\n",
       " 'feature_213',\n",
       " 'feature_38',\n",
       " 'feature_223',\n",
       " 'feature_5',\n",
       " 'feature_75',\n",
       " 'feature_56',\n",
       " 'feature_26']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: На получившемся наборе признаков обучим, наконец, логрег!\n",
    "\n",
    "Для обучения можно использовать трейн + валидацию вместе, либо просто трейн\n",
    "\n",
    "*Не забудьте отскалировать фичи*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = df_for_logreg[df_for_logreg['sample_part'] != 'test'][selected_features],\\\n",
    "                                    df_for_logreg[df_for_logreg['sample_part'] != 'test'][TARGET],\\\n",
    "                                    df_for_logreg[df_for_logreg['sample_part'] == 'test'][selected_features],\\\n",
    "                                    df_for_logreg[df_for_logreg['sample_part'] == 'test'][TARGET]\n",
    "X = df_for_logreg[selected_features]\n",
    "pipe = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('logisticregression', LogisticRegression(verbose=0, random_state=42))\n",
    "])\n",
    "param_grid = {\n",
    "    'logisticregression__penalty': ['l2', None],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__tol': [1e-4, 1e-3, 1e-2],\n",
    "    'logisticregression__fit_intercept': [True, False],\n",
    "    'logisticregression__intercept_scaling': [1, 2, 3],\n",
    "    'logisticregression__class_weight': [None, 'balanced'],\n",
    "    'logisticregression__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'logisticregression__max_iter': list(range(10, 1000, 10)),\n",
    "    'logisticregression__warm_start': [True, False],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/denis/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                              StandardScaler()),\n",
       "                                             (&#x27;logisticregression&#x27;,\n",
       "                                              LogisticRegression(random_state=42))]),\n",
       "                   n_iter=40, n_jobs=1,\n",
       "                   param_distributions={&#x27;logisticregression__C&#x27;: [0.01, 0.1, 1,\n",
       "                                                                  10, 100],\n",
       "                                        &#x27;logisticregression__class_weight&#x27;: [None,\n",
       "                                                                             &#x27;balanced&#x27;],\n",
       "                                        &#x27;logisticregression__fit_intercept&#x27;: [True,\n",
       "                                                                              False],\n",
       "                                        &#x27;logisticregression__i...\n",
       "                                        &#x27;logisticregression__max_iter&#x27;: [10, 20,\n",
       "                                                                         30, 40,\n",
       "                                                                         50, 60,\n",
       "                                                                         70, 80,\n",
       "                                                                         90,\n",
       "                                                                         100,\n",
       "                                                                         110,\n",
       "                                                                         120,\n",
       "                                                                         130,\n",
       "                                                                         140,\n",
       "                                                                         150,\n",
       "                                                                         160,\n",
       "                                                                         170,\n",
       "                                                                         180,\n",
       "                                                                         190,\n",
       "                                                                         200,\n",
       "                                                                         210,\n",
       "                                                                         220,\n",
       "                                                                         230,\n",
       "                                                                         240,\n",
       "                                                                         250,\n",
       "                                                                         260,\n",
       "                                                                         270,\n",
       "                                                                         280,\n",
       "                                                                         290,\n",
       "                                                                         300, ...],\n",
       "                                        &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;,\n",
       "                                                                        None],\n",
       "                                        &#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;,\n",
       "                                                                       &#x27;lbfgs&#x27;,\n",
       "                                                                       &#x27;sag&#x27;,\n",
       "                                                                       &#x27;saga&#x27;],\n",
       "                                        &#x27;logisticregression__tol&#x27;: [0.0001,\n",
       "                                                                    0.001,\n",
       "                                                                    0.01],\n",
       "                                        &#x27;logisticregression__warm_start&#x27;: [True,\n",
       "                                                                           False]},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                              StandardScaler()),\n",
       "                                             (&#x27;logisticregression&#x27;,\n",
       "                                              LogisticRegression(random_state=42))]),\n",
       "                   n_iter=40, n_jobs=1,\n",
       "                   param_distributions={&#x27;logisticregression__C&#x27;: [0.01, 0.1, 1,\n",
       "                                                                  10, 100],\n",
       "                                        &#x27;logisticregression__class_weight&#x27;: [None,\n",
       "                                                                             &#x27;balanced&#x27;],\n",
       "                                        &#x27;logisticregression__fit_intercept&#x27;: [True,\n",
       "                                                                              False],\n",
       "                                        &#x27;logisticregression__i...\n",
       "                                        &#x27;logisticregression__max_iter&#x27;: [10, 20,\n",
       "                                                                         30, 40,\n",
       "                                                                         50, 60,\n",
       "                                                                         70, 80,\n",
       "                                                                         90,\n",
       "                                                                         100,\n",
       "                                                                         110,\n",
       "                                                                         120,\n",
       "                                                                         130,\n",
       "                                                                         140,\n",
       "                                                                         150,\n",
       "                                                                         160,\n",
       "                                                                         170,\n",
       "                                                                         180,\n",
       "                                                                         190,\n",
       "                                                                         200,\n",
       "                                                                         210,\n",
       "                                                                         220,\n",
       "                                                                         230,\n",
       "                                                                         240,\n",
       "                                                                         250,\n",
       "                                                                         260,\n",
       "                                                                         270,\n",
       "                                                                         280,\n",
       "                                                                         290,\n",
       "                                                                         300, ...],\n",
       "                                        &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;,\n",
       "                                                                        None],\n",
       "                                        &#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;,\n",
       "                                                                       &#x27;lbfgs&#x27;,\n",
       "                                                                       &#x27;sag&#x27;,\n",
       "                                                                       &#x27;saga&#x27;],\n",
       "                                        &#x27;logisticregression__tol&#x27;: [0.0001,\n",
       "                                                                    0.001,\n",
       "                                                                    0.01],\n",
       "                                        &#x27;logisticregression__warm_start&#x27;: [True,\n",
       "                                                                           False]},\n",
       "                   random_state=42)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(random_state=42))]),\n",
       "                   n_iter=40, n_jobs=1,\n",
       "                   param_distributions={'logisticregression__C': [0.01, 0.1, 1,\n",
       "                                                                  10, 100],\n",
       "                                        'logisticregression__class_weight': [None,\n",
       "                                                                             'balanced'],\n",
       "                                        'logisticregression__fit_intercept': [True,\n",
       "                                                                              False],\n",
       "                                        'logisticregression__i...\n",
       "                                        'logisticregression__max_iter': [10, 20,\n",
       "                                                                         30, 40,\n",
       "                                                                         50, 60,\n",
       "                                                                         70, 80,\n",
       "                                                                         90,\n",
       "                                                                         100,\n",
       "                                                                         110,\n",
       "                                                                         120,\n",
       "                                                                         130,\n",
       "                                                                         140,\n",
       "                                                                         150,\n",
       "                                                                         160,\n",
       "                                                                         170,\n",
       "                                                                         180,\n",
       "                                                                         190,\n",
       "                                                                         200,\n",
       "                                                                         210,\n",
       "                                                                         220,\n",
       "                                                                         230,\n",
       "                                                                         240,\n",
       "                                                                         250,\n",
       "                                                                         260,\n",
       "                                                                         270,\n",
       "                                                                         280,\n",
       "                                                                         290,\n",
       "                                                                         300, ...],\n",
       "                                        'logisticregression__penalty': ['l2',\n",
       "                                                                        None],\n",
       "                                        'logisticregression__solver': ['newton-cg',\n",
       "                                                                       'lbfgs',\n",
       "                                                                       'sag',\n",
       "                                                                       'saga'],\n",
       "                                        'logisticregression__tol': [0.0001,\n",
       "                                                                    0.001,\n",
       "                                                                    0.01],\n",
       "                                        'logisticregression__warm_start': [True,\n",
       "                                                                           False]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search = RandomizedSearchCV(pipe, param_grid, n_iter=40, random_state=42, n_jobs=1)\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {key[len('logisticregression__'):]: val for key, val in bayes_search.best_params_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': False,\n",
       " 'tol': 0.001,\n",
       " 'solver': 'newton-cg',\n",
       " 'penalty': 'l2',\n",
       " 'max_iter': 870,\n",
       " 'intercept_scaling': 1,\n",
       " 'fit_intercept': True,\n",
       " 'class_weight': None,\n",
       " 'C': 10}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11948/3000569535.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg['logreg'] = logreg.predict_proba(X)[:, 1]\n",
      "/tmp/ipykernel_11948/3000569535.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_for_logreg['logit_logreg'] = logit(df_for_logreg['logreg'])\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('logisticregression', LogisticRegression(**best_params))\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "df_for_logreg['logreg'] = logreg.predict_proba(X)[:, 1]\n",
    "df_for_logreg['logit_logreg'] = logit(df_for_logreg['logreg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Оцените качество получившегося логрега **на тестовой выборке** по метрике `roc_auc`. \n",
    "\n",
    "**Ваша задача - побить** `threshold_auc = 0.622`. Если этого сделать ну совсем не получается, попробуйте добавить в модель ещё переменных (но должно получаться :)\n",
    "\n",
    "**Также:**\n",
    "\n",
    "- Постройте графики линейности по WoE получившегося логрега на трейне и тестовой выборке (оценивайте линейность для `logit_logreg`, а не для вероятности!)\n",
    "- Постройте график стабильности `roc_auc` во времени для получившегося логрега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.07980717134739565,
          0.3740569821704096,
          0.5016257096950488,
          0.5925407243675407,
          0.6655776737293795,
          0.7283883047612786,
          0.7839496414726261,
          0.8355290203720332,
          0.8839482238860327,
          0.9308341070183713,
          0.9767910990484443,
          1.0224384641412907,
          1.068943708597542,
          1.1169636970668866,
          1.16756392836353,
          1.2229688414621758,
          1.2852590562456043,
          1.3608494887587943,
          1.462298105132975,
          1.6727629529439734
         ],
         "y": [
          -0.8394359563528804,
          -0.5411001164546303,
          -0.41175993654299137,
          -0.3195824524324111,
          -0.24553129307728694,
          -0.18184845735675115,
          -0.12551558153505882,
          -0.07321995802269432,
          -0.024128392909533614,
          0.023408559738061885,
          0.07000372246098863,
          0.11628495868685551,
          0.1634359870111335,
          0.21212279347614382,
          0.2634256726885613,
          0.31959995275875674,
          0.3827551455960232,
          0.4593952464308164,
          0.562252604564212,
          0.7756400217561921
         ]
        },
        {
         "error_y": {
          "array": [
           -0.9458360007870834,
           -0.5823875497617172,
           -0.40240562814393216,
           -0.3124777228392148,
           -0.20174959735299147,
           -0.09026009814458913,
           -0.002193571008599182,
           0.025270162578662436,
           0.07798813111077563,
           0.11651988492741383,
           0.2206450535515665,
           0.23430505262513823,
           0.2606066384999586,
           0.3254905798321055,
           0.33765286445319376,
           0.3358460385605786,
           0.4123673301199011,
           0.4717486099562094,
           0.4727232029401167,
           0.5866542687930019
          ],
          "arrayminus": [
           -1.016035812984923,
           -0.6531776476495271,
           -0.47434702980236493,
           -0.3852096529554565,
           -0.275654247512958,
           -0.16557057643663342,
           -0.0787764970841125,
           -0.05173917370919068,
           0.00012046995671788352,
           0.0379915172196007,
           0.14018854736836528,
           0.15357997658414302,
           0.1793541374802512,
           0.2428784869543359,
           0.254776586746696,
           0.2530091955306477,
           0.3278027098576548,
           0.38576092695199704,
           0.38671155735892837,
           0.4977043292025136
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.07980717134739565,
          0.3740569821704096,
          0.5016257096950488,
          0.5925407243675407,
          0.6655776737293795,
          0.7283883047612786,
          0.7839496414726261,
          0.8355290203720332,
          0.8839482238860327,
          0.9308341070183713,
          0.9767910990484443,
          1.0224384641412907,
          1.068943708597542,
          1.1169636970668866,
          1.16756392836353,
          1.2229688414621758,
          1.2852590562456043,
          1.3608494887587943,
          1.462298105132975,
          1.6727629529439734
         ],
         "y": [
          -0.9809085043337444,
          -0.6178678983850758,
          -0.4385205334517433,
          -0.3490189057412951,
          -0.2389172476135657,
          -0.128173643421432,
          -0.04077947282702321,
          -0.013540653235362243,
          0.03872504135967747,
          0.07690899144091179,
          0.18002036371223062,
          0.1935392567533607,
          0.21956379026755157,
          0.2837338159742733,
          0.2957574126462683,
          0.2939712880340075,
          0.36958572020478697,
          0.42822019113237064,
          0.42918220901197435,
          0.5415711891069053
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.605 IV = 0.151 R_sqr = 0.948 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(df_for_logreg[df_for_logreg['sample_part'] == 'train'][\"logit_logreg\"].to_numpy(), df_for_logreg[df_for_logreg['sample_part'] == 'train'][TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "interpolation_line",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -0.16376431902348568,
          0.13864795622487908,
          0.2727229908844334,
          0.36839844670494315,
          0.44459208689849894,
          0.5099754370006893,
          0.5696222384942203,
          0.6253669524271108,
          0.6772045749071625,
          0.7262881865948944,
          0.7743215894078367,
          0.8236350139469326,
          0.8729100905956734,
          0.9245187373396351,
          0.9790136992787192,
          1.0371317338796924,
          1.1034032282054174,
          1.1820949335185953,
          1.2886107802789337,
          1.5139859834688845
         ],
         "y": [
          -0.8242134619419017,
          -0.5366283472811233,
          -0.409126961353423,
          -0.3181424372967647,
          -0.24568454274374174,
          -0.18350691380787398,
          -0.12678457265099508,
          -0.07377300116317631,
          -0.024476957897656026,
          0.022200102693183288,
          0.06787844575701063,
          0.1147740515611877,
          0.16163318965771034,
          0.21071148378171856,
          0.26253457814789516,
          0.3178031072803631,
          0.380825335061137,
          0.4556588155366115,
          0.556952230225563,
          0.7712773716168884
         ]
        },
        {
         "error_y": {
          "array": [
           -0.8645849180579527,
           -0.5982193207931137,
           -0.3697399829229091,
           -0.28938309878574586,
           -0.20001047859996335,
           -0.09502805353596544,
           -0.04258307095621272,
           0.026473484967471594,
           0.08558134244915805,
           0.14901434209529563,
           0.1538128872534883,
           0.2543448780602202,
           0.2514639052750338,
           0.30694289438467526,
           0.3587495852844478,
           0.39566541867935223,
           0.4726790028351584,
           0.477556183348933,
           0.5329890939462483,
           0.569557896065328
          ],
          "arrayminus": [
           -0.955130916563752,
           -0.6894870486784914,
           -0.46290723649468063,
           -0.3835019130018301,
           -0.29536283912159234,
           -0.19206754243019042,
           -0.14056277562591013,
           -0.0728443210372377,
           -0.014973029113699687,
           0.04703826155701596,
           0.051725239938689604,
           0.1497884777474392,
           0.14698176692584997,
           0.20099385216495103,
           0.25136003988568567,
           0.2872073085568696,
           0.3618774101937432,
           0.36660093095366064,
           0.42024294331444745,
           0.45558521662800877
          ],
          "symmetric": false,
          "type": "data"
         },
         "line": {
          "color": "firebrick",
          "dash": "dot",
          "width": 1
         },
         "name": "WoE",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -0.16376431902348568,
          0.13864795622487908,
          0.2727229908844334,
          0.36839844670494315,
          0.44459208689849894,
          0.5099754370006893,
          0.5696222384942203,
          0.6253669524271108,
          0.6772045749071625,
          0.7262881865948944,
          0.7743215894078367,
          0.8236350139469326,
          0.8729100905956734,
          0.9245187373396351,
          0.9790136992787192,
          1.0371317338796924,
          1.1034032282054174,
          1.1820949335185953,
          1.2886107802789337,
          1.5139859834688845
         ],
         "y": [
          -0.9098510839957676,
          -0.643983984188452,
          -0.41657913359302373,
          -0.3367446189659944,
          -0.2480428126179498,
          -0.14397097083017063,
          -0.09203121590394425,
          -0.023691822785755656,
          0.03475473236346982,
          0.09742865166569326,
          0.10216767360697665,
          0.20138375079802873,
          0.19854233393743925,
          0.2532401993429403,
          0.3042801871958978,
          0.3406274320290801,
          0.41639426205956465,
          0.4211896983300165,
          0.47566986091519703,
          0.5115860938146621
         ]
        }
       ],
       "layout": {
        "height": 450,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 12
         },
         "text": "AUC = 0.605 IV = 0.146 R_sqr = 0.956 ",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "Feature value"
         }
        },
        "yaxis": {
         "title": {
          "font": {
           "size": 12
          },
          "text": "WoE"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woe_line(df_for_logreg[df_for_logreg['sample_part'] == 'test'][\"logit_logreg\"].to_numpy(), df_for_logreg[df_for_logreg['sample_part'] == 'test'][TARGET].to_numpy(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":`(  \n",
    "Очевидно, что модель врятли побьет 0.622 roc auc при данных фичях, возможно, стоило бы их взять побольше.  \n",
    "Однако, в данной модели есть и хорошая сторона: стабильность - сестра таланта!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Визуализируйте важность фичей полученной линейной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "plt.barh(selected_features, logreg['logisticregression'].coef_[0])\n",
    "plt.xlabel('Важность')\n",
    "plt.ylabel('Признаки')\n",
    "plt.title('Коэффициенты значимости признаков для Logistic Regression Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонусная часть (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе про бустинг мы обучали `LGBMClassifier` на довольно большом наборе фичей. Их количество можно сократить, при этом не теряя в качестве модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За начальный набор признаков можно взять все признаки (все 230) или признаки после отбора по IV.\n",
    "\n",
    "**Ваша задача:** Отобрать признаки, подобрать оптимальные гиперпараметры и обучить `LGBMClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание творческое) Можно использовать любые методы отбора признаков / оптимизации гиперпараметров.\n",
    "\n",
    "**Чем меньше признаков, без ухудшения качества модели – тем лучше.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идеи для отбора признаков:\n",
    "\n",
    "- Воспользоваться методами из модуля `sklearn.feature_selection` (точно можно попробовать RFE). Документация https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "- С помощью `BorutaPy` из библиотеки `boruta` (https://towardsdatascience.com/simple-example-using-boruta-feature-selection-in-python-8b96925d5d7a – статья может помочь разобраться с запуском алгоритма (мб не откроется без vpn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answere here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
